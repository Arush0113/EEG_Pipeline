{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with BIDS Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import pathlib\n",
    "\n",
    "import mne\n",
    "import mne_bids\n",
    "\n",
    "matplotlib.use('Qt5Agg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the input data we wish to convert to BIDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:\\Users\\hp\\mne_data\\MNE-sample-data\\MEG\\sample\\sample_audvis_raw.fif...\n",
      "    Read a total of 3 projection items:\n",
      "        PCA-v1 (1 x 102)  idle\n",
      "        PCA-v2 (1 x 102)  idle\n",
      "        PCA-v3 (1 x 102)  idle\n",
      "    Range : 25800 ... 192599 =     42.956 ...   320.670 secs\n",
      "Ready.\n",
      "320 events found\n",
      "Event IDs: [ 1  2  3  4  5 32]\n"
     ]
    }
   ],
   "source": [
    "sample_data_dir = mne.datasets.sample.data_path()\n",
    "sample_data_dir = pathlib.Path(sample_data_dir)\n",
    "\n",
    "raw_path = sample_data_dir / 'MEG' / 'sample' / 'sample_audvis_raw.fif'\n",
    "raw = mne.io.read_raw(raw_path)\n",
    "\n",
    "events = mne.find_events(raw)\n",
    "event_id = {\n",
    "    'Auditory/Left': 1,\n",
    "    'Auditory/Right': 2,\n",
    "    'Visual/Left': 3,\n",
    "    'Visual/Right': 4,\n",
    "    'Smiley': 5,\n",
    "    'Button': 32\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write the Raw data to BIDS!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<table class=\"table table-hover\">\n",
       "    <tr>\n",
       "        <th>Measurement date</th>\n",
       "        <td>December 03, 2002  19:01:10 GMT</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Experimenter</th>\n",
       "        <td>MEG</td>\n",
       "        \n",
       "    </tr>\n",
       "        <th>Participant</th>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Digitized points</th>\n",
       "        <td>146 points</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Good channels</th>\n",
       "        <td>102 magnetometer, 203 gradiometer,\n",
       "            and 59 EEG channels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Bad channels</th>\n",
       "        <td>MEG 2443, EEG 053</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>EOG channels</th>\n",
       "        <td>EOG 061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>ECG channels</th>\n",
       "        <td>Not available</td>\n",
       "    <tr>\n",
       "        <th>Sampling frequency</th>\n",
       "        <td>600.61 Hz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Highpass</th>\n",
       "        <td>0.10 Hz</td>\n",
       "    </tr>\n",
       "     <tr>\n",
       "        <th>Lowpass</th>\n",
       "        <td>172.18 Hz</td>\n",
       "    </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<Info | 23 non-empty values\n",
       " acq_pars: ACQch001 110113 ACQch002 110112 ACQch003 110111 ACQch004 110122 ...\n",
       " bads: 2 items (MEG 2443, EEG 053)\n",
       " ch_names: MEG 0113, MEG 0112, MEG 0111, MEG 0122, MEG 0123, MEG 0121, MEG ...\n",
       " chs: 204 GRAD, 102 MAG, 9 STIM, 60 EEG, 1 EOG\n",
       " custom_ref_applied: False\n",
       " description: acquisition (megacq) VectorView system at NMR-MGH\n",
       " dev_head_t: MEG device -> head transform\n",
       " dig: 146 items (3 Cardinal, 4 HPI, 61 EEG, 78 Extra)\n",
       " events: 1 item (list)\n",
       " experimenter: MEG\n",
       " file_id: 4 items (dict)\n",
       " highpass: 0.1 Hz\n",
       " hpi_meas: 1 item (list)\n",
       " hpi_results: 1 item (list)\n",
       " line_freq: 60\n",
       " lowpass: 172.2 Hz\n",
       " meas_date: 2002-12-03 19:01:10 UTC\n",
       " meas_id: 4 items (dict)\n",
       " nchan: 376\n",
       " proj_id: 1 item (ndarray)\n",
       " proj_name: test\n",
       " projs: PCA-v1: off, PCA-v2: off, PCA-v3: off\n",
       " sfreq: 600.6 Hz\n",
       " subject_info: 3 items (dict)\n",
       ">"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.info['line_freq'] = 60 ## Setting the power line frequency to 60 Hz.\n",
    "\n",
    "subject_info = {\n",
    "    'birthday': (1988, 10, 1),\n",
    "    'sex': 2,\n",
    "    'hand': 3\n",
    "}\n",
    "\n",
    "raw.info['subject_info'] = subject_info\n",
    "raw.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:\\Users\\hp\\mne_data\\MNE-sample-data\\MEG\\sample\\sample_audvis_raw.fif...\n",
      "    Read a total of 3 projection items:\n",
      "        PCA-v1 (1 x 102)  idle\n",
      "        PCA-v2 (1 x 102)  idle\n",
      "        PCA-v3 (1 x 102)  idle\n",
      "    Range : 25800 ... 192599 =     42.956 ...   320.670 secs\n",
      "Ready.\n",
      "\n",
      "Writing 'out_data\\sample_BIDS\\participants.tsv'...\n",
      "\n",
      "participant_id\tage\tsex\thand\n",
      "sub-01\t14\tF\tA\n",
      "sub-02\tn/a\tn/a\tn/a\n",
      "\n",
      "Writing 'out_data\\sample_BIDS\\participants.json'...\n",
      "\n",
      "{\n",
      "    \"participant_id\": {\n",
      "        \"Description\": \"Unique participant identifier\"\n",
      "    },\n",
      "    \"age\": {\n",
      "        \"Description\": \"Age of the participant at time of testing\",\n",
      "        \"Units\": \"years\"\n",
      "    },\n",
      "    \"sex\": {\n",
      "        \"Description\": \"Biological sex of the participant\",\n",
      "        \"Levels\": {\n",
      "            \"F\": \"female\",\n",
      "            \"M\": \"male\"\n",
      "        }\n",
      "    },\n",
      "    \"hand\": {\n",
      "        \"Description\": \"Handedness of the participant\",\n",
      "        \"Levels\": {\n",
      "            \"R\": \"right\",\n",
      "            \"L\": \"left\",\n",
      "            \"A\": \"ambidextrous\"\n",
      "        }\n",
      "    }\n",
      "}\n",
      "\n",
      "Writing 'out_data\\sample_BIDS\\sub-02\\ses-01\\meg\\sub-02_ses-01_coordsystem.json'...\n",
      "\n",
      "{\n",
      "    \"MEGCoordinateSystem\": \"ElektaNeuromag\",\n",
      "    \"MEGCoordinateUnits\": \"m\",\n",
      "    \"MEGCoordinateSystemDescription\": \"RAS orientation and the origin between the ears\",\n",
      "    \"HeadCoilCoordinates\": {\n",
      "        \"NAS\": [\n",
      "            3.725290298461914e-09,\n",
      "            0.10260561108589172,\n",
      "            4.190951585769653e-09\n",
      "        ],\n",
      "        \"LPA\": [\n",
      "            -0.07137660682201385,\n",
      "            0.0,\n",
      "            5.122274160385132e-09\n",
      "        ],\n",
      "        \"RPA\": [\n",
      "            0.07526767998933792,\n",
      "            0.0,\n",
      "            5.587935447692871e-09\n",
      "        ],\n",
      "        \"coil1\": [\n",
      "            0.032922741025686264,\n",
      "            0.09897983074188232,\n",
      "            0.07984329760074615\n",
      "        ],\n",
      "        \"coil2\": [\n",
      "            -0.06998106092214584,\n",
      "            0.06771647930145264,\n",
      "            0.06888450682163239\n",
      "        ],\n",
      "        \"coil3\": [\n",
      "            -0.07260829955339432,\n",
      "            -0.02086828649044037,\n",
      "            0.0971473976969719\n",
      "        ],\n",
      "        \"coil4\": [\n",
      "            0.04996863007545471,\n",
      "            -0.007233052980154753,\n",
      "            0.1228904277086258\n",
      "        ]\n",
      "    },\n",
      "    \"HeadCoilCoordinateSystem\": \"ElektaNeuromag\",\n",
      "    \"HeadCoilCoordinateUnits\": \"m\"\n",
      "}\n",
      "\n",
      "Writing 'out_data\\sample_BIDS\\sub-02\\ses-01\\meg\\sub-02_ses-01_task-audiovisual_run-01_events.tsv'...\n",
      "\n",
      "onset\tduration\ttrial_type\tvalue\tsample\n",
      "3.6246181587150867\t0.0\tAuditory/Right\t2\t2177\n",
      "4.237323479067476\t0.0\tVisual/Left\t3\t2545\n",
      "4.946596485779753\t0.0\tAuditory/Left\t1\t2971\n",
      "5.692498614904401\t0.0\tVisual/Right\t4\t3419\n",
      "6.41342634238425\t0.0\tAuditory/Right\t2\t3852\n",
      "\n",
      "Writing 'out_data\\sample_BIDS\\dataset_description.json'...\n",
      "\n",
      "{\n",
      "    \"Name\": \" \",\n",
      "    \"BIDSVersion\": \"1.4.0\",\n",
      "    \"DatasetType\": \"raw\",\n",
      "    \"Authors\": [\n",
      "        \"Please cite MNE-BIDS in your publication before removing this (citations in README)\"\n",
      "    ]\n",
      "}\n",
      "Reading 0 ... 166799  =      0.000 ...   277.714 secs...\n",
      "\n",
      "Writing 'out_data\\sample_BIDS\\sub-02\\ses-01\\meg\\sub-02_ses-01_task-audiovisual_run-01_meg.json'...\n",
      "\n",
      "{\n",
      "    \"TaskName\": \"audiovisual\",\n",
      "    \"Manufacturer\": \"Elekta\",\n",
      "    \"PowerLineFrequency\": 60,\n",
      "    \"SamplingFrequency\": 600.614990234375,\n",
      "    \"SoftwareFilters\": \"n/a\",\n",
      "    \"RecordingDuration\": 277.7136813300495,\n",
      "    \"RecordingType\": \"continuous\",\n",
      "    \"DewarPosition\": \"n/a\",\n",
      "    \"DigitizedLandmarks\": false,\n",
      "    \"DigitizedHeadPoints\": false,\n",
      "    \"MEGChannelCount\": 306,\n",
      "    \"MEGREFChannelCount\": 0,\n",
      "    \"EEGChannelCount\": 60,\n",
      "    \"EOGChannelCount\": 1,\n",
      "    \"ECGChannelCount\": 0,\n",
      "    \"EMGChannelCount\": 0,\n",
      "    \"MiscChannelCount\": 0,\n",
      "    \"TriggerChannelCount\": 9\n",
      "}\n",
      "\n",
      "Writing 'out_data\\sample_BIDS\\sub-02\\ses-01\\meg\\sub-02_ses-01_task-audiovisual_run-01_channels.tsv'...\n",
      "\n",
      "name\ttype\tunits\tlow_cutoff\thigh_cutoff\tdescription\tsampling_frequency\tstatus\tstatus_description\n",
      "MEG 0113\tMEGGRADPLANAR\tT/m\t0.10000000149011612\t172.17630004882812\tPlanar Gradiometer\t600.614990234375\tgood\tn/a\n",
      "MEG 0112\tMEGGRADPLANAR\tT/m\t0.10000000149011612\t172.17630004882812\tPlanar Gradiometer\t600.614990234375\tgood\tn/a\n",
      "MEG 0111\tMEGMAG\tT\t0.10000000149011612\t172.17630004882812\tMagnetometer\t600.614990234375\tgood\tn/a\n",
      "MEG 0122\tMEGGRADPLANAR\tT/m\t0.10000000149011612\t172.17630004882812\tPlanar Gradiometer\t600.614990234375\tgood\tn/a\n",
      "MEG 0123\tMEGGRADPLANAR\tT/m\t0.10000000149011612\t172.17630004882812\tPlanar Gradiometer\t600.614990234375\tgood\tn/a\n",
      "Copying data files to sub-02_ses-01_task-audiovisual_run-01_meg.fif\n",
      "Reserving possible split file sub-02_ses-01_task-audiovisual_run-01_split-01_meg.fif\n",
      "Writing C:\\Users\\hp\\Desktop\\JupyterLab\\out_data\\sample_BIDS\\sub-02\\ses-01\\meg\\sub-02_ses-01_task-audiovisual_run-01_meg.fif\n",
      "Closing C:\\Users\\hp\\Desktop\\JupyterLab\\out_data\\sample_BIDS\\sub-02\\ses-01\\meg\\sub-02_ses-01_task-audiovisual_run-01_meg.fif\n",
      "[done]\n",
      "\n",
      "Writing 'out_data\\sample_BIDS\\sub-02\\ses-01\\sub-02_ses-01_scans.tsv'...\n",
      "\n",
      "filename\tacq_time\n",
      "meg/sub-02_ses-01_task-audiovisual_run-01_meg.fif\t2002-12-03T19:01:10.720100Z\n",
      "Wrote out_data\\sample_BIDS\\sub-02\\ses-01\\sub-02_ses-01_scans.tsv entry with meg\\sub-02_ses-01_task-audiovisual_run-01_meg.fif.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BIDSPath(\n",
       "root: out_data\\sample_BIDS\n",
       "datatype: meg\n",
       "basename: sub-02_ses-01_task-audiovisual_run-01_meg.fif)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_path = pathlib.Path('out_data/sample_BIDS')\n",
    "\n",
    "bids_path = mne_bids.BIDSPath(subject = '02',\n",
    "                             session = '01',\n",
    "                             task = 'audiovisual',\n",
    "                             run = '01',\n",
    "                             root = out_path)\n",
    "\n",
    "mne_bids.write_raw_bids(raw, bids_path = bids_path, events_data = events, event_id = event_id, overwrite = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write MEGIN / Elekta / NeuroMag fine-calibration and crosstalk files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing fine-calibration file to out_data\\sample_BIDS\\sub-02\\ses-01\\meg\\sub-02_ses-01_acq-calibration_meg.dat\n",
      "Writing crosstalk file to out_data\\sample_BIDS\\sub-02\\ses-01\\meg\\sub-02_ses-01_acq-crosstalk_meg.fif\n"
     ]
    }
   ],
   "source": [
    "cal_path = sample_data_dir / 'SSS' / 'sss_cal_mgh.dat'\n",
    "ct_path = sample_data_dir / 'SSS' / 'ct_sparse_mgh.fif'\n",
    "\n",
    "mne_bids.write_meg_calibration(cal_path, bids_path = bids_path)\n",
    "mne_bids.write_meg_crosstalk(ct_path, bids_path = bids_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the created file and directory structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|sample_BIDS\\\n",
      "|--- README\n",
      "|--- dataset_description.json\n",
      "|--- participants.json\n",
      "|--- participants.tsv\n",
      "|--- sub-01\\\n",
      "|------ ses-01\\\n",
      "|--------- sub-01_ses-01_scans.tsv\n",
      "|--------- meg\\\n",
      "|------------ sub-01_ses-01_acq-calibration_meg.dat\n",
      "|------------ sub-01_ses-01_acq-crosstalk_meg.fif\n",
      "|------------ sub-01_ses-01_coordsystem.json\n",
      "|------------ sub-01_ses-01_task-audiovisual_run-01_channels.tsv\n",
      "|------------ sub-01_ses-01_task-audiovisual_run-01_events.tsv\n",
      "|------------ sub-01_ses-01_task-audiovisual_run-01_meg.fif\n",
      "|------------ sub-01_ses-01_task-audiovisual_run-01_meg.json\n",
      "|--- sub-02\\\n",
      "|------ ses-01\\\n",
      "|--------- sub-02_ses-01_scans.tsv\n",
      "|--------- meg\\\n",
      "|------------ sub-02_ses-01_acq-calibration_meg.dat\n",
      "|------------ sub-02_ses-01_acq-crosstalk_meg.fif\n",
      "|------------ sub-02_ses-01_coordsystem.json\n",
      "|------------ sub-02_ses-01_task-audiovisual_run-01_channels.tsv\n",
      "|------------ sub-02_ses-01_task-audiovisual_run-01_events.tsv\n",
      "|------------ sub-02_ses-01_task-audiovisual_run-01_meg.fif\n",
      "|------------ sub-02_ses-01_task-audiovisual_run-01_meg.json\n"
     ]
    }
   ],
   "source": [
    "mne_bids.print_dir_tree(out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate a data summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing participants.tsv out_data\\sample_BIDS\\participants.tsv...\n",
      "Summarizing scans.tsv files [WindowsPath('out_data/sample_BIDS/sub-01/ses-01/sub-01_ses-01_scans.tsv'), WindowsPath('out_data/sample_BIDS/sub-02/ses-01/sub-02_ses-01_scans.tsv')]...\n",
      "The participant template found: comprised of 0 men and 1 women;\n",
      "comprised of 0 right hand, 0 left hand and 1 ambidextrous; ages ranged from 14.0 to 14.0 (mean = 14.0, std = 0.0; 1 with unknown age)\n",
      "This dataset was created with BIDS version 1.4.0 by Please cite MNE-BIDS in your\n",
      "publication before removing this (citations in README). This report was\n",
      "generated with MNE-BIDS (https://doi.org/10.21105/joss.01896). The dataset\n",
      "consists of 2 participants (comprised of 0 men and 1 women; comprised of 0 right\n",
      "hand, 0 left hand and 1 ambidextrous; ages ranged from 14.0 to 14.0 (mean =\n",
      "14.0, std = 0.0; 1 with unknown age))and 1 recording sessions: 01. Data was\n",
      "recorded using a MEG system (Elekta manufacturer) sampled at 600.61 Hz with line\n",
      "noise at 60 Hz. There were 2 scans in total. Recording durations ranged from\n",
      "277.71 to 277.71 seconds (mean = 277.71, std = 0.0), for a total of 555.43\n",
      "seconds of data recorded over all scans. For each dataset, there were on average\n",
      "376.0 (std = 0.0) recording channels per scan, out of which 374.0 (std = 0.0)\n",
      "were used in analysis (2.0 +/- 0.0 were removed from analysis).\n"
     ]
    }
   ],
   "source": [
    "print(mne_bids.make_report(out_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read BIDS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file out_data\\sample_BIDS\\sub-01\\ses-01\\meg\\sub-01_ses-01_task-audiovisual_run-01_meg.fif...\n",
      "    Read a total of 3 projection items:\n",
      "        PCA-v1 (1 x 102)  idle\n",
      "        PCA-v2 (1 x 102)  idle\n",
      "        PCA-v3 (1 x 102)  idle\n",
      "    Range : 25800 ... 192599 =     42.956 ...   320.670 secs\n",
      "Ready.\n",
      "Reading events from out_data\\sample_BIDS\\sub-01\\ses-01\\meg\\sub-01_ses-01_task-audiovisual_run-01_events.tsv.\n",
      "Reading channel info from out_data\\sample_BIDS\\sub-01\\ses-01\\meg\\sub-01_ses-01_task-audiovisual_run-01_channels.tsv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Roaming\\Python\\Python37\\site-packages\\mne_bids\\read.py:406: RuntimeWarning: The unit for channel(s) STI 001, STI 002, STI 003, STI 004, STI 005, STI 006, STI 014, STI 015, STI 016 has changed from V to NA.\n",
      "  raw.set_channel_types(channel_type_dict)\n"
     ]
    }
   ],
   "source": [
    "bids_root = pathlib.Path('out_data/sample_BIDS')\n",
    "\n",
    "bids_path = mne_bids.BIDSPath(subject = '01',\n",
    "                             session = '01',\n",
    "                             task = 'audiovisual',\n",
    "                             run = '01',\n",
    "                             datatype = 'meg',\n",
    "                             root = bids_root)\n",
    "raw = mne_bids.read_raw_bids(bids_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MNEBrowseFigure size 1920x940 with 5 Axes>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels marked as bad: ['MEG 2443', 'EEG 053']\n"
     ]
    }
   ],
   "source": [
    "raw.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Events are stored as annotations - but we convert between the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('onset', 46.58058882905339),\n",
       "             ('duration', 0.0),\n",
       "             ('description', 'Auditory/Right'),\n",
       "             ('orig_time',\n",
       "              datetime.datetime(2002, 12, 3, 19, 1, 10, 720100, tzinfo=datetime.timezone.utc))])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.annotations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('onset', 280.8321518290534),\n",
       "             ('duration', 0.0),\n",
       "             ('description', 'Button'),\n",
       "             ('orig_time',\n",
       "              datetime.datetime(2002, 12, 3, 19, 1, 10, 720100, tzinfo=datetime.timezone.utc))])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.annotations[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m\n",
       "\u001b[0mmne\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevents_from_annotations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mraw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mevent_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'auto'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mregexp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'^(?![Bb][Aa][Dd]|[Ee][Dd][Gg][Ee]).*$'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0muse_rounding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mchunk_duration\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Get events and event_id from an Annotations object.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "raw : instance of Raw\n",
       "    The raw data for which Annotations are defined.\n",
       "event_id : dict | callable | None | 'auto'\n",
       "    Can be:\n",
       "\n",
       "    - **dict**: map descriptions (keys) to integer event codes (values).\n",
       "      Only the descriptions present will be mapped, others will be ignored.\n",
       "    - **callable**: must take a string input and return an integer event\n",
       "      code, or return ``None`` to ignore the event.\n",
       "    - **None**: Map descriptions to unique integer values based on their\n",
       "      ``sorted`` order.\n",
       "    - **'auto' (default)**: prefer a raw-format-specific parser:\n",
       "\n",
       "      - Brainvision: map stimulus events to their integer part; response\n",
       "        events to integer part + 1000; optic events to integer part + 2000;\n",
       "        'SyncStatus/Sync On' to 99998; 'New Segment/' to 99999;\n",
       "        all others like ``None`` with an offset of 10000.\n",
       "      - Other raw formats: Behaves like None.\n",
       "\n",
       "      .. versionadded:: 0.18\n",
       "regexp : str | None\n",
       "    Regular expression used to filter the annotations whose\n",
       "    descriptions is a match. The default ignores descriptions beginning\n",
       "    ``'bad'`` or ``'edge'`` (case-insensitive).\n",
       "\n",
       "    .. versionchanged:: 0.18\n",
       "       Default ignores bad and edge descriptions.\n",
       "use_rounding : bool\n",
       "    If True, use rounding (instead of truncation) when converting\n",
       "    times to indices. This can help avoid non-unique indices.\n",
       "chunk_duration : float | None\n",
       "    Chunk duration in seconds. If ``chunk_duration`` is set to None\n",
       "    (default), generated events correspond to the annotation onsets.\n",
       "    If not, :func:`mne.events_from_annotations` returns as many events as\n",
       "    they fit within the annotation duration spaced according to\n",
       "    ``chunk_duration``. As a consequence annotations with duration shorter\n",
       "    than ``chunk_duration`` will not contribute events.\n",
       "\n",
       "verbose : bool, str, int, or None\n",
       "    If not None, override default verbose level (see :func:`mne.verbose`\n",
       "    and :ref:`Logging documentation <tut_logging>` for more).\n",
       "    If used, it should be passed as a keyword-argument only.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "events : ndarray, shape (n_events, 3)\n",
       "    The events.\n",
       "event_id : dict\n",
       "    The event_id variable that can be passed to Epochs.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "mne.annotations_from_events\n",
       "\n",
       "Notes\n",
       "-----\n",
       "For data formats that store integer events as strings (e.g., NeuroScan\n",
       "``.cnt`` files), passing the Python built-in function :class:`int` as the\n",
       "``event_id`` parameter will do what most users probably want in those\n",
       "circumstances: return an ``event_id`` dictionary that maps event ``'1'`` to\n",
       "integer event code ``1``, ``'2'`` to ``2``, etc.\n",
       "\u001b[1;31mFile:\u001b[0m      d:\\anacondainstalled\\lib\\site-packages\\mne\\annotations.py\n",
       "\u001b[1;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mne.events_from_annotations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['Auditory/Left', 'Auditory/Right', 'Button', 'Smiley', 'Visual/Left', 'Visual/Right']\n"
     ]
    }
   ],
   "source": [
    "events, event_id = mne.events_from_annotations(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(320, 3)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x476 with 1 Axes>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mne.viz.plot_events(events, event_id = event_id, sfreq = raw.info['sfreq'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine the MEG fine-calibration and crosstalk files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('out_data/sample_BIDS/sub-01/ses-01/meg/sub-01_ses-01_acq-calibration_meg.dat')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bids_path.meg_calibration_fpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('out_data/sample_BIDS/sub-01/ses-01/meg/sub-01_ses-01_acq-crosstalk_meg.fif')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bids_path.meg_crosstalk_fpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
