{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23.0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import pathlib\n",
    "\n",
    "import mne\n",
    "print(mne.__version__)\n",
    "import mne_bids\n",
    "\n",
    "matplotlib.use('Qt5Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bids_root = pathlib.Path('data')\n",
    "\n",
    "# bids_path = mne_bids.BIDSPath(subject = 'AB6',\n",
    "#                              task = 'gonogo',\n",
    "#                              datatype = 'eeg',\n",
    "#                              root = bids_root,\n",
    "#                              run = '1')\n",
    "\n",
    "# bids_path = mne_bids.BIDSPath(subject = 'AB6',\n",
    "# #                              session = '1',\n",
    "#                              datatype = 'eeg',\n",
    "#                              run = '1',\n",
    "#                              task = 'gonogo',\n",
    "#                              root = bids_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path1 = pathlib.Path('data/sub-AB6/eeg/sub-AB6_task-gonogo_run-1_eeg.set')\n",
    "\n",
    "# raw = mne.io.read_raw_eeglab(path1)\n",
    "# raw.load_data()\n",
    "\n",
    "# events = mne.find_events(raw)\n",
    "# event_id = {\n",
    "#     'Auditory/Left': 1,\n",
    "#     'Auditory/Right': 2,\n",
    "#     'Visual/Left': 3,\n",
    "#     'Visual/Right': 4,\n",
    "#     'Smiley': 5,\n",
    "#     'Button': 32\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw = mne_bids.read_raw_bids(bids_path)\n",
    "# raw.load_data()\n",
    "# raw.data()\n",
    "# raw.filter(l_freq = 0.1, h_freq = 40)\n",
    "# events, event_id = mne.events_from_annotations(raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the data using EEGLAB module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawab6_1 = mne.io.read_raw_eeglab('data/sub-AB6/eeg/sub-AB6_task-gonogo_run-1_eeg.set', eog=(), preload=True, uint16_codec=None, verbose=None)\n",
    "rawab6_2 = mne.io.read_raw_eeglab('data/sub-AB6/eeg/sub-AB6_task-gonogo_run-2_eeg.set', eog=(), preload=True, uint16_codec=None, verbose=None)\n",
    "\n",
    "rawab10_1 = mne.io.read_raw_eeglab('data/other subjects set files/sub-AB10_eeg_sub-AB10_task-gonogo_run-1_eeg.set', eog=(), preload=True, uint16_codec=None, verbose=None)\n",
    "rawab10_2 = mne.io.read_raw_eeglab('data/other subjects set files/sub-AB10_eeg_sub-AB10_task-gonogo_run-2_eeg.set', eog=(), preload=True, uint16_codec=None, verbose=None)\n",
    "\n",
    "# rawab11_1 = mne.io.read_raw_eeglab('data/other subjects set files/sub-AB11_eeg_sub-AB11_task-gonogo_run-1_eeg.set', eog=(), preload=True, uint16_codec=None, verbose=None)\n",
    "# rawab11_2 = mne.io.read_raw_eeglab('data/other subjects set files/sub-AB11_eeg_sub-AB11_task-gonogo_run-2_eeg.set', eog=(), preload=True, uint16_codec=None, verbose=None)\n",
    "\n",
    "rawab12_1 = mne.io.read_raw_eeglab('data/other subjects set files/sub-AB12_eeg_sub-AB12_task-gonogo_run-1_eeg.set', eog=(), preload=True, uint16_codec=None, verbose=None)\n",
    "rawab12_2 = mne.io.read_raw_eeglab('data/other subjects set files/sub-AB12_eeg_sub-AB12_task-gonogo_run-2_eeg.set', eog=(), preload=True, uint16_codec=None, verbose=None)\n",
    "\n",
    "rawab13_1 = mne.io.read_raw_eeglab('data/other subjects set files/sub-AB13_eeg_sub-AB13_task-gonogo_run-1_eeg.set', eog=(), preload=True, uint16_codec=None, verbose=None)\n",
    "rawab13_2 = mne.io.read_raw_eeglab('data/other subjects set files/sub-AB13_eeg_sub-AB13_task-gonogo_run-2_eeg.set', eog=(), preload=True, uint16_codec=None, verbose=None)\n",
    "\n",
    "rawab28_1 = mne.io.read_raw_eeglab('data/other subjects set files/sub-AB28_eeg_sub-AB28_task-gonogo_run-1_eeg.set', eog=(), preload=True, uint16_codec=None, verbose=None)\n",
    "rawab28_2 = mne.io.read_raw_eeglab('data/other subjects set files/sub-AB28_eeg_sub-AB28_task-gonogo_run-2_eeg.set', eog=(), preload=True, uint16_codec=None, verbose=None)\n",
    "\n",
    "rawab31_1 = mne.io.read_raw_eeglab('data/other subjects set files/sub-AB31_eeg_sub-AB31_task-gonogo_run-1_eeg.set', eog=(), preload=True, uint16_codec=None, verbose=None)\n",
    "rawab31_2 = mne.io.read_raw_eeglab('data/other subjects set files/sub-AB31_eeg_sub-AB31_task-gonogo_run-2_eeg.set', eog=(), preload=True, uint16_codec=None, verbose=None)\n",
    "\n",
    "rawab32_1 = mne.io.read_raw_eeglab('data/other subjects set files/sub-AB32_eeg_sub-AB32_task-gonogo_run-1_eeg.set', eog=(), preload=True, uint16_codec=None, verbose=None)\n",
    "rawab32_2 = mne.io.read_raw_eeglab('data/other subjects set files/sub-AB32_eeg_sub-AB32_task-gonogo_run-2_eeg.set', eog=(), preload=True, uint16_codec=None, verbose=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MNEBrowseFigure size 1920x962 with 4 Axes>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels marked as bad: none\n",
      "Channels marked as bad: none\n",
      "Channels marked as bad: none\n",
      "Channels marked as bad: none\n"
     ]
    }
   ],
   "source": [
    "rawab6_1.plot()\n",
    "rawab10_1.plot()\n",
    "rawab12_1.plot()\n",
    "rawab13_1.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.5 - 60 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.50\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
      "- Upper passband edge: 60.00 Hz\n",
      "- Upper transition bandwidth: 15.00 Hz (-6 dB cutoff frequency: 67.50 Hz)\n",
      "- Filter length: 3301 samples (6.602 sec)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<MNEBrowseFigure size 1920x957 with 4 Axes>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels marked as bad: none\n"
     ]
    }
   ],
   "source": [
    "clean_ab12_1 = rawab12_1.copy().filter(0.5, 60)\n",
    "clean_ab12_1.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "The 64 eeg channels indices are:\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "66\n",
      "The 66 eeg channels indices are:\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65]\n"
     ]
    }
   ],
   "source": [
    "rawab13_2.info\n",
    "# rawab6_2.info\n",
    "channel_indices_ab6_1 = mne.pick_types(rawab6_1.info, eeg=True)\n",
    "channel_indices_ab13_1 = mne.pick_types(rawab13_1.info, eeg=True)\n",
    "print(len(channel_indices_ab6_1))\n",
    "print(f\"The {len(channel_indices_ab6_1)} eeg channels indices are:\\n{channel_indices_ab6_1}\")\n",
    "print(len(channel_indices_ab13_1))\n",
    "print(f\"The {len(channel_indices_ab13_1)} eeg channels indices are:\\n{channel_indices_ab13_1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eeg_indices = mne.pick_types(rawab13_1.info, meg=False, eeg=True)\n",
    "# reduced_info = mne.pick_info(rawab13_1.info, eeg_indices)\n",
    "# reduced_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the events for all Subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['1', '10', '2', '4', '5', '9']\n",
      "Used Annotations descriptions: ['1', '10', '2', '4', '5', '6', '7', '9']\n",
      "Used Annotations descriptions: ['1', '10', '11', '2', '3', '4', '5', '9']\n",
      "Used Annotations descriptions: ['1', '10', '2', '3', '4', '5', '9']\n",
      "Used Annotations descriptions: ['1', '10', '2', '4', '5', '6', '7', '9']\n",
      "Used Annotations descriptions: ['1', '10', '11', '2', '3', '4', '5', '6', '7', '9']\n",
      "Used Annotations descriptions: ['1', '10', '2', '3', '4', '5', '9']\n",
      "Used Annotations descriptions: ['1', '10', '11', '2', '4', '5', '6', '7', '9']\n",
      "Used Annotations descriptions: ['1', '10', '2', '4', '5', '6', '7', '9']\n",
      "Used Annotations descriptions: ['1', '10', '2', '3', '4', '5', '6', '7', '9']\n",
      "Used Annotations descriptions: ['1', '10', '2', '3', '4', '5', '9']\n",
      "Used Annotations descriptions: ['1', '10', '2', '3', '4', '5', '6', '7', '9']\n",
      "Used Annotations descriptions: ['1', '10', '11', '2', '3', '4', '5', '6', '7', '9']\n",
      "Used Annotations descriptions: ['1', '10', '2', '4', '5', '6', '7', '9']\n"
     ]
    }
   ],
   "source": [
    "eventsab6_1 = mne.events_from_annotations(rawab6_1)\n",
    "eventsab6_2 = mne.events_from_annotations(rawab6_2)\n",
    "\n",
    "eventsab10_1 = mne.events_from_annotations(rawab10_1)\n",
    "eventsab10_2 = mne.events_from_annotations(rawab10_2)\n",
    "\n",
    "eventsab12_1 = mne.events_from_annotations(rawab12_1)\n",
    "eventsab12_2 = mne.events_from_annotations(rawab12_2)\n",
    "\n",
    "eventsab13_1 = mne.events_from_annotations(rawab13_1)\n",
    "eventsab13_2 = mne.events_from_annotations(rawab13_2)\n",
    "\n",
    "eventsab28_1 = mne.events_from_annotations(rawab28_1)\n",
    "eventsab28_2 = mne.events_from_annotations(rawab28_2)\n",
    "\n",
    "eventsab31_1 = mne.events_from_annotations(rawab31_1)\n",
    "eventsab31_2 = mne.events_from_annotations(rawab31_2)\n",
    "\n",
    "eventsab32_1 = mne.events_from_annotations(rawab32_1)\n",
    "eventsab32_2 = mne.events_from_annotations(rawab32_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the event_id dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'taskstart': '9',\n",
       " 'cue': '1',\n",
       " 'go': '2',\n",
       " 'button press': '5',\n",
       " 'no-go': '4',\n",
       " 'task end': '10',\n",
       " 'error 1': '3',\n",
       " 'error 2': '6',\n",
       " 'error 3': '7',\n",
       " 'error 4': '8',\n",
       " 'error 5': '11'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_id = {\n",
    "    \"taskstart\" : '9',\n",
    "    \"cue\" : \"1\",\n",
    "    \"go\" : \"2\",\n",
    "    \"button press\" : \"5\",\n",
    "    \"no-go\" : \"4\",\n",
    "    \"task end\": \"10\",\n",
    "    \"error 1\" : \"3\",\n",
    "    \"error 2\" : \"6\",\n",
    "    \"error 3\" : \"7\",\n",
    "    \"error 4\" : \"8\",\n",
    "    \"error 5\" : \"11\"\n",
    "}\n",
    "event_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping unwanted channels from the various Subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "<table class=\"table table-hover\">\n",
       "    <tr>\n",
       "        <th>Measurement date</th>\n",
       "<td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Experimenter</th>\n",
       "<td>Unknown</td>\n",
       "    </tr>\n",
       "        <th>Participant</th>\n",
       "<td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Digitized points</th>\n",
       "        <td>66 points</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Good channels</th>\n",
       "        <td>0 magnetometer, 0 gradiometer,\n",
       "            and 61 EEG channels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Bad channels</th>\n",
       "        <td></td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>EOG channels</th>\n",
       "        <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>ECG channels</th>\n",
       "        <td>Not available</td>\n",
       "    <tr>\n",
       "        <th>Sampling frequency</th>\n",
       "        <td>500.00 Hz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Highpass</th>\n",
       "        <td>0.00 Hz</td>\n",
       "    </tr>\n",
       "     <tr>\n",
       "        <th>Lowpass</th>\n",
       "        <td>250.00 Hz</td>\n",
       "    </tr>\n",
       "\n",
       "    <tr>\n",
       "        <th>Filenames</th>\n",
       "        <td>sub-AB32_eeg_sub-AB32_task-gonogo_run-2_eeg.set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Duration</th>\n",
       "        <td>00:08:16 (HH:MM:SS)</td>\n",
       "    </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<RawEEGLAB | sub-AB32_eeg_sub-AB32_task-gonogo_run-2_eeg.set, 61 x 248300 (496.6 s), ~115.6 MB, data loaded>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawab6_1.drop_channels(ch_names = [\"EKG\", \"VEO\", \"HEO\"])\n",
    "rawab6_2.drop_channels(ch_names = [\"EKG\", \"VEO\", \"HEO\"])\n",
    "\n",
    "rawab10_1.drop_channels(ch_names = [\"EKG\", \"R-Dia-X-(mm)\", \"R-Dia-Y-(mm)\", \"VEO\", \"HEO\"])\n",
    "rawab10_2.drop_channels(ch_names = [\"EKG\", \"R-Dia-X-(mm)\", \"R-Dia-Y-(mm)\", \"VEO\", \"HEO\"])\n",
    "\n",
    "rawab12_1.drop_channels(ch_names = [\"EKG\", \"R-Dia-X-(mm)\", \"R-Dia-Y-(mm)\", \"VEO\", \"HEO\"])\n",
    "rawab12_2.drop_channels(ch_names = [\"EKG\", \"R-Dia-X-(mm)\", \"R-Dia-Y-(mm)\", \"VEO\", \"HEO\"])\n",
    "\n",
    "rawab13_1.drop_channels(ch_names = [\"EKG\", \"R-Dia-X-(mm)\", \"R-Dia-Y-(mm)\", \"VEO\", \"HEO\"])\n",
    "rawab13_2.drop_channels(ch_names = [\"EKG\", \"R-Dia-X-(mm)\", \"R-Dia-Y-(mm)\", \"VEO\", \"HEO\"])\n",
    "\n",
    "rawab28_1.drop_channels(ch_names = [\"EKG\", \"R-Dia-X-(mm)\", \"R-Dia-Y-(mm)\", \"VEO\", \"HEO\"])\n",
    "rawab28_2.drop_channels(ch_names = [\"EKG\", \"R-Dia-X-(mm)\", \"R-Dia-Y-(mm)\", \"VEO\", \"HEO\"])\n",
    "\n",
    "rawab31_1.drop_channels(ch_names = [\"EKG\", \"R-Dia-X-(mm)\", \"R-Dia-Y-(mm)\", \"VEO\", \"HEO\"])\n",
    "rawab31_2.drop_channels(ch_names = [\"EKG\", \"R-Dia-X-(mm)\", \"R-Dia-Y-(mm)\", \"VEO\", \"HEO\"])\n",
    "\n",
    "rawab32_1.drop_channels(ch_names = [\"EKG\", \"R-Dia-X-(mm)\", \"R-Dia-Y-(mm)\", \"VEO\", \"HEO\"])\n",
    "rawab32_2.drop_channels(ch_names = [\"EKG\", \"R-Dia-X-(mm)\", \"R-Dia-Y-(mm)\", \"VEO\", \"HEO\"])\n",
    "\n",
    "# rawab14_1.drop_channels(ch_names = [\"EKG\", \"R-Dia-X-(mm)\", \"R-Dia-Y-(mm)\"])\n",
    "# rawab14_2.drop_channels(ch_names = [\"EKG\", \"R-Dia-X-(mm)\", \"R-Dia-Y-(mm)\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting 2D and 3D positions of the 63 Sensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawab6_1.plot_sensors(ch_type = 'eeg', sphere = 10);\n",
    "# rawab6_2.plot_sensors(ch_type = 'eeg', sphere = 10);\n",
    "\n",
    "rawab10_1.plot_sensors(ch_type = 'eeg', sphere = 10);\n",
    "# rawab10_2.plot_sensors(ch_type = 'eeg', sphere = 10);\n",
    "\n",
    "rawab12_1.plot_sensors(ch_type = 'eeg', sphere = 10);\n",
    "# rawab12_2.plot_sensors(ch_type = 'eeg', sphere = 10);\n",
    "\n",
    "rawab13_1.plot_sensors(ch_type = 'eeg', sphere = 10);\n",
    "# rawab13_2.plot_sensors(ch_type = 'eeg', sphere = 10);\n",
    "\n",
    "rawab28_1.plot_sensors(ch_type = 'eeg', sphere = 10);\n",
    "# rawab28_2.plot_sensors(ch_type = 'eeg', sphere = 10);\n",
    "\n",
    "rawab31_1.plot_sensors(ch_type = 'eeg', sphere = 10);\n",
    "# rawab31_2.plot_sensors(ch_type = 'eeg', sphere = 10);\n",
    "\n",
    "rawab32_1.plot_sensors(ch_type = 'eeg', sphere = 10);\n",
    "# rawab32_2.plot_sensors(ch_type = 'eeg', sphere = 10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawab6_1.plot_sensors(ch_type = 'eeg', kind = '3d');\n",
    "# rawab6_2.plot_sensors(ch_type = 'eeg', kind = '3d');\n",
    "\n",
    "rawab10_1.plot_sensors(ch_type = 'eeg', kind = '3d');\n",
    "# rawab10_2.plot_sensors(ch_type = 'eeg', kind = '3d');\n",
    "\n",
    "rawab12_1.plot_sensors(ch_type = 'eeg', kind = '3d');\n",
    "# rawab12_2.plot_sensors(ch_type = 'eeg', kind = '3d');\n",
    "\n",
    "rawab13_1.plot_sensors(ch_type = 'eeg', kind = '3d');\n",
    "# rawab13_2.plot_sensors(ch_type = 'eeg', kind = '3d');\n",
    "\n",
    "rawab28_1.plot_sensors(ch_type = 'eeg', kind = '3d');\n",
    "# rawab28_2.plot_sensors(ch_type = 'eeg', kind = '3d');\n",
    "\n",
    "rawab31_1.plot_sensors(ch_type = 'eeg', kind = '3d');\n",
    "# rawab31_2.plot_sensors(ch_type = 'eeg', kind = '3d');\n",
    "\n",
    "rawab32_1.plot_sensors(ch_type = 'eeg', kind = '3d');\n",
    "# rawab32_2.plot_sensors(ch_type = 'eeg', kind = '3d');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rawab6_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rawab6_1.plot_sensors(ch_type = 'eeg', sphere = 10)\n",
    "# rawab6_2.plot_sensors(ch_type = 'eeg', sphere = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing ICA and SSP Projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-1497dd8d8761>:1: DeprecationWarning: Version 0.23 introduced max_iter=\"auto\", setting max_iter=1000 for `fastica` and max_iter=500 for `infomax` and `picard`. The current default of max_iter=200 will be changed to \"auto\" in version 0.24.\n",
      "  ica = mne.preprocessing.ICA(n_components = 20, random_state = 42)\n"
     ]
    }
   ],
   "source": [
    "ica = mne.preprocessing.ICA(n_components = 20, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica.exclude = [11, 14, 19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_ab6_1 = ica.apply(rawab6_1.copy().filter(1, 50), exclude = ica.exclude)\n",
    "# clean_ab6_2 = ica.apply(rawab6_2.copy().filter(1, 50), exclude = ica.exclude)\n",
    "# clean_ab6_1.plot();\n",
    "# clean_ab6_2.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-56-1497dd8d8761>:1: DeprecationWarning: Version 0.23 introduced max_iter=\"auto\", setting max_iter=1000 for `fastica` and max_iter=500 for `infomax` and `picard`. The current default of max_iter=200 will be changed to \"auto\" in version 0.24.\n",
      "  ica = mne.preprocessing.ICA(n_components = 20, random_state = 42)\n"
     ]
    }
   ],
   "source": [
    "ica = mne.preprocessing.ICA(n_components = 20, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 8 - 35 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 8.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 7.00 Hz)\n",
      "- Upper passband edge: 35.00 Hz\n",
      "- Upper transition bandwidth: 8.75 Hz (-6 dB cutoff frequency: 39.38 Hz)\n",
      "- Filter length: 825 samples (1.650 sec)\n",
      "\n",
      "Fitting ICA to data using 63 channels (please be patient, this may take a while)\n",
      "Selecting by number: 20 components\n",
      "Fitting ICA took 12.4s.\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 8 - 35 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 8.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 7.00 Hz)\n",
      "- Upper passband edge: 35.00 Hz\n",
      "- Upper transition bandwidth: 8.75 Hz (-6 dB cutoff frequency: 39.38 Hz)\n",
      "- Filter length: 825 samples (1.650 sec)\n",
      "\n",
      "Fitting ICA to data using 63 channels (please be patient, this may take a while)\n",
      "Selecting by number: 20 components\n",
      "Fitting ICA took 8.6s.\n"
     ]
    }
   ],
   "source": [
    "cleaned_ab6_1 = ica.fit(rawab6_1.copy().filter(8, 35))\n",
    "cleaned_ab6_2 = ica.fit(rawab6_2.copy().filter(8, 35))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<MNEFigure size 975x963 with 20 Axes>]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ica.plot_components(outlines = 'head', sphere = 10, ch_type = 'eeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ICA' object has no attribute 'plot'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-70f1ef83ca8c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcleaned_ab6_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mcleaned_ab6_2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ICA' object has no attribute 'plot'"
     ]
    }
   ],
   "source": [
    "cleaned_ab6_1.plot();\n",
    "cleaned_ab6_2.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MNEFigure size 750x220 with 5 Axes>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evoked2.plot_topomap(ch_type = 'eeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ecg_projs, ecg_events = mne.preprocessing.compute_proj_ecg(rawab6_1, n_grad = 1, n_mag = 1, n_eeg = 0,\n",
    "#                                                            average = True)\n",
    "# eog_projs, eog_events = mne.preprocessing.compute_proj_eog(raw, n_grad = 1, n_mag = 1, n_eeg = 0,\n",
    "#                                                            average = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Epochs of data for different Subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(ica.plot_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': 1, '10': 2, '11': 3, '2': 4, '3': 5, '4': 6, '5': 7, '9': 8}\n"
     ]
    }
   ],
   "source": [
    "print(eventsab10_1[1])\n",
    "# print(eventsab6_1[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4968,     0,     8],\n",
       "       [ 7636,     0,     1],\n",
       "       [ 8707,     0,     4],\n",
       "       [ 8892,     0,     7],\n",
       "       [11940,     0,     1],\n",
       "       [12807,     0,     4],\n",
       "       [13123,     0,     7],\n",
       "       [15497,     0,     1],\n",
       "       [16752,     0,     4],\n",
       "       [17075,     0,     7]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eventsab10_1[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "Not setting metadata\n",
      "152 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "152 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "155 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "153 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "154 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "158 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "153 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "156 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "154 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "157 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "155 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "159 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "167 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "154 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Loading data for 152 events and 351 original time points ...\n",
      "0 bad epochs dropped\n",
      "Loading data for 152 events and 351 original time points ...\n",
      "Loading data for 20 events and 351 original time points ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<MNEBrowseFigure size 1920x953 with 4 Axes>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochsab6_1 = mne.Epochs(rawab6_1,\n",
    "                   events = eventsab6_1[0],\n",
    "                   event_id = eventsab6_1[1],\n",
    "                   )\n",
    "epochsab6_2 = mne.Epochs(rawab6_2,\n",
    "                   events = eventsab6_1[0],\n",
    "                   event_id = eventsab6_1[1],)\n",
    "\n",
    "epochsab10_1 = mne.Epochs(rawab10_1,\n",
    "                   events = eventsab10_1[0],\n",
    "                   event_id = eventsab10_1[1],)\n",
    "epochsab10_2 = mne.Epochs(rawab10_2,\n",
    "                   events = eventsab10_2[0],\n",
    "                   event_id = eventsab10_2[1],)\n",
    "\n",
    "epochsab12_1 = mne.Epochs(rawab12_1,\n",
    "                   events = eventsab12_1[0],\n",
    "                   event_id = eventsab12_1[1],)\n",
    "epochsab12_2 = mne.Epochs(rawab12_2,\n",
    "                   events = eventsab12_2[0],\n",
    "                   event_id = eventsab12_2[1],)\n",
    "\n",
    "epochsab13_1 = mne.Epochs(rawab13_1,\n",
    "                   events = eventsab13_1[0],\n",
    "                   event_id = eventsab13_1[1],)\n",
    "epochsab13_2 = mne.Epochs(rawab13_2,\n",
    "                   events = eventsab13_2[0],\n",
    "                   event_id = eventsab13_2[1],)\n",
    "\n",
    "epochsab28_1 = mne.Epochs(rawab28_1,\n",
    "                   events = eventsab28_1[0],\n",
    "                   event_id = eventsab28_1[1],)\n",
    "epochsab28_2 = mne.Epochs(rawab28_2,\n",
    "                   events = eventsab28_2[0],\n",
    "                   event_id = eventsab28_2[1],)\n",
    "\n",
    "epochsab31_1 = mne.Epochs(rawab31_1,\n",
    "                   events = eventsab31_1[0],\n",
    "                   event_id = eventsab31_1[1],)\n",
    "epochsab31_2 = mne.Epochs(rawab31_2,\n",
    "                   events = eventsab31_2[0],\n",
    "                   event_id = eventsab31_2[1],)\n",
    "\n",
    "epochsab32_1 = mne.Epochs(rawab32_1,\n",
    "                   events = eventsab32_1[0],\n",
    "                   event_id = eventsab32_1[1],)\n",
    "epochsab32_2 = mne.Epochs(rawab32_2,\n",
    "                   events = eventsab32_2[0],\n",
    "                   event_id = eventsab32_2[1],)\n",
    "\n",
    "epochsab6_1.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev_epochsab6_1 = epochsab6_1.events\n",
    "# ev_epochsab6_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_keys_from_value(d, val):\n",
    "#     return [k for k, v in d.items() if v == val]\n",
    "\n",
    "# def replace(dataevents2, dataevents1):\n",
    "#     len = dataevents2.shape[0];\n",
    "#     for i in range(len):\n",
    "#         dataevents2[i][2] = int(get_keys_from_value(dataevents1[1], dataevents2[i][2])[0]);\n",
    "#     return dataevents2;\n",
    "\n",
    "#Changing event indicators(ex. 6 becomes 9)\n",
    "def get_keys_from_value(d, val):\n",
    "    return [k for k, v in d.items() if v == val]\n",
    "def fix_event_ids(epochsab, eventsab):\n",
    "    for i in range(epochsab.events.shape[0]):\n",
    "        epochsab.events[i][2] = int(get_keys_from_value(eventsab[1], epochsab.events[i][2])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(epochsab6_1.shape[0]):\n",
    "#     ev_epochsab6_1[i][2] = int(get_keys_from_value(eventsab6_1[1], ev_epochsab6_1[i][2])[0])\n",
    "fix_event_ids(epochsab6_1, eventsab6_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_event_ids(epochsab10_1, eventsab10_1)\n",
    "fix_event_ids(epochsab12_1, eventsab12_1)\n",
    "fix_event_ids(epochsab13_1, eventsab13_1)\n",
    "fix_event_ids(epochsab28_1, eventsab28_1)\n",
    "fix_event_ids(epochsab31_1, eventsab31_1)\n",
    "fix_event_ids(epochsab32_1, eventsab32_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_event_ids(epochsab10_2, eventsab10_2)\n",
    "fix_event_ids(epochsab12_2, eventsab12_2)\n",
    "fix_event_ids(epochsab13_2, eventsab13_2)\n",
    "fix_event_ids(epochsab28_2, eventsab28_2)\n",
    "fix_event_ids(epochsab31_2, eventsab31_2)\n",
    "fix_event_ids(epochsab32_2, eventsab32_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2398,     0,     9],\n",
       "       [ 5066,     0,     1],\n",
       "       [ 5914,     0,     2],\n",
       "       [ 6065,     0,     5],\n",
       "       [ 8825,     0,     1],\n",
       "       [ 9622,     0,     2],\n",
       "       [ 9751,     0,     5],\n",
       "       [13972,     0,     1],\n",
       "       [17720,     0,     1],\n",
       "       [18495,     0,     2]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochsab28_2.events[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<table class=\"table table-hover\">\n",
       "    <tr>\n",
       "        <th>Number of events</th>\n",
       "        <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Events</th>\n",
       "        <td>1: 60<br>10: 40<br>2: 0<br>4: 10<br>5: 40<br>9: 0<br></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Time range</th>\n",
       "        <td>-0.200 – 0.500 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Baseline</th>\n",
       "        <td>-0.200 – 0.000 sec</td>\n",
       "    </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<Epochs |  152 events (all good), -0.2 - 0.5 sec, baseline -0.2 – 0 sec, ~86 kB, data not loaded,\n",
       " '1': 60\n",
       " '10': 40\n",
       " '2': 0\n",
       " '4': 10\n",
       " '5': 40\n",
       " '9': 0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochsab6_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<table class=\"table table-hover\">\n",
       "    <tr>\n",
       "        <th>Number of events</th>\n",
       "        <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Events</th>\n",
       "        <td>1: 60<br>10: 40<br>11: 2<br>2: 10<br>3: 40<br>4: 0<br>5: 0<br>9: 0<br></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Time range</th>\n",
       "        <td>-0.200 – 0.500 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Baseline</th>\n",
       "        <td>-0.200 – 0.000 sec</td>\n",
       "    </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<Epochs |  155 events (good & bad), -0.2 - 0.5 sec, baseline -0.2 – 0 sec, ~87 kB, data not loaded,\n",
       " '1': 60\n",
       " '10': 40\n",
       " '11': 2\n",
       " '2': 10\n",
       " '3': 40\n",
       " '4': 0\n",
       " '5': 0\n",
       " '9': 0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochsab10_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rawab6_1 = ica.apply(rawab6_1.copy().filter(1, 50), exclude = ica.exclude)\n",
    "# raw_m.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evoked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 0 epochs: \n",
      "Channels marked as bad: none\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x296 with 1 Axes>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# target_ab6_1 = epochsab6_1[\"target\"].average()\n",
    "target = epochsab6_1[0].average()\n",
    "target.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<table class=\"table table-hover\">\n",
       "    <tr>\n",
       "        <th>Number of events</th>\n",
       "        <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Events</th>\n",
       "        <td>1: 60<br>10: 1<br>2: 40<br>4: 10<br>5: 40<br>9: 1<br></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Time range</th>\n",
       "        <td>-0.200 – 0.500 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Baseline</th>\n",
       "        <td>-0.200 – 0.000 sec</td>\n",
       "    </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<Epochs |  152 events (all good), -0.2 - 0.5 sec, baseline -0.2 – 0 sec, ~88 kB, data not loaded,\n",
       " '1': 60\n",
       " '10': 1\n",
       " '2': 40\n",
       " '4': 10\n",
       " '5': 40\n",
       " '9': 1>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochsab6_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x296 with 2 Axes>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evoked1 = epochsab6_1['10'].copy().average()\n",
    "evoked2 = epochsab6_2.copy().average()\n",
    "\n",
    "evoked1.plot(spatial_colors = True)\n",
    "# evoked2.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Evoked | '10' (average, N=1), -0.2 – 0.5 sec, baseline -0.2 – 0 sec, 63 ch, ~261 kB>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evoked1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Machine Learning Models for classification purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Softmax\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for 152 events and 351 original time points ...\n",
      "(152, 61, 351)\n",
      "Loading data for 152 events and 351 original time points ...\n",
      "0 bad epochs dropped\n",
      "(152, 61, 351)\n",
      "Loading data for 155 events and 351 original time points ...\n",
      "0 bad epochs dropped\n",
      "(155, 61, 351)\n",
      "Loading data for 153 events and 351 original time points ...\n",
      "0 bad epochs dropped\n",
      "(153, 61, 351)\n",
      "Loading data for 154 events and 351 original time points ...\n",
      "0 bad epochs dropped\n",
      "(154, 61, 351)\n",
      "Loading data for 158 events and 351 original time points ...\n",
      "0 bad epochs dropped\n",
      "(158, 61, 351)\n",
      "Loading data for 153 events and 351 original time points ...\n",
      "0 bad epochs dropped\n",
      "(153, 61, 351)\n",
      "Loading data for 156 events and 351 original time points ...\n",
      "0 bad epochs dropped\n",
      "(156, 61, 351)\n",
      "Loading data for 154 events and 351 original time points ...\n",
      "0 bad epochs dropped\n",
      "(154, 61, 351)\n",
      "Loading data for 157 events and 351 original time points ...\n",
      "0 bad epochs dropped\n",
      "(157, 61, 351)\n",
      "Loading data for 155 events and 351 original time points ...\n",
      "0 bad epochs dropped\n",
      "(155, 61, 351)\n",
      "Loading data for 159 events and 351 original time points ...\n",
      "0 bad epochs dropped\n",
      "(159, 61, 351)\n",
      "Loading data for 167 events and 351 original time points ...\n",
      "0 bad epochs dropped\n",
      "(167, 61, 351)\n",
      "Loading data for 154 events and 351 original time points ...\n",
      "0 bad epochs dropped\n",
      "(154, 61, 351)\n",
      "(2179, 61, 351)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2179, 351, 61)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs_copyab6_1 = epochsab6_1.copy()\n",
    "dataab6_1 = epochs_copyab6_1.get_data()\n",
    "print(dataab6_1.shape)\n",
    "epochs_copyab6_2 = epochsab6_2.copy()\n",
    "dataab6_2 = epochs_copyab6_2.get_data()\n",
    "print(dataab6_2.shape)\n",
    "\n",
    "epochs_copyab10_1 = epochsab10_1.copy()\n",
    "dataab10_1 = epochs_copyab10_1.get_data()\n",
    "print(dataab10_1.shape)\n",
    "epochs_copyab10_2 = epochsab10_2.copy()\n",
    "dataab10_2 = epochs_copyab10_2.get_data()\n",
    "print(dataab10_2.shape)\n",
    "\n",
    "epochs_copyab12_1 = epochsab12_1.copy()\n",
    "dataab12_1 = epochs_copyab12_1.get_data()\n",
    "print(dataab12_1.shape)\n",
    "epochs_copyab12_2 = epochsab12_2.copy()\n",
    "dataab12_2 = epochs_copyab12_2.get_data()\n",
    "print(dataab12_2.shape)\n",
    "\n",
    "epochs_copyab13_1 = epochsab13_1.copy()\n",
    "dataab13_1 = epochs_copyab13_1.get_data()\n",
    "print(dataab13_1.shape)\n",
    "epochs_copyab13_2 = epochsab13_2.copy()\n",
    "dataab13_2 = epochs_copyab13_2.get_data()\n",
    "print(dataab13_2.shape)\n",
    "\n",
    "epochs_copyab28_1 = epochsab28_1.copy()\n",
    "dataab28_1 = epochs_copyab28_1.get_data()\n",
    "print(dataab28_1.shape)\n",
    "epochs_copyab28_2 = epochsab28_2.copy()\n",
    "dataab28_2 = epochs_copyab28_2.get_data()\n",
    "print(dataab28_2.shape)\n",
    "\n",
    "epochs_copyab31_1 = epochsab31_1.copy()\n",
    "dataab31_1 = epochs_copyab31_1.get_data()\n",
    "print(dataab31_1.shape)\n",
    "epochs_copyab31_2 = epochsab31_2.copy()\n",
    "dataab31_2 = epochs_copyab31_2.get_data()\n",
    "print(dataab31_2.shape)\n",
    "\n",
    "epochs_copyab32_1 = epochsab32_1.copy()\n",
    "dataab32_1 = epochs_copyab32_1.get_data()\n",
    "print(dataab32_1.shape)\n",
    "epochs_copyab32_2 = epochsab32_2.copy()\n",
    "dataab32_2 = epochs_copyab32_2.get_data()\n",
    "print(dataab32_2.shape)\n",
    "\n",
    "\n",
    "data = np.concatenate([dataab6_1, dataab6_2,\n",
    "                      dataab10_1, dataab10_2,\n",
    "                      dataab12_1, dataab12_2,\n",
    "                      dataab13_1, dataab13_2,\n",
    "                      dataab28_1, dataab28_2,\n",
    "                      dataab31_1, dataab31_2,\n",
    "                      dataab32_1, dataab32_2], \n",
    "                      axis = 0)\n",
    "print(data.shape)\n",
    "\n",
    "#Changing the shape of data from (events, channel, time points) to (events, time points, channel)\n",
    "datars = np.zeros((data.shape[0], data.shape[2], data.shape[1]))\n",
    "for i in range(datars.shape[0]):\n",
    "    datars[i] = np.transpose(data[i])\n",
    "datars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2179, 21411)\n"
     ]
    }
   ],
   "source": [
    "n_trials = data.shape[0]\n",
    "data = data.reshape(n_trials, -1)\n",
    "print(data.shape)\n",
    "dims_ip = data.shape[1]\n",
    "# dims_ip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(152, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  979,     0,     9],\n",
       "       [ 3641,     0,     1],\n",
       "       [ 4532,     0,     2],\n",
       "       [ 4704,     0,     5],\n",
       "       [ 7453,     0,     1],\n",
       "       [ 8513,     0,     2],\n",
       "       [ 8663,     0,     5],\n",
       "       [11543,     0,     1],\n",
       "       [12343,     0,     2],\n",
       "       [12591,     0,     5]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(epochsab6_1.events.shape)\n",
    "epochsab6_1.events[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(155,)\n",
      "(115,)\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "9\n",
      "10\n",
      "11\n",
      "None\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "yab6_1 = epochsab6_1.events[:, 2]\n",
    "yab6_2 = epochsab6_2.events[:, 2]\n",
    "\n",
    "yab10_1 = epochsab10_1.events[:, 2]\n",
    "yab10_2 = epochsab10_2.events[:, 2]\n",
    "\n",
    "yab12_1 = epochsab12_1.events[:, 2]\n",
    "yab12_2 = epochsab12_2.events[:, 2]\n",
    "\n",
    "yab13_1 = epochsab13_1.events[:, 2]\n",
    "yab13_2 = epochsab13_2.events[:, 2]\n",
    "\n",
    "yab28_1 = epochsab28_1.events[:, 2]\n",
    "yab28_2 = epochsab28_2.events[:, 2]\n",
    "\n",
    "yab31_1 = epochsab31_1.events[:, 2]\n",
    "yab31_2 = epochsab31_2.events[:, 2]\n",
    "\n",
    "yab32_1 = epochsab32_1.events[:, 2]\n",
    "yab32_2 = epochsab32_2.events[:, 2]\n",
    "\n",
    "y = np.concatenate([yab6_1, yab6_2,\n",
    "                   yab10_1, yab10_2,\n",
    "                   yab12_1, yab12_2,\n",
    "                   yab13_1, yab13_2,\n",
    "                   yab28_1, yab28_2,\n",
    "                   yab31_1, yab31_2,\n",
    "                   yab32_1, yab32_2],\n",
    "                   axis = 0)\n",
    "\n",
    "def unique(list1):\n",
    "    # insert the list to the set\n",
    "    list_set = set(list1)\n",
    "    # convert the set to the list\n",
    "    unique_list = (list(list_set))\n",
    "    for x in unique_list:\n",
    "        print(x);\n",
    "        \n",
    "#6: task start\n",
    "#2: task end\n",
    "#{'1': 1(cue), '10': 2(task end), '2': 3(go), '4': 4(no-go), '5': 5(button press), '9': 6(task start)}\n",
    "#\n",
    "#\n",
    "#\n",
    "\n",
    "# print(y.shape)\n",
    "# print(unique(y))\n",
    "\n",
    "y_copy = yab10_1.copy()\n",
    "print(y_copy.shape)\n",
    "y_copy = y_copy[y_copy[:]!=6]\n",
    "y_copy = y_copy[y_copy[:]!=2]\n",
    "\n",
    "# print(unique(y_copy))\n",
    "# y_copy[:15]\n",
    "print(y_copy.shape)\n",
    "# unique(yab6_1)\n",
    "\n",
    "# num_classes = 11\n",
    "# y = tf.keras.utils.to_categorical(y, num_classes)\n",
    "# y[:5]\n",
    "# yab6_1[0]\n",
    "\n",
    "print(unique(yab10_1))\n",
    "\n",
    "\n",
    "j = 0;\n",
    "for i in range(len(yab10_1)):\n",
    "    if (yab10_1[i] == 2):\n",
    "        j = j + 1;\n",
    "print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2179, 351, 61)\n",
      "(2179, 1)\n",
      "(2179, 21412)\n"
     ]
    }
   ],
   "source": [
    "y = y.reshape(-1, 1)\n",
    "# y = y[...,np.newaxis]\n",
    "datarscopy = datars.copy()\n",
    "datarscopy = datarscopy.reshape(datars.shape[0], -1)\n",
    "\n",
    "print(datars.shape)\n",
    "print(y.shape)\n",
    "dataset = np.concatenate((datarscopy, y), axis = 1)\n",
    "print(dataset.shape)\n",
    "\n",
    "# y_copy = y.copy()\n",
    "# X_copy = data.copy()\n",
    "# X_copy = X_copy[y_copy[:]!=9]\n",
    "# X_copy = X_copy[y_copy[:]!=10]\n",
    "# X_copy = X_copy[y_copy[:]!=3]\n",
    "# X_copy = X_copy[y_copy[:]!=6]\n",
    "# X_copy = X_copy[y_copy[:]!=7]\n",
    "# X_copy = X_copy[y_copy[:]!=8]\n",
    "# X_copy = X_copy[y_copy[:]!=11]\n",
    "\n",
    "# y_copy = y.copy()\n",
    "# y_copy = y_copy[y_copy[:]!=9]\n",
    "# y_copy = y_copy[y_copy[:]!=10]\n",
    "# y_copy = y_copy[y_copy[:]!=3]\n",
    "# y_copy = y_copy[y_copy[:]!=6]\n",
    "# y_copy = y_copy[y_copy[:]!=7]\n",
    "# y_copy = y_copy[y_copy[:]!=8]\n",
    "# y_copy = y_copy[y_copy[:]!=11]\n",
    "\n",
    "\n",
    "# print(y_copy.shape)\n",
    "# print(unique(y_copy))\n",
    "# unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2179, 21411)\n",
      "(2179,)\n"
     ]
    }
   ],
   "source": [
    "x = dataset[:, :-1]\n",
    "y = dataset[:, -1]\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2179, 21412)\n",
      "(2058, 21412)\n",
      "(2058, 21411)\n",
      "(2058,)\n",
      "1.0\n",
      "2.0\n",
      "4.0\n",
      "5.0\n"
     ]
    }
   ],
   "source": [
    "datasetcopy = dataset.copy()\n",
    "print(datasetcopy.shape)\n",
    "datasetcopy = datasetcopy[datasetcopy[:, -1]!=9]\n",
    "datasetcopy = datasetcopy[datasetcopy[:, -1]!=10]\n",
    "\n",
    "datasetcopy = datasetcopy[datasetcopy[:, -1]!=3]\n",
    "datasetcopy = datasetcopy[datasetcopy[:, -1]!=6]\n",
    "datasetcopy = datasetcopy[datasetcopy[:, -1]!=7]\n",
    "datasetcopy = datasetcopy[datasetcopy[:, -1]!=8]\n",
    "datasetcopy = datasetcopy[datasetcopy[:, -1]!=11]\n",
    "\n",
    "print(datasetcopy.shape)\n",
    "\n",
    "\n",
    "xcopy = datasetcopy[:, :-1]\n",
    "ycopy = datasetcopy[:, -1]\n",
    "print(xcopy.shape)\n",
    "print(ycopy.shape)\n",
    "unique(ycopy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = 6\n",
    "ycopy = tf.keras.utils.to_categorical(ycopy, num_classes)\n",
    "ycopy[:5]\n",
    "# yab6_1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\anacondainstalled\\lib\\site-packages\\tensorflow\\python\\keras\\initializers.py:143: calling RandomNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From D:\\anacondainstalled\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "inp_shape = (dims_ip, )\n",
    "ip = tf.keras.Input(shape = inp_shape)\n",
    "dense1 = tf.keras.layers.Dense(units = 32, activation = 'relu', kernel_initializer = 'random_normal')(ip)\n",
    "dense2 = tf.keras.layers.Dense(units = 16, activation = 'relu', kernel_initializer = 'random_normal')(dense1)\n",
    "out = tf.keras.layers.Dense(num_classes, activation = 'softmax')(dense2)\n",
    "\n",
    "model = tf.keras.Model(inputs = ip, outputs = out)\n",
    "\n",
    "# inp_shape = (None, )\n",
    "# review_sequence = tf.keras.Input(shape = inp_shape)\n",
    "# embedding_sequence = tf.keras.layers.Embedding(input_dim=100+1, output_dim=32, input_shape=(review_sequence.shape), mask_zero=False)(review_sequence)\n",
    "# average_embedding = tf.keras.layers.GlobalAveragePooling1D()(embedding_sequence)\n",
    "# positive_probability = tf.keras.layers.Dense(units=1, activation='sigmoid')(average_embedding)\n",
    "\n",
    "# model = tf.keras.Model(inputs = review_sequence, outputs = positive_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 21411)]           0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                685184    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 102       \n",
      "=================================================================\n",
      "Total params: 685,814\n",
      "Trainable params: 685,814\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt = Adam(0.001)\n",
    "\n",
    "earlystop = EarlyStopping(patience = 50, min_delta = 0.0001, monitor = 'acc')\n",
    "\n",
    "path = 'model_checkpoint/checkpoint_{epoch:02d}';\n",
    "model_checkpoint = ModelCheckpoint(filepath = path,\n",
    "                            verbose = 1,\n",
    "                            monitor = 'acc',\n",
    "                            save_freq = 'epoch',\n",
    "                            save_best_only = True,\n",
    "                            save_weights_only = True)\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', metrics = ['accuracy'], optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 1.6982 - acc: 0.4077\n",
      "Epoch 00001: acc improved from -inf to 0.40865, saving model to model_checkpoint/checkpoint_01\n",
      "2058/2058 [==============================] - 2s 1ms/sample - loss: 1.6972 - acc: 0.4086\n",
      "Epoch 2/100\n",
      "1984/2058 [===========================>..] - ETA: 0s - loss: 1.4252 - acc: 0.4052\n",
      "Epoch 00002: acc did not improve from 0.40865\n",
      "2058/2058 [==============================] - 1s 526us/sample - loss: 1.4208 - acc: 0.4082\n",
      "Epoch 3/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 1.3035 - acc: 0.4077\n",
      "Epoch 00003: acc did not improve from 0.40865\n",
      "2058/2058 [==============================] - 1s 554us/sample - loss: 1.3034 - acc: 0.4082\n",
      "Epoch 4/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 1.2822 - acc: 0.4082\n",
      "Epoch 00004: acc did not improve from 0.40865\n",
      "2058/2058 [==============================] - 1s 669us/sample - loss: 1.2816 - acc: 0.4082\n",
      "Epoch 5/100\n",
      "1984/2058 [===========================>..] - ETA: 0s - loss: 1.2710 - acc: 0.4093\n",
      "Epoch 00005: acc did not improve from 0.40865\n",
      "2058/2058 [==============================] - 1s 604us/sample - loss: 1.2698 - acc: 0.4082\n",
      "Epoch 6/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 1.2648 - acc: 0.4072\n",
      "Epoch 00006: acc did not improve from 0.40865\n",
      "2058/2058 [==============================] - 1s 568us/sample - loss: 1.2638 - acc: 0.4082\n",
      "Epoch 7/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 1.2604 - acc: 0.4077\n",
      "Epoch 00007: acc did not improve from 0.40865\n",
      "2058/2058 [==============================] - 1s 491us/sample - loss: 1.2597 - acc: 0.4082\n",
      "Epoch 8/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 1.2557 - acc: 0.4072- ETA: 0s - loss: 1.2466 - \n",
      "Epoch 00008: acc did not improve from 0.40865\n",
      "2058/2058 [==============================] - 1s 534us/sample - loss: 1.2561 - acc: 0.4082\n",
      "Epoch 9/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 1.2547 - acc: 0.4082\n",
      "Epoch 00009: acc did not improve from 0.40865\n",
      "2058/2058 [==============================] - 1s 532us/sample - loss: 1.2541 - acc: 0.4082\n",
      "Epoch 10/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 1.2526 - acc: 0.4082\n",
      "Epoch 00010: acc did not improve from 0.40865\n",
      "2058/2058 [==============================] - 1s 560us/sample - loss: 1.2529 - acc: 0.4082\n",
      "Epoch 11/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 1.2539 - acc: 0.4058\n",
      "Epoch 00011: acc did not improve from 0.40865\n",
      "2058/2058 [==============================] - 1s 643us/sample - loss: 1.2523 - acc: 0.4082\n",
      "Epoch 12/100\n",
      "1984/2058 [===========================>..] - ETA: 0s - loss: 1.2525 - acc: 0.4068\n",
      "Epoch 00012: acc did not improve from 0.40865\n",
      "2058/2058 [==============================] - 1s 526us/sample - loss: 1.2504 - acc: 0.4082\n",
      "Epoch 13/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 1.2497 - acc: 0.4087\n",
      "Epoch 00013: acc did not improve from 0.40865\n",
      "2058/2058 [==============================] - 1s 577us/sample - loss: 1.2502 - acc: 0.4082\n",
      "Epoch 14/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 1.2508 - acc: 0.4043\n",
      "Epoch 00014: acc did not improve from 0.40865\n",
      "2058/2058 [==============================] - 1s 577us/sample - loss: 1.2498 - acc: 0.4082\n",
      "Epoch 15/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 1.2465 - acc: 0.4097\n",
      "Epoch 00015: acc did not improve from 0.40865\n",
      "2058/2058 [==============================] - 1s 630us/sample - loss: 1.2487 - acc: 0.4082\n",
      "Epoch 16/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 1.2480 - acc: 0.4087\n",
      "Epoch 00016: acc did not improve from 0.40865\n",
      "2058/2058 [==============================] - 1s 703us/sample - loss: 1.2478 - acc: 0.4082\n",
      "Epoch 17/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 1.2468 - acc: 0.4082\n",
      "Epoch 00017: acc did not improve from 0.40865\n",
      "2058/2058 [==============================] - 1s 657us/sample - loss: 1.2477 - acc: 0.4082\n",
      "Epoch 18/100\n",
      "1984/2058 [===========================>..] - ETA: 0s - loss: 1.2444 - acc: 0.4078\n",
      "Epoch 00018: acc did not improve from 0.40865\n",
      "2058/2058 [==============================] - 1s 566us/sample - loss: 1.2468 - acc: 0.4082\n",
      "Epoch 19/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 1.2460 - acc: 0.4082\n",
      "Epoch 00019: acc did not improve from 0.40865\n",
      "2058/2058 [==============================] - 1s 478us/sample - loss: 1.2462 - acc: 0.4082\n",
      "Epoch 20/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 1.2467 - acc: 0.4072\n",
      "Epoch 00020: acc did not improve from 0.40865\n",
      "2058/2058 [==============================] - 1s 548us/sample - loss: 1.2458 - acc: 0.4082\n",
      "Epoch 21/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 1.2450 - acc: 0.4092\n",
      "Epoch 00021: acc did not improve from 0.40865\n",
      "2058/2058 [==============================] - 1s 503us/sample - loss: 1.2455 - acc: 0.4082\n",
      "Epoch 22/100\n",
      "1952/2058 [===========================>..] - ETA: 0s - loss: 1.2415 - acc: 0.4114\n",
      "Epoch 00022: acc did not improve from 0.40865\n",
      "2058/2058 [==============================] - 1s 527us/sample - loss: 1.2439 - acc: 0.4082\n",
      "Epoch 23/100\n",
      "1952/2058 [===========================>..] - ETA: 0s - loss: 1.2410 - acc: 0.4129- ETA: 0s - loss: 1.2468 - acc: 0 - ETA: 0s - loss: 1.2453 - acc: \n",
      "Epoch 00023: acc did not improve from 0.40865\n",
      "2058/2058 [==============================] - 1s 475us/sample - loss: 1.2445 - acc: 0.4082\n",
      "Epoch 24/100\n",
      "1952/2058 [===========================>..] - ETA: 0s - loss: 1.2476 - acc: 0.4068\n",
      "Epoch 00024: acc did not improve from 0.40865\n",
      "2058/2058 [==============================] - 1s 470us/sample - loss: 1.2438 - acc: 0.4082\n",
      "Epoch 25/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 1.2424 - acc: 0.4087\n",
      "Epoch 00025: acc did not improve from 0.40865\n",
      "2058/2058 [==============================] - 1s 526us/sample - loss: 1.2426 - acc: 0.4082\n",
      "Epoch 26/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 1.2402 - acc: 0.4092\n",
      "Epoch 00026: acc did not improve from 0.40865\n",
      "2058/2058 [==============================] - 1s 472us/sample - loss: 1.2414 - acc: 0.4082\n",
      "Epoch 27/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 1.2401 - acc: 0.4077\n",
      "Epoch 00027: acc did not improve from 0.40865\n",
      "2058/2058 [==============================] - 1s 476us/sample - loss: 1.2400 - acc: 0.4082\n",
      "Epoch 28/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 1.2389 - acc: 0.4082\n",
      "Epoch 00028: acc did not improve from 0.40865\n",
      "2058/2058 [==============================] - 1s 530us/sample - loss: 1.2397 - acc: 0.4082\n",
      "Epoch 29/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 1.2381 - acc: 0.4087\n",
      "Epoch 00029: acc did not improve from 0.40865\n",
      "2058/2058 [==============================] - 1s 483us/sample - loss: 1.2386 - acc: 0.4082\n",
      "Epoch 30/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 1.2387 - acc: 0.4072- ETA: 0s - loss: 1.2262 - acc: 0.4\n",
      "Epoch 00030: acc did not improve from 0.40865\n",
      "2058/2058 [==============================] - 1s 529us/sample - loss: 1.2380 - acc: 0.4082\n",
      "Epoch 31/100\n",
      "1984/2058 [===========================>..] - ETA: 0s - loss: 1.2359 - acc: 0.4083\n",
      "Epoch 00031: acc did not improve from 0.40865\n",
      "2058/2058 [==============================] - 1s 486us/sample - loss: 1.2360 - acc: 0.4082\n",
      "Epoch 32/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 1.2349 - acc: 0.4077\n",
      "Epoch 00032: acc did not improve from 0.40865\n",
      "2058/2058 [==============================] - 1s 513us/sample - loss: 1.2345 - acc: 0.4082\n",
      "Epoch 33/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 1.2322 - acc: 0.4092\n",
      "Epoch 00033: acc did not improve from 0.40865\n",
      "2058/2058 [==============================] - 1s 550us/sample - loss: 1.2328 - acc: 0.4086\n",
      "Epoch 34/100\n",
      "1952/2058 [===========================>..] - ETA: 0s - loss: 1.2338 - acc: 0.4062\n",
      "Epoch 00034: acc did not improve from 0.40865\n",
      "2058/2058 [==============================] - 1s 482us/sample - loss: 1.2302 - acc: 0.4086\n",
      "Epoch 35/100\n",
      "1952/2058 [===========================>..] - ETA: 0s - loss: 1.2259 - acc: 0.4119\n",
      "Epoch 00035: acc improved from 0.40865 to 0.40914, saving model to model_checkpoint/checkpoint_35\n",
      "2058/2058 [==============================] - 2s 783us/sample - loss: 1.2279 - acc: 0.4091\n",
      "Epoch 36/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 1.2259 - acc: 0.4087\n",
      "Epoch 00036: acc did not improve from 0.40914\n",
      "2058/2058 [==============================] - 1s 577us/sample - loss: 1.2250 - acc: 0.4091\n",
      "Epoch 37/100\n",
      "1952/2058 [===========================>..] - ETA: 0s - loss: 1.2216 - acc: 0.4124\n",
      "Epoch 00037: acc improved from 0.40914 to 0.40962, saving model to model_checkpoint/checkpoint_37\n",
      "2058/2058 [==============================] - 1s 678us/sample - loss: 1.2222 - acc: 0.4096\n",
      "Epoch 38/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 1.2185 - acc: 0.4150\n",
      "Epoch 00038: acc improved from 0.40962 to 0.41399, saving model to model_checkpoint/checkpoint_38\n",
      "2058/2058 [==============================] - 2s 815us/sample - loss: 1.2185 - acc: 0.4140\n",
      "Epoch 39/100\n",
      "1984/2058 [===========================>..] - ETA: 0s - loss: 1.2151 - acc: 0.4264\n",
      "Epoch 00039: acc improved from 0.41399 to 0.42663, saving model to model_checkpoint/checkpoint_39\n",
      "2058/2058 [==============================] - 2s 901us/sample - loss: 1.2147 - acc: 0.4266\n",
      "Epoch 40/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 1.2106 - acc: 0.4248\n",
      "Epoch 00040: acc did not improve from 0.42663\n",
      "2058/2058 [==============================] - 1s 617us/sample - loss: 1.2103 - acc: 0.4247\n",
      "Epoch 41/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 1.2063 - acc: 0.4399\n",
      "Epoch 00041: acc improved from 0.42663 to 0.43975, saving model to model_checkpoint/checkpoint_41\n",
      "2058/2058 [==============================] - 2s 1ms/sample - loss: 1.2062 - acc: 0.4397\n",
      "Epoch 42/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 1.2000 - acc: 0.4512\n",
      "Epoch 00042: acc improved from 0.43975 to 0.45092, saving model to model_checkpoint/checkpoint_42\n",
      "2058/2058 [==============================] - 2s 895us/sample - loss: 1.2014 - acc: 0.4509\n",
      "Epoch 43/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 1.1972 - acc: 0.4613- ETA: 0s - loss: 1.2084 - acc:\n",
      "Epoch 00043: acc improved from 0.45092 to 0.46404, saving model to model_checkpoint/checkpoint_43\n",
      "2058/2058 [==============================] - 2s 1ms/sample - loss: 1.1965 - acc: 0.4640\n",
      "Epoch 44/100\n",
      "1984/2058 [===========================>..] - ETA: 0s - loss: 1.1922 - acc: 0.4708\n",
      "Epoch 00044: acc improved from 0.46404 to 0.46987, saving model to model_checkpoint/checkpoint_44\n",
      "2058/2058 [==============================] - 2s 810us/sample - loss: 1.1931 - acc: 0.4699\n",
      "Epoch 45/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 1.1883 - acc: 0.4697\n",
      "Epoch 00045: acc improved from 0.46987 to 0.47036, saving model to model_checkpoint/checkpoint_45\n",
      "2058/2058 [==============================] - 2s 787us/sample - loss: 1.1877 - acc: 0.4704\n",
      "Epoch 46/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 1.1802 - acc: 0.4841\n",
      "Epoch 00046: acc improved from 0.47036 to 0.48202, saving model to model_checkpoint/checkpoint_46\n",
      "2058/2058 [==============================] - 2s 1ms/sample - loss: 1.1813 - acc: 0.4820\n",
      "Epoch 47/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 1.1784 - acc: 0.4844\n",
      "Epoch 00047: acc improved from 0.48202 to 0.48445, saving model to model_checkpoint/checkpoint_47\n",
      "2058/2058 [==============================] - 2s 872us/sample - loss: 1.1787 - acc: 0.4845\n",
      "Epoch 48/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 1.1719 - acc: 0.4873\n",
      "Epoch 00048: acc improved from 0.48445 to 0.48639, saving model to model_checkpoint/checkpoint_48\n",
      "2058/2058 [==============================] - 2s 1ms/sample - loss: 1.1725 - acc: 0.4864\n",
      "Epoch 49/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 1.1663 - acc: 0.4990\n",
      "Epoch 00049: acc improved from 0.48639 to 0.49708, saving model to model_checkpoint/checkpoint_49\n",
      "2058/2058 [==============================] - 2s 774us/sample - loss: 1.1671 - acc: 0.4971\n",
      "Epoch 50/100\n",
      "1984/2058 [===========================>..] - ETA: 0s - loss: 1.1630 - acc: 0.4990\n",
      "Epoch 00050: acc improved from 0.49708 to 0.49806, saving model to model_checkpoint/checkpoint_50\n",
      "2058/2058 [==============================] - 2s 810us/sample - loss: 1.1628 - acc: 0.4981\n",
      "Epoch 51/100\n",
      "1984/2058 [===========================>..] - ETA: 0s - loss: 1.1598 - acc: 0.4945\n",
      "Epoch 00051: acc improved from 0.49806 to 0.49951, saving model to model_checkpoint/checkpoint_51\n",
      "2058/2058 [==============================] - 3s 1ms/sample - loss: 1.1582 - acc: 0.4995\n",
      "Epoch 52/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 1.1546 - acc: 0.4995\n",
      "Epoch 00052: acc improved from 0.49951 to 0.50049, saving model to model_checkpoint/checkpoint_52\n",
      "2058/2058 [==============================] - 2s 856us/sample - loss: 1.1539 - acc: 0.5005\n",
      "Epoch 53/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 1.1516 - acc: 0.5093\n",
      "Epoch 00053: acc improved from 0.50049 to 0.50923, saving model to model_checkpoint/checkpoint_53\n",
      "2058/2058 [==============================] - 2s 863us/sample - loss: 1.1508 - acc: 0.5092\n",
      "Epoch 54/100\n",
      "1952/2058 [===========================>..] - ETA: 0s - loss: 1.1484 - acc: 0.5036\n",
      "Epoch 00054: acc did not improve from 0.50923\n",
      "2058/2058 [==============================] - 1s 621us/sample - loss: 1.1454 - acc: 0.5083\n",
      "Epoch 55/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 1.1404 - acc: 0.5119\n",
      "Epoch 00055: acc did not improve from 0.50923\n",
      "2058/2058 [==============================] - 1s 504us/sample - loss: 1.1413 - acc: 0.5092\n",
      "Epoch 56/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 1.1379 - acc: 0.5112\n",
      "Epoch 00056: acc improved from 0.50923 to 0.51166, saving model to model_checkpoint/checkpoint_56\n",
      "2058/2058 [==============================] - 2s 998us/sample - loss: 1.1375 - acc: 0.5117\n",
      "Epoch 57/100\n",
      "1984/2058 [===========================>..] - ETA: 0s - loss: 1.1335 - acc: 0.5217\n",
      "Epoch 00057: acc improved from 0.51166 to 0.52187, saving model to model_checkpoint/checkpoint_57\n",
      "2058/2058 [==============================] - 2s 775us/sample - loss: 1.1328 - acc: 0.5219\n",
      "Epoch 58/100\n",
      "1984/2058 [===========================>..] - ETA: 0s - loss: 1.1328 - acc: 0.5131\n",
      "Epoch 00058: acc did not improve from 0.52187\n",
      "2058/2058 [==============================] - 1s 537us/sample - loss: 1.1303 - acc: 0.5160\n",
      "Epoch 59/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 1.1250 - acc: 0.5169\n",
      "Epoch 00059: acc did not improve from 0.52187\n",
      "2058/2058 [==============================] - 1s 543us/sample - loss: 1.1236 - acc: 0.5180\n",
      "Epoch 60/100\n",
      "1984/2058 [===========================>..] - ETA: 0s - loss: 1.1177 - acc: 0.5282\n",
      "Epoch 00060: acc improved from 0.52187 to 0.52527, saving model to model_checkpoint/checkpoint_60\n",
      "2058/2058 [==============================] - 2s 982us/sample - loss: 1.1184 - acc: 0.5253\n",
      "Epoch 61/100\n",
      "1984/2058 [===========================>..] - ETA: 0s - loss: 1.1173 - acc: 0.5252- ETA: 0s - loss: 1.1212 - acc: 0.5\n",
      "Epoch 00061: acc improved from 0.52527 to 0.52624, saving model to model_checkpoint/checkpoint_61\n",
      "2058/2058 [==============================] - 2s 1ms/sample - loss: 1.1150 - acc: 0.5262\n",
      "Epoch 62/100\n",
      "1952/2058 [===========================>..] - ETA: 0s - loss: 1.1111 - acc: 0.5343\n",
      "Epoch 00062: acc improved from 0.52624 to 0.53547, saving model to model_checkpoint/checkpoint_62\n",
      "2058/2058 [==============================] - 2s 736us/sample - loss: 1.1100 - acc: 0.5355\n",
      "Epoch 63/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 1.1040 - acc: 0.5303\n",
      "Epoch 00063: acc did not improve from 0.53547\n",
      "2058/2058 [==============================] - 1s 576us/sample - loss: 1.1046 - acc: 0.5296\n",
      "Epoch 64/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 1.1046 - acc: 0.5312\n",
      "Epoch 00064: acc did not improve from 0.53547\n",
      "2058/2058 [==============================] - 1s 528us/sample - loss: 1.1005 - acc: 0.5340\n",
      "Epoch 65/100\n",
      "1984/2058 [===========================>..] - ETA: 0s - loss: 1.0958 - acc: 0.5524\n",
      "Epoch 00065: acc improved from 0.53547 to 0.55102, saving model to model_checkpoint/checkpoint_65\n",
      "2058/2058 [==============================] - 2s 991us/sample - loss: 1.0951 - acc: 0.5510\n",
      "Epoch 66/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 1.0926 - acc: 0.5422\n",
      "Epoch 00066: acc did not improve from 0.55102\n",
      "2058/2058 [==============================] - 1s 581us/sample - loss: 1.0904 - acc: 0.5428\n",
      "Epoch 67/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 1.0870 - acc: 0.5552- ETA: 0s - loss: 1.0797 - acc - ETA: 0s - loss: 1.0824 - acc: 0.55\n",
      "Epoch 00067: acc improved from 0.55102 to 0.55637, saving model to model_checkpoint/checkpoint_67\n",
      "2058/2058 [==============================] - 2s 740us/sample - loss: 1.0857 - acc: 0.5564\n",
      "Epoch 68/100\n",
      "1952/2058 [===========================>..] - ETA: 0s - loss: 1.0790 - acc: 0.5512\n",
      "Epoch 00068: acc did not improve from 0.55637\n",
      "2058/2058 [==============================] - 1s 503us/sample - loss: 1.0803 - acc: 0.5520\n",
      "Epoch 69/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 1.0747 - acc: 0.5635\n",
      "Epoch 00069: acc improved from 0.55637 to 0.56268, saving model to model_checkpoint/checkpoint_69\n",
      "2058/2058 [==============================] - 2s 996us/sample - loss: 1.0752 - acc: 0.5627\n",
      "Epoch 70/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 1.0709 - acc: 0.5625- ETA: 0s - loss: 1.0794 - acc:\n",
      "Epoch 00070: acc improved from 0.56268 to 0.56317, saving model to model_checkpoint/checkpoint_70\n",
      "2058/2058 [==============================] - 2s 802us/sample - loss: 1.0714 - acc: 0.5632\n",
      "Epoch 71/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 1.0660 - acc: 0.5708- ETA: 0s - loss: 1.0664 - acc: 0.56\n",
      "Epoch 00071: acc improved from 0.56317 to 0.57094, saving model to model_checkpoint/checkpoint_71\n",
      "2058/2058 [==============================] - 3s 1ms/sample - loss: 1.0660 - acc: 0.5709\n",
      "Epoch 72/100\n",
      "1984/2058 [===========================>..] - ETA: 0s - loss: 1.0646 - acc: 0.5655- ETA: 0s - loss: 1.0698 - acc: 0\n",
      "Epoch 00072: acc did not improve from 0.57094\n",
      "2058/2058 [==============================] - 1s 589us/sample - loss: 1.0617 - acc: 0.5685\n",
      "Epoch 73/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 1.0558 - acc: 0.5719\n",
      "Epoch 00073: acc improved from 0.57094 to 0.57240, saving model to model_checkpoint/checkpoint_73\n",
      "2058/2058 [==============================] - 2s 732us/sample - loss: 1.0547 - acc: 0.5724\n",
      "Epoch 74/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 1.0512 - acc: 0.5823\n",
      "Epoch 00074: acc improved from 0.57240 to 0.58260, saving model to model_checkpoint/checkpoint_74\n",
      "2058/2058 [==============================] - 2s 1ms/sample - loss: 1.0528 - acc: 0.5826\n",
      "Epoch 75/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 1.0480 - acc: 0.5864\n",
      "Epoch 00075: acc improved from 0.58260 to 0.58601, saving model to model_checkpoint/checkpoint_75\n",
      "2058/2058 [==============================] - 2s 872us/sample - loss: 1.0482 - acc: 0.5860\n",
      "Epoch 76/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 1.0439 - acc: 0.5913\n",
      "Epoch 00076: acc improved from 0.58601 to 0.59232, saving model to model_checkpoint/checkpoint_76\n",
      "2058/2058 [==============================] - 2s 736us/sample - loss: 1.0428 - acc: 0.5923\n",
      "Epoch 77/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 1.0381 - acc: 0.5874\n",
      "Epoch 00077: acc did not improve from 0.59232\n",
      "2058/2058 [==============================] - 1s 531us/sample - loss: 1.0380 - acc: 0.5879\n",
      "Epoch 78/100\n",
      "1984/2058 [===========================>..] - ETA: 0s - loss: 1.0358 - acc: 0.5867\n",
      "Epoch 00078: acc did not improve from 0.59232\n",
      "2058/2058 [==============================] - 1s 487us/sample - loss: 1.0340 - acc: 0.5884\n",
      "Epoch 79/100\n",
      "1984/2058 [===========================>..] - ETA: 0s - loss: 1.0315 - acc: 0.5943\n",
      "Epoch 00079: acc improved from 0.59232 to 0.59621, saving model to model_checkpoint/checkpoint_79\n",
      "2058/2058 [==============================] - 2s 1ms/sample - loss: 1.0286 - acc: 0.5962\n",
      "Epoch 80/100\n",
      "1984/2058 [===========================>..] - ETA: 0s - loss: 1.0238 - acc: 0.5948\n",
      "Epoch 00080: acc did not improve from 0.59621\n",
      "2058/2058 [==============================] - 1s 565us/sample - loss: 1.0245 - acc: 0.5952\n",
      "Epoch 81/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 1.0221 - acc: 0.6064\n",
      "Epoch 00081: acc improved from 0.59621 to 0.60641, saving model to model_checkpoint/checkpoint_81\n",
      "2058/2058 [==============================] - 2s 1ms/sample - loss: 1.0214 - acc: 0.6064\n",
      "Epoch 82/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 1.0163 - acc: 0.5962\n",
      "Epoch 00082: acc did not improve from 0.60641\n",
      "2058/2058 [==============================] - 1s 492us/sample - loss: 1.0154 - acc: 0.5977\n",
      "Epoch 83/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 1.0117 - acc: 0.6047- ETA: 0s - loss: 1.0055 - acc:\n",
      "Epoch 00083: acc did not improve from 0.60641\n",
      "2058/2058 [==============================] - 1s 484us/sample - loss: 1.0127 - acc: 0.6035\n",
      "Epoch 84/100\n",
      "1984/2058 [===========================>..] - ETA: 0s - loss: 1.0070 - acc: 0.6048\n",
      "Epoch 00084: acc improved from 0.60641 to 0.60787, saving model to model_checkpoint/checkpoint_84\n",
      "2058/2058 [==============================] - 2s 1ms/sample - loss: 1.0059 - acc: 0.6079\n",
      "Epoch 85/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 1.0015 - acc: 0.6060\n",
      "Epoch 00085: acc did not improve from 0.60787\n",
      "2058/2058 [==============================] - 1s 554us/sample - loss: 1.0025 - acc: 0.6059\n",
      "Epoch 86/100\n",
      "1952/2058 [===========================>..] - ETA: 0s - loss: 1.0004 - acc: 0.6086\n",
      "Epoch 00086: acc improved from 0.60787 to 0.61127, saving model to model_checkpoint/checkpoint_86\n",
      "2058/2058 [==============================] - 1s 721us/sample - loss: 0.9973 - acc: 0.6113\n",
      "Epoch 87/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 0.9935 - acc: 0.6126\n",
      "Epoch 00087: acc did not improve from 0.61127\n",
      "2058/2058 [==============================] - 1s 512us/sample - loss: 0.9967 - acc: 0.6113\n",
      "Epoch 88/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 0.9898 - acc: 0.6187\n",
      "Epoch 00088: acc improved from 0.61127 to 0.61856, saving model to model_checkpoint/checkpoint_88\n",
      "2058/2058 [==============================] - 2s 1ms/sample - loss: 0.9901 - acc: 0.6186\n",
      "Epoch 89/100\n",
      "1984/2058 [===========================>..] - ETA: 0s - loss: 0.9894 - acc: 0.6094\n",
      "Epoch 00089: acc did not improve from 0.61856\n",
      "2058/2058 [==============================] - 1s 487us/sample - loss: 0.9866 - acc: 0.6113\n",
      "Epoch 90/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 0.9800 - acc: 0.6206\n",
      "Epoch 00090: acc improved from 0.61856 to 0.62002, saving model to model_checkpoint/checkpoint_90\n",
      "2058/2058 [==============================] - 2s 738us/sample - loss: 0.9801 - acc: 0.6200\n",
      "Epoch 91/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 0.9809 - acc: 0.6171\n",
      "Epoch 00091: acc did not improve from 0.62002\n",
      "2058/2058 [==============================] - 1s 580us/sample - loss: 0.9793 - acc: 0.6166\n",
      "Epoch 92/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 0.9711 - acc: 0.6260\n",
      "Epoch 00092: acc improved from 0.62002 to 0.62536, saving model to model_checkpoint/checkpoint_92\n",
      "2058/2058 [==============================] - 2s 1ms/sample - loss: 0.9721 - acc: 0.6254\n",
      "Epoch 93/100\n",
      "1984/2058 [===========================>..] - ETA: 0s - loss: 0.9667 - acc: 0.6331- ETA: 0s - loss: 0.9775 - acc\n",
      "Epoch 00093: acc improved from 0.62536 to 0.62925, saving model to model_checkpoint/checkpoint_93\n",
      "2058/2058 [==============================] - 1s 721us/sample - loss: 0.9686 - acc: 0.6293\n",
      "Epoch 94/100\n",
      "1952/2058 [===========================>..] - ETA: 0s - loss: 0.9608 - acc: 0.6352\n",
      "Epoch 00094: acc improved from 0.62925 to 0.63314, saving model to model_checkpoint/checkpoint_94\n",
      "2058/2058 [==============================] - 2s 960us/sample - loss: 0.9639 - acc: 0.6331\n",
      "Epoch 95/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 0.9635 - acc: 0.6324\n",
      "Epoch 00095: acc did not improve from 0.63314\n",
      "2058/2058 [==============================] - 1s 608us/sample - loss: 0.9623 - acc: 0.6327\n",
      "Epoch 96/100\n",
      "1984/2058 [===========================>..] - ETA: 0s - loss: 0.9560 - acc: 0.6346\n",
      "Epoch 00096: acc did not improve from 0.63314\n",
      "2058/2058 [==============================] - 1s 483us/sample - loss: 0.9574 - acc: 0.6327\n",
      "Epoch 97/100\n",
      "1952/2058 [===========================>..] - ETA: 0s - loss: 0.9531 - acc: 0.6404\n",
      "Epoch 00097: acc improved from 0.63314 to 0.63848, saving model to model_checkpoint/checkpoint_97\n",
      "2058/2058 [==============================] - 2s 1ms/sample - loss: 0.9532 - acc: 0.6385\n",
      "Epoch 98/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 0.9492 - acc: 0.6353\n",
      "Epoch 00098: acc did not improve from 0.63848\n",
      "2058/2058 [==============================] - 1s 519us/sample - loss: 0.9476 - acc: 0.6356\n",
      "Epoch 99/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 0.9445 - acc: 0.6382\n",
      "Epoch 00099: acc improved from 0.63848 to 0.63897, saving model to model_checkpoint/checkpoint_99\n",
      "2058/2058 [==============================] - 2s 758us/sample - loss: 0.9439 - acc: 0.6390\n",
      "Epoch 100/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 0.9400 - acc: 0.6431\n",
      "Epoch 00100: acc improved from 0.63897 to 0.64334, saving model to model_checkpoint/checkpoint_100\n",
      "2058/2058 [==============================] - 2s 871us/sample - loss: 0.9397 - acc: 0.6433\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(xcopy, ycopy, epochs=100, callbacks = [earlystop, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3dd3xc1Z338c9PXbItybLlJlkuYINtbLkITAslDsEEYgIkhLIQ0nhtIaRtNvCEZPPAPtnUTSCNUBwHQkwCCw5pkNB7McYYNzDukovcJMvq5ff8cUa2MJIs2xqNpPt9v17zGs29d2bO9cB855R7jrk7IiISXUmJLoCIiCSWgkBEJOIUBCIiEacgEBGJOAWBiEjEKQhERCJOQSCRZmZjzczNLKULx15jZs8fxXsVmdk+M0s+0tcQiQcFgfQZZrbBzBrMbOhB25fGvszHJqZkHQeKmS0ws/8CcPdN7j7Q3ZsP8VpHFTgih0tBIH3NeuDy1gdmNhXITFxxep+u1G5E2lIQSF9zL3B1m8efAu5pe4CZ5ZjZPWa2w8w2mtlNZpYU25dsZj80s51mtg44v53n3m1mW82szMz+q7uacg6uNcR++a8zsyozW29mV5rZJOB24JRYM1JFF87pGjN7wcx+bGa7gVvMbHcsJFvfe5iZ1ZpZfneci/QvCgLpa14Gss1sUuwL+pPAbw865qdADjAeOJMQHJ+O7fs8cAEwAygBPn7Qc38DNAHHxo75MPC57j4JMxsA3Aac5+6DgFOBpe6+Cvhn4KVYM1JuF84JYDawDhgG3AzcD/xTm/2XA4+7+47uPhfp+xQE0he11grOAVYDZa072oTDje5e5e4bgB8BV8UOuRT4ibtvdvfdwH+3ee5w4DzgS+5e7e7lwI+Byw6jbDvNrKL1BlzRybEtwAlmlunuW919RXsHdeGcALa4+0/dvcndawmBdkVrrSF27L2HcR4SIWpLlL7oXuBZYBwHNQsBQ4E0YGObbRuBgtjfo4DNB+1rNQZIBbaaWeu2pIOOP5Sh7t7U+sDMFrR3kLtXm9kngX8H7jazF4Cvuvvq9l6Tzs+Jg8vo7q+YWTVwppltJdRwHjmM85AIUY1A+hx330joNP4I8NBBu3cCjYQv9VZFHKg1bAVGH7Sv1WagnvBlnhu7Zbv7lO4sfyt3f8zdzwFGEmo2d7buOujQQ51Te8+BUCv4J0Jt4EF3r+uOckv/oyCQvuqzwAfdvbrtxtjQzD8A/8/MBpnZGOArHOhH+ANwvZkVmtlg4IY2z90K/B34kZllm1mSmR1jZmd2d+HNbLiZzYv1FdQD+4DWYaXbgUIzS+viOXXkXuAiQhgcXHMS2U9BIH2Su69198Ud7P4CUE3oPH0e+B0wP7bvTuAx4E1gCe+vUVxNaIZZCewBHiT8Yu9uScBXgS3AbkIH8L/G9j0JrAC2mdnO2LbOzqld7l5KOEcHnuvm8ks/YlqYRqT/MrP5hI7kmxJdFum91Fks0k/FrrS+mDAMVqRDahoS6YfM7BZgOfADd1+f6PJI76amIRGRiFONQEQk4vpcH8HQoUN97NixiS6GiEif8vrrr+9093bnmupzQTB27FgWL+5o1KCIiLTHzDZ2tE9NQyIiEacgEBGJOAWBiEjE9bk+AhHpvxobGyktLaWuTvPjHamMjAwKCwtJTU3t8nMUBCLSa5SWljJo0CDGjh1Lm6nApYvcnV27dlFaWsq4ceO6/Dw1DYlIr1FXV8eQIUMUAkfIzBgyZMhh16gUBCLSqygEjs6R/PtFJwi2r4QnboGa3YkuiYhIrxKdINi9Fp77IVSWJrokItLLPfzww5gZq1e3t3Jo/xOdIMgcHO5rVSMQkc4tXLiQ008/nfvvvz9u79Hc3Hzog3pIhIIgL9yraUhEOrFv3z5eeOEF7r777vcEwfe//32mTp1KcXExN9wQVjh99913+dCHPkRxcTEzZ85k7dq1PP3001xwwQX7n3fdddexYMECIEyRc/PNN3P66afzwAMPcOedd3LiiSdSXFzMJZdcQk1NDQDbt2/noosuori4mOLiYl588UW++c1vcuutt+5/3W984xvcdttt3XLO0Rk+mhULgto9iS2HiHTJ//3TClZu2dutrzl5VDb/+dEpnR6zaNEi5s6dy8SJE8nLy2PJkiVs376dRYsW8corr5CVlcXu3eEH5ZVXXskNN9zARRddRF1dHS0tLWzevLnT18/IyOD5558HYNeuXXz+858H4KabbuLuu+/mC1/4Atdffz1nnnkmDz/8MM3Nzezbt49Ro0Zx8cUX88UvfpGWlhbuv/9+Xn311W74V4lSEKhpSES6YOHChXzpS18C4LLLLmPhwoW0tLTw6U9/mqysLADy8vKoqqqirKyMiy66CAhf8F3xyU9+cv/fy5cv56abbqKiooJ9+/Zx7rnnAvDkk09yzz33AJCcnExOTg45OTkMGTKEN954g+3btzNjxgyGDBnSLeccnSBISYfUAVBbkeiSiEgXHOqXezzs2rWLJ598kuXLl2NmNDc3Y2Zccskl7xuW2dGiXikpKbS0tOx/fPCY/gEDBuz/+5prrmHRokUUFxezYMECnn766U7L97nPfY4FCxawbds2PvOZzxzm2XUsOn0EEGoF6iMQkQ48+OCDXH311WzcuJENGzawefNmxo0bR15eHvPnz9/fhr97926ys7MpLCxk0aJFANTX11NTU8OYMWNYuXIl9fX1VFZW8sQTT3T4flVVVYwcOZLGxkbuu+++/dvnzJnDL3/5SyB0Ku/dG5rILrroIh599FFee+21/bWH7hCtIMgarD4CEenQwoUL9zf1tLrkkkvYsmUL8+bNo6SkhOnTp/PDH/4QgHvvvZfbbruNadOmceqpp7Jt2zZGjx7NpZdeyrRp07jyyiuZMWNGh+93yy23MHv2bM455xyOP/74/dtvvfVWnnrqKaZOncqsWbNYsWIFAGlpaZx99tlceumlJCcnd9t597k1i0tKSvyIF6b5zUehqR4++/fuLZSIdItVq1YxadKkRBej12ppaWHmzJk88MADTJgwocPj2vt3NLPX3b2kveOjVSPIzFONQET6pJUrV3LssccyZ86cTkPgSESnsxjCEFL1EYhIHzR58mTWrVsXl9eOWI0g1kfQx5rDRETiKW5BYGbzzazczJZ3csxZZrbUzFaY2TPxKst+mXngzVDfvRepiIj0ZfGsESwA5na008xygV8A89x9CvCJOJYlaL2oTM1DIiL7xS0I3P1ZoLNv3CuAh9x9U+z48niVZT9NMyEi8j6J7COYCAw2s6fN7HUzu7qjA83sWjNbbGaLd+zYceTvqGkmROQQBg4cmOgi9LhEBkEKMAs4HzgX+KaZTWzvQHe/w91L3L0kPz//yN+xdQZSTTMhIrJfIoOgFHjU3avdfSfwLFAc13fM0lTUInL4Nm7cyJw5c5g2bRpz5sxh06ZNADzwwAOccMIJFBcXc8YZZwCwYsUKTjrpJKZPn860adNYs2ZNIoveJYm8juCPwM/MLAVIA2YDP47rO2bkhns1DYn0fn+7Aba91b2vOWIqnPfdw37addddx9VXX82nPvUp5s+fz/XXX8+iRYu4+eabeeyxxygoKKCiIrQ03H777Xzxi1/kyiuvpKGhoVctQNOReA4fXQi8BBxnZqVm9lkz+2cz+2cAd18FPAosA14F7nL3DoeadovkFEjPUWexiByWl156iSuuuAKAq666av96AqeddhrXXHMNd9555/4v/FNOOYXvfOc7fO9732Pjxo1kZmYmrNxdFbcagbtf3oVjfgD8IF5laFdmrpqGRPqCI/jl3lNap6S+/fbbeeWVV/jLX/7C9OnTWbp0KVdccQWzZ8/mL3/5C+eeey533XUXH/zgBxNc4s5F68piCP0EqhGIyGE49dRT9y9bed9993H66acDsHbtWmbPns3NN9/M0KFD2bx5M+vWrWP8+PFcf/31zJs3j2XLliWy6F0SrbmGIDbNhGoEItK+mpoaCgsL9z/+yle+wm233cZnPvMZfvCDH5Cfn8+vf/1rAL72ta+xZs0a3J05c+ZQXFzMd7/7XX7729+SmprKiBEj+Na3vpWoU+myCAZBHuzZkOhSiEgv1XZ1sbaefPLJ92176KGH3rftxhtv5MYbb+z2csVT9JqGtEqZiMh7RC8IsvKgrhJaev+QLhGRnhC9IMjMAzyEgYj0On1t1cTe5kj+/SIYBJqBVKS3ysjIYNeuXQqDI+Tu7Nq1i4yMjMN6XvQ6izUDqUivVVhYSGlpKUc1uWTEZWRkvGfUU1dELwg0A6lIr5Wamsq4ceMSXYzIiW7TkGoEIiJAlINAfQQiIkAUgyAjFyxJNQIRkZjoBUFSUggD9RGIiABRDAKIzTekGoGICEQ1CLLy1EcgIhITzSDQDKQiIvtFNAi0JoGISKuIBsFgqFEQiIhAVIMgKw8aqqC5MdElERFJuGgGga4uFhHZT0EgIhJx0QyCrCHhvlozHIqIxC0IzGy+mZWb2fJDHHeimTWb2cfjVZb3GXJMuN+5psfeUkSkt4pnjWABMLezA8wsGfge8Fgcy/F+OaMhbSCUr+rRtxUR6Y3iFgTu/ixwqKu2vgD8L1Aer3K0ywzyj4fylT36tiIivVHC+gjMrAC4CLi9C8dea2aLzWxxt61cNGySagQiIiS2s/gnwNfdvflQB7r7He5e4u4l+fn53fPuwyZDzU7Ypw5jEYm2RC5VWQLcb2YAQ4GPmFmTuy/qkXcfdny437EKBnZTuIiI9EEJqxG4+zh3H+vuY4EHgX/tsRCAUCMANQ+JSOTFrUZgZguBs4ChZlYK/CeQCuDuh+wXiLuBw8OFZeowFpGIi1sQuPvlh3HsNfEqR4fMQq2gfHWPv7WISG8SzSuLW+UfH5qG3BNdEhGRhIl2EAybBPWVsHdLoksiIpIwEQ8CdRiLiEQ8CCaF+x0KAhGJrmgHQVZeGD2kGoGIRFi0gwBiU01oCKmIRJeCYNhk2PE2tLQkuiQiIgmhIBg2CRproGJjoksiIpIQCoLhU8L9m/cnthwiIgmiIBg1E6Z+Ap75Lry+INGlERHpcYmcfbR3MIMLfwG1FfDnL0NmHkyel+hSiYj0GNUIAFLS4NLfQEEJ/O9nYfF8aDnkMgkiIv2CgqBV2gC44vdQeFKoGdx5Nmx6JdGlEhGJOwVBW1l5cM2f4ZK7w8pl8z8Md50Dz/1Ik9OJSL9l3se+3EpKSnzx4sXxf6P6ffDqr2DlI7B1adiWNQRGzQi3EdNgxAmQOxaSlKci0ruZ2evuXtLuPgVBF+zdAmv+DqWvwZalsdpBrA8hbSAMHhumqhg0IoRFZi5k5EDaIEhJD7e0geGYgcPCvrBEp4hIj+gsCDRqqCuyR8Gsa8INoKEmTFS3fQVsWw4Vm2DfthAQNbugub7z17MksOTYfRIkp0JSSgiM9EGQnh3u0wZAahakZkJSMmDhPiXjvftS0sO25FRISj3weknJ4T5tYAiorCGQnBbK19wQypISe76CSSSyFARHIi0LCmaFW3sa66CuIjQvNddDUz3U7w39Dvu2h30tzeAtoWbR3AQtjdBUF55TXxU7vhwaq6GxNnZsS3heU124dafUrAMBlJEdai2tt8zBkJEbtrcGTXJqCJi0gZA+MARKaka4z8qLBZeI9AUKgnhIzYDUETAoju/R0hymxmiqD0HRFPuV39IYC5Y2t4Z9oaZSvTM8Tk4LtQD3A6HSUH0ggOoqoW4vVGwOoVVbEV63qywJBuSHprABQ8O1GVl5kDUUBuaHfdkFoUktc7BqIyIJpiDoq5KSY81I8UybGPcQOnWVIUiaG8OtoRoaqkItpqkuBFJjDVTvgKptofZTsxt2r4fa3eH5B0vPhpzRofktpwByiyDvGBhyDOSND01gIhJXCgI5NLPwhXy0X8pNDVCzMzR5VZaGif72bIDKMthbClveCPvbGjgiBMLQY2H41DBSa/iU0GQlIt0ibkFgZvOBC4Bydz+hnf1XAl+PPdwH/Iu7vxmv8kgvkJIWfvlnj4JR09s/pr4Kdq+DXWvD/e714X7Vn2HJPQeOGzwWRkyFEcVQWBL6azKye+Q0RPqbeNYIFgA/A+7pYP964Ex332Nm5wF3ALPjWB7pC9IHwcjicGvLHaq2hlFa25bBtrfCbdWfYgdYWFti1IwQMqNmwshpoVNbRDoVtyBw92fNbGwn+19s8/BloDBeZZF+wOxAbWLihw9sr62AssWw+bVwncc7f4Olvw37UrOg8EQYcxqMOTX8nZqRmPKL9GK9pY/gs8DfOtppZtcC1wIUFRX1VJmkL8jMhWM/FG4Qag6VpSEcNr4Em16Ep/8b8DBaqmBWaFIaNulADSIlPaGnIJJocb2yOFYj+HN7fQRtjjkb+AVwurvvOtRrJuTKYunbaitg08uw4blwv2N1GFIL4bqHMafA+LNh4lzIn5jYsorESa+9stjMpgF3Aed1JQREjkhmLhw3N9wgrE+9tzT0Max/DtY9Bf/4ZrgNPQ4mXRBqDrlFkDtGndDS7yUsCMysCHgIuMrd30lUOSSCkpJiX/JFcPz5YVtlGbz9V1j1CDz/kwNzSUEIh+PPh+MvCE1JmmRQ+pm4NQ2Z2ULgLGAosB34TyAVwN1vN7O7gEuA1lXjmzqqtrSlpiGJu9oK2L02zCG1ex2sexo2vBDCYUA+jDsTjjkbxp4eagy6Mlr6AM0+KnK0avfAmn/Au4/D2qegujxszxoarmMoLIHRJ4cmpbSsxJZVpB29to9ApM/IHAzTLg03dyhfCZtegtLXwwildx4NxyWlhFFJBbGL3EZND1NmpKQltvwinVCNQKQ71OwO1zFsejm2bsUbB0YmWXK4EnrYpFiz0gfDXEpqUpIepBqBSLxl5cHEc8MNwuywO9+Brctg1xrYuSasdLf6z2F/dkFsKvOZB1a8y8pLXPkl0hQEIvGQlBy7aG3Se7fvXhf6GDY8D1uWhFFKrbILw7QYo0+ColN0sZv0GAWBSE/KGx9uJ342PK7ZHWoKrXMnbXkjDGOFsAhQ6zDX3CIYfyZMODcsBCTSjRQEIomUlRf6DI754IFt1Tth8yuw+dXYNN2bYeUfYclvwpXQE84JTVDjzggBIXKUDhkEZjYc+A4wyt3PM7PJwCnufnfcSycSRQOGxi5gO//AtpbmMEppxcNhxtXWJqXB40Jfw7BJYZ2GUTNh0PDElFv6rEOOGjKzvwG/Br7h7sVmlgK84e5Te6KAB9OoIYm81uGr658NU2RsewsqNx3YP2QCjD0t1BjGnRmCRSLvaEcNDXX3P5jZjQDu3mRmzYd6kojEiVn49T98Cpz8L2Fb3V4oXxWalDa+AMsfgtcXhH0jpsLYD4TaQsHM0EehoavSRleCoNrMhgAOYGYnA+0sPisiCZORDUWzw+2060NT0palsO5JWPs0LP41NP0iHJs1BMafFWZcHX+m+hmkS0HwFeAR4BgzewHIBz4e11KJyNFJSobCWeF2xteguQl2rIKyJbDxxTDj6vL/DcdmFxwYslp0SqhpJCUntvzSo7p0ZXGsX+A4wIC33b0x3gXriPoIRLqBe2hK2vA8bH45XBG9tyzsS8+G0bNDreGYs8MCPmpK6vOOatI5M7u6ve3u3tFaxHGlIBCJk4pNIRA2vhgCYteasH3g8DDT6tgPhJumx+iTjraz+MQ2f2cAc4AldLwovYj0Ra0Xrk27NDyuLA1TcK97OoxOam1KSs8OHdAjph0YnZSRk6hSSzc47EnnzCwHuNfd58WnSJ1TjUAkAdxh17thRFLrVdDb3oLGmjCpXsGs0FFdEJuSO6cw0SWWg3T3pHM1wISjK5KI9ClmMHRCuLVqaggzra57Ksyf9MqvoPmnYd+wKTD1EjjhkjDzqvRqXekj+BOxoaNAEjAZ+IO73xDnsrVLNQKRXqqpHrYtD53PK/8YrmmAMFx14AgYOCxcAT36pLCIT/bIxJY3Yo62s/jMNg+bgI3uXtqN5TssCgKRPmLPxjAVxu51ULUdqraGK6Kb6sL+vPHhWobWZT8zBye2vP2clqoUkd6hqQG2LQujk9Y/G0YnNVYDsauli06BopNh5PQQFElJiS5xv3FEQWBmVRxoEnrPLsDdPbv7ith1CgKRfqS1n2HjC+G2+bVYMABpg8KUGOPPCrWGEcUKhqOgGoGI9A3NjeFCt61vhnUaNr0M25eHfRk5oaYwagaMLIb840OtITUjsWXuI7pl1JCZDSNcRwCAu2/q5HARkcOXnBpWaRs5DbgqbKvaDuufCTWGLUvhpZ9DS2xyA0uCvGPg2DlhjYYxp2lVtyPQlc7iecCPgFFAOTAGWOXuUw7xvPnABUC5u5/Qzn4DbgU+QhiSeo27LzlUgVUjEIm4pnrYsTqsA73znbCq2/pnQyd0SibkjQvrNAwZH1Z0G3Oq5k7i6GsEtwAnA4+7+wwzOxu4vAvPWwD8jI6vQD6PcD3CBGA28MvYvYhIx1LSQ9PQyOID2xpqYuszPAt71oeRSu8+Di/+NEyRMWleGLY6bBIMnahaw0G6EgSN7r7LzJLMLMndnzKz7x3qSe7+rJmN7eSQC4F7PFRJXjazXDMb6e5bu1Z0EZGYtCw4bm64tWqohncegxUPwRv3wmt3hu2WHPoZxp0B4z4QZl9NSYeUDBgwLJId0l0JggozGwg8B9xnZuWE6wmOVgGwuc3j0ti29wWBmV0LXAtQVKS500WkC9IGwAkXh1tTA+xeG65j2PZWmFjvxdvg+f9573MGjoDJ82Dyx8Iw1og0KXUYBGb2M2Ah4Zd7LfAl4EogB7i5G967vekL2+2wcPc7gDsg9BF0w3uLSJSkpIVmoWGTwrQXAPVVsPlVqN0T+h0aqkOn9JJ74NU7Qg0h/7gwXUbRbDjufBiYn9jziJPOagRrgB8CI4HfAwvd/Tfd+N6lwOg2jwuBLd34+iIiHUsfFEYbtTX72hAQa/4eFvHZviL0Nbz5O/jzl6Ho1NDXkJYFqQNg8Bg49kN9vs+hwyBw91uBW81sDHAZ8GszywB+B/ze3d85yvd+BLjOzO4ndBJXqn9ARBIufVCoNbTWHNxDIKx6BFb9CV74CXjLgeMzckJT0qR5YXrugcP63HoNh3VBmZnNAOYD09y908YzM1sInAUMBbYD/wmkArj77bHhoz8D5hKGj37a3Q85LlTDR0UkodzDhW+N1aHWsOwPISBar4jOzIMRJ4RV3opOhlEzwzxKCQ6Ho510LpXwZX0ZYVGaZwjNRIu6u6BdoSAQkV6noRpKF4erostXhquit711oOaQnAZZQ2HQCCg8MSzoU3Rqj/Y5HOlcQ+cQrhc4H3gVuB9Y5O7V8SpoVygIRKRPqK8K4bDtLajZCdW7oHJT2NZYE47JHRMW9SksCcNZh58Qt5rDkV5Q9n8I/QH/7u6741IyEZH+Kn1QmCzvmLPfu725MUyVselFKHs9jFxa8VDYN3A4HPPBEA4jpoYZWdMHxb2onXUWn93RPhEROULJqTD6xHBrVVkWVnp794kwYunNhQf2DZkQZmEtmAXjzoRhx3d7kTT7qIhIb+IOe8vCam/bloW5lMpeh33b4fQvw4e+fUQv291rFouISLyYQU5huLVOmeEOe7eE2VbjQEEgItLbmUFOQdxePnqzK4mIyHsoCEREIk5BICIScQoCEZGIUxCIiEScgkBEJOIUBCIiEacgEBGJOAWBiEjEKQhERCJOQSAiEnEKAhGRiFMQiIhEnIJARCTiFAQiIhGnIBARibi4BoGZzTWzt83sXTO7oZ39RWb2lJm9YWbLzOwj8SyPiIi8X9yCwMySgZ8D5wGTgcvNbPJBh90E/MHdZwCXAb+IV3lERKR98awRnAS86+7r3L0BuB+48KBjHMiO/Z0DbIljeUREpB3xDIICYHObx6WxbW19G/gnMysF/gp8ob0XMrNrzWyxmS3esWNHPMoqIhJZ8QwCa2ebH/T4cmCBuxcCHwHuNbP3lcnd73D3Encvyc/Pj0NRRUSiK55BUAqMbvO4kPc3/XwW+AOAu78EZABD41gmERE5SDyD4DVggpmNM7M0QmfwIwcdswmYA2BmkwhBoLYfEZEeFLcgcPcm4DrgMWAVYXTQCjO72czmxQ77KvB5M3sTWAhc4+4HNx+JiEgcpcTzxd39r4RO4LbbvtXm75XAafEsg4iIdE5XFouIRJyCQEQk4hQEIiIRpyAQEYk4BYGISMQpCEREIk5BICIScQoCEZGIUxCIiEScgkBEJOIUBCIiEacgEBGJOAWBiEjEKQhERCJOQSAiEnEKAhGRiFMQiIj0EfFawDGuK5SJiEjn3J2tlXXkDUgjIzV5//aahibe2b6PNzdXsHRzBW9s2sMnSkbzb2cf2+1lUBCIiMRBQ1MLa8qr2LSrhuQkIy0lidTkJCy2f29dE8+t2cHTb++grKIWMxiZnUHh4Cy27q1l8+7a/a81bFA6M4pyOSZ/QFzKqiAQETlKjc0tvFVWyYqySlZs2cvyLZW8s20fDc0tnT4vKy2Z048dyuc+MI69tU1s2FVN6Z4aigtz+cSs0UwcPpBphbmMzMnAzDp9raOhIBAROUh9UzPJZqQkv7cbde2OfWzfW8fE4YMYOjCd3dUNLHx1E/e8tIHte+sBGJyVypRROXz69LGcMCqH8fkDcIeG5hYamw4EQ2pKElNGZZOekkyixTUIzGwucCuQDNzl7t9t55hLgW8DDrzp7lfEs0wiIu1pam7h+Xd38vAbZTy2YhsD0lL4aPEoLp5ZwK7qBuY/v57n1uzcf3zegDSq65uob2rhAxOG8q0LpjC9KJdRcf71Hg9xCwIzSwZ+DpwDlAKvmdkj7r6yzTETgBuB09x9j5kNi1d5RKT/aWxuoWxPLWOGZLX75VvT0MRbpZWs2rqXrPQUhg1KJyczleVb9vLCmp28vH4X++qaAGhxp8UhJzOVi2YUUlHTwO9e2cSCFzcAoZ3+3z88kWmFuawp38c726rISE3iypPHMHH4oJ487W4XzxrBScC77r4OwMzuBy4EVrY55vPAz919D4C7l8exPCLST7g7j68q57//top1O6qZNDKbz5w2lvOnjWR52V6eeruc56IcI+AAAA8dSURBVNbsYNXWKppb2h9yWZCbyYcnDyd/UPr+bVMLcjn7+Pz9zTWVNY08tmIbmWnJnDtlBGkpoanojIn58T/JHmTxGpdqZh8H5rr752KPrwJmu/t1bY5ZBLwDnEZoPvq2uz/azmtdC1wLUFRUNGvjxo1xKbOI9Lym5hYcSE1u/7KmnfvqeXhJGcvKKslKTSYrPZmVW/byyvrdjM8fwCUzC3lk6Rbe3l6FGbhDSpIxa8xgThqXx/TRuZxQkEN9YwvlVXXsqm7guOGDOqxF9Fdm9rq7l7S3L541gvb+hQ9OnRRgAnAWUAg8Z2YnuHvFe57kfgdwB0BJSUl8kktEekxVXSPPrdnJ31ds44nV5TQ0tTC1IIfpo3MZnZdFY3MLDc0tLNtcyeOrttPU4hQOzqSp2aluaCIrLZlbLpzCZScVkZqcxL+edQwvrt3FM+/sYProXE6fMJTsjNT3vW/RkKwEnG3vF88gKAVGt3lcCGxp55iX3b0RWG9mbxOC4bU4lktEelhlbSO/fXkjr23YzZrt+yirCGPkB2elMnfKCLIzU1m6uYJ7Xt5IQ5uRNXkD0rjm1LF88sTRTOikHd7MOO3YoZx27NC4n0t/FM8geA2YYGbjgDLgMuDgEUGLgMuBBWY2FJgIrItjmUSkB1XVNbLghQ3c+dw69tY1cfyIQZSMHcwVw4uYWTSYE8cOfs8QzYamFiprG0lLSSItOYn0lCSSkqLTfJMocQsCd28ys+uAxwjt//PdfYWZ3QwsdvdHYvs+bGYrgWbga+6+K15lEpHuVVnTyB/fLOPR5dvITE2mYHAmw7MzKN1Ty8otlazeVkV9UwsfmjScL58zgSmjcjp9vbSUpPd03krPiFtncbyUlJT44sWLE10MkcjZtKuGB5eUUl3fRENTCzv31fPk6nLqm1qYOHwgSWaUVdRSVddEdkYKU0blMGVUNvOmj2JaYW6iix95ieosFpE+aNXWvfx9xXYmDh/IjKLBJCcZP31yDb97ZRMt7gxISyE1JYnM1GQuLRnNJ08czQkFB37pV9eHztwojcjp6xQEIhH1h9c289K6XXxiViGnHDOE5hbn9mfWcusTa2hsPtBSkGShM/ayE0fzxTkTGJad0enrDkjX10pfo09MJGKaW5zv/HUVdz+/nrTkJB5+o4zx+QPISktmedleLpg2km9eMJktFbUs3VzBtso6LjupiHFD4zPzpSSegkCkH1pWWkFjcwvFhbnvGZVTVdfIl3+/lMdXlXPNqWP5j7nH8ejybdz78ka2Vdbx08tn8NHiUQAMz85gRtHgRJ2C9CAFgUg/0dLiPLG6nF89s5bFG/cAYd6cMyfmk52ZwtLNFazaWgXALRdO4apTxgJw8cxCLp5ZmKhiSy+gIBDphVpanJVb91I0JKvdK2Sr65t4dPk2/rRsC1sqaqmub2ZvbSNV9U0U5Gby7Y9OJn9QBk+9Xc7Tb5dT19hC8egc/uXMY/jQ5OFMH61RPHKAgkCkF2mdTO3H/3iHlVv3kpJklIwdzAcm5JNkRnlVHWV7anluzU5qG5sZnZfJlJE5DEhPYUB6MrPGDOb8qSP3NwedP23k/nVuNYpHOqIgEOkBO6rqWbJpDxmpyQxMTyYtOZmahiaqG5rYW9tEWUUtZRW1LN1UwcqtexkzJItbLpzClso6nlpdzg8eexuAAWnJDMvO4KKZBVw8o4BZYwYf8gteASCHoiAQiaPlZZX8+oUN/OnNLYdctnBwVipFQwbw/UumcdHMgv2zcX597vHsrm4gPSVJQzMlLvRflchhcneeXF3OW2WVVNc3Ud0Q2ucraxvZU9PA3tomahqa2FffRF1jC1lpyVx20mgunB5G41TXN1PfFLYPSE9hYHoKI3MyOv2SzxuQ1lOnJxGkIBA5DC+v28X3Hl3NG5vCTOlZaclkpaUwKCOF3KxUhg3K4Nj8lFibfQoFuZl8bEYBOZnv7/AV6S0UBCIH2VFVz5rtVZRW1FK2p5byqjrK99ZTVlHL6m1VjMjO4HuXTOXimYUdLqYi0pcoCERi9tY18tMn1vDrFzbQ1NI60gaGDEgjf1AGw7MzuGRmIVedMoaM1OQEl1ak+ygIJJJqG5pZsmkPVXWNNDQ75XvruP2ZteyqbuATswr52PQCCgZnMjInc/86tSL9lYJAIqOusZkHXi/l8ZXbeWndrveshAUwsyiX+decqCmTJXIUBBIJr2/czX88uIy1O6oZP3QAV508hjMm5jNsUDqpsZWwCgdnasy9RJKCQPq1qrpG/ucf77DgxQ2Mysnkns+cxBkT8xNdLJFeRUEg/VJTcwv3v7aZnzz+Djv3NXD1KWP4j7nHM1AXZIm8j/6vkH5nyaY9fP3BZawp38dJY/O4+1OTKNYkayIdUhBIv+Hu3PXcer736GqGZ2fwq6tm8eHJw9XuL3IICgLpk9ydv761jSdWbycvK41h2em8un43j68q59wpw/n+x4t1Na9IFykIpM8p3VPDNxct56m3d5A3II2ahjCnT2qy8a0LJvPp08aqFiByGOIaBGY2F7gVSAbucvfvdnDcx4EHgBPdfXE8yyR9h7vT1OI0NrdQtqeWNzZVsGTTHv64dAtm8M0LJvOpU8aQnGTsq2/Cod1FXESkc3ELAjNLBn4OnAOUAq+Z2SPuvvKg4wYB1wOvxKssAP9YuZ0bH1pGWnISqSlJpCYnod+MPccJi6Y3NLXQ0NxCbK0UIPZlH9ve4gee09z2QUx2RgpzJg3jxo9MoiA3c//2QQoAkSMWzxrBScC77r4OwMzuBy4EVh503C3A94F/j2NZGJ6dzoenjKCxqYXG5pZDzg0v3S8lKQRwWoq9p+kmJcn2B3Rym+1JBmkpSaSlJJE3IJ0ZRbmMGzKApCRFuEh3imcQFACb2zwuBWa3PcDMZgCj3f3PZtZhEJjZtcC1AEVFRUdUmGmFuZo6QESkHfGcTau9n2376/pmlgT8GPjqoV7I3e9w9xJ3L8nP11WhIiLdKZ5BUAqMbvO4ENjS5vEg4ATgaTPbAJwMPGJmJXEsk4iIHCSeQfAaMMHMxplZGnAZ8EjrTnevdPeh7j7W3ccCLwPzNGpIRKRnxS0I3L0JuA54DFgF/MHdV5jZzWY2L17vKyIihyeu1xG4+1+Bvx607VsdHHtWPMsiIiLt09JLIiIRpyAQEYk4BYGISMSZ+/sv4+/NzGwHsPEInz4U2NmNxekronjeUTxniOZ5R/Gc4fDPe4y7t3shVp8LgqNhZovdPXLXKUTxvKN4zhDN847iOUP3nreahkREIk5BICIScVELgjsSXYAEieJ5R/GcIZrnHcVzhm4870j1EYiIyPtFrUYgIiIHURCIiERcZILAzOaa2dtm9q6Z3ZDo8sSDmY02s6fMbJWZrTCzL8a255nZP8xsTex+cKLLGg9mlmxmb5jZn2OPx5nZK7Hz/n1sFtx+w8xyzexBM1sd+8xPicJnbWZfjv33vdzMFppZRn/8rM1svpmVm9nyNtva/XwtuC32/bbMzGYezntFIgjarJ98HjAZuNzMJie2VHHRBHzV3ScR1nf4t9h53gA84e4TgCdij/ujLxJmum31PeDHsfPeA3w2IaWKn1uBR939eKCYcO79+rM2swLCGucl7n4CkEyY4r4/ftYLgLkHbevo8z0PmBC7XQv88nDeKBJBQJv1k929AWhdP7lfcfet7r4k9ncV4YuhgHCuv4kd9hvgY4kpYfyYWSFwPnBX7LEBHwQejB3Sr87bzLKBM4C7Ady9wd0riMBnTZg1OdPMUoAsYCv98LN292eB3Qdt7ujzvRC4x4OXgVwzG9nV94pKELS3fnJBgsrSI8xsLDADeAUY7u5bIYQFMCxxJYubnwD/AbTEHg8BKmLrYkD/+8zHAzuAX8eaw+4yswH088/a3cuAHwKbCAFQCbxO//6s2+ro8z2q77ioBEGn6yf3N2Y2EPhf4EvuvjfR5Yk3M7sAKHf319tubufQ/vSZpwAzgV+6+wygmn7WDNSeWJv4hcA4YBQwgNAscrD+9Fl3xVH99x6VIDjU+sn9hpmlEkLgPnd/KLZ5e2s1MXZfnqjyxclpwLzY2tf3E5oJfkKoHrcuvtTfPvNSoNTdX4k9fpAQDP39s/4QsN7dd7h7I/AQcCr9+7Nuq6PP96i+46ISBJ2un9xfxNrF7wZWufv/tNn1CPCp2N+fAv7Y02WLJ3e/0d0LY2tfXwY86e5XAk8BH48d1q/O2923AZvN7LjYpjnASvr5Z01oEjrZzLJi/723nne//awP0tHn+whwdWz00MlAZWsTUpe4eyRuwEeAd4C1wDcSXZ44nePphOrgMmBp7PYRQnv5E8Ca2H1eossax3+Ds4A/x/4eD7wKvAs8AKQnunzdfK7TgcWxz3sRMDgKnzXwf4HVwHLgXiC9P37WwEJCP0gj4Rf/Zzv6fAlNQz+Pfb+9RRhV1eX30hQTIiIRF5WmIRER6YCCQEQk4hQEIiIRpyAQEYk4BYGISMQpCETizMzOap0RVaQ3UhCIiEScgkAkxsz+ycxeNbOlZvar2PoG+8zsR2a2xMyeMLP82LHTzezl2NzvD7eZF/5YM3vczN6MPeeY2MsPbLN2wH2xq2Ixs++a2crY6/wwQacuEacgEAHMbBLwSeA0d58ONANXEiY1W+LuM4FngP+MPeUe4OvuPo1wJWfr9vuAn7t7MWEOnNbL/GcAXyKshzEeOM3M8oCLgCmx1/mv+J6lSPsUBCLBHGAW8JqZLY09Hk+Y1vr3sWN+C5xuZjlArrs/E9v+G+AMMxsEFLj7wwDuXufuNbFjXnX3UndvIUz9MRbYC9QBd5nZxUDrsSI9SkEgEhjwG3efHrsd5+7fbue4zuZkaW8q4Fb1bf5uBlI8zJ9/EmG22I8Bjx5mmUW6hYJAJHgC+LiZDYP9a8OOIfw/0jqr5RXA8+5eCewxsw/Etl8FPONh7YdSM/tY7DXSzSyrozeMrRuR4+5/JTQbTY/HiYkcSsqhDxHp/9x9pZndBPzdzJIIMz7+G2HBlylm9jphNaxPxp7yKeD22Bf9OuDTse1XAb8ys5tjr/GJTt52EPBHM8sg1Ca+3M2nJdIlmn1UpBNmts/dBya6HCLxpKYhEZGIU41ARCTiVCMQEYk4BYGISMQpCEREIk5BICIScQoCEZGI+/8BQgPCsMm1owAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['loss'])\n",
    "plt.legend(['Accuracy', 'Loss'])\n",
    "plt.title('Model History')\n",
    "plt.ylabel('Value')\n",
    "plt.xlabel('epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial accuracy is:  0.40864918\n",
      "Final accuracy is:  0.64334303\n",
      "Initial loss is:  1.6972040512587285\n",
      "Final loss is:  0.9397311382669054\n"
     ]
    }
   ],
   "source": [
    "# plt.plot(history.history['loss'])\n",
    "# plt.title('model loss')\n",
    "# plt.ylabel('loss')\n",
    "# plt.xlabel('epochs')\n",
    "# plt.show()\n",
    "print(\"Initial accuracy is: \", history.history['acc'][0])\n",
    "print(\"Final accuracy is: \", history.history['acc'][-1])\n",
    "\n",
    "print(\"Initial loss is: \", history.history['loss'][0])\n",
    "print(\"Final loss is: \", history.history['loss'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
