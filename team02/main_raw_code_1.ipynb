{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Last updated 27/07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23.0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import pathlib\n",
    "\n",
    "import mne\n",
    "print(mne.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-0.24.2-cp37-cp37m-win_amd64.whl (6.8 MB)\n",
      "Requirement already satisfied: scipy>=0.19.1 in d:\\anacondainstalled\\envs\\tf-gpu\\lib\\site-packages (from scikit-learn) (1.4.1)\n",
      "Collecting joblib>=0.11\n",
      "  Downloading joblib-1.0.1-py3-none-any.whl (303 kB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-2.2.0-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: numpy>=1.13.3 in d:\\anacondainstalled\\envs\\tf-gpu\\lib\\site-packages (from scikit-learn) (1.18.1)\n",
      "Installing collected packages: joblib, threadpoolctl, scikit-learn\n",
      "Successfully installed joblib-1.0.1 scikit-learn-0.24.2 threadpoolctl-2.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in d:\\anacondainstalled\\envs\\tf-gpu\\lib\\site-packages (3.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\anacondainstalled\\envs\\tf-gpu\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.16 in d:\\anacondainstalled\\envs\\tf-gpu\\lib\\site-packages (from matplotlib) (1.18.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in d:\\anacondainstalled\\envs\\tf-gpu\\lib\\site-packages (from matplotlib) (8.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\anacondainstalled\\envs\\tf-gpu\\lib\\site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\anacondainstalled\\envs\\tf-gpu\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in d:\\anacondainstalled\\envs\\tf-gpu\\lib\\site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: six>=1.5 in d:\\anacondainstalled\\envs\\tf-gpu\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mne in d:\\anacondainstalled\\envs\\tf-gpu\\lib\\site-packages (0.23.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in d:\\anacondainstalled\\envs\\tf-gpu\\lib\\site-packages (from mne) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.15.4 in d:\\anacondainstalled\\envs\\tf-gpu\\lib\\site-packages (from mne) (1.18.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install mne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pathlib in d:\\anacondainstalled\\envs\\tf-gpu\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: pandas in d:\\anacondainstalled\\envs\\tf-gpu\\lib\\site-packages (1.3.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in d:\\anacondainstalled\\envs\\tf-gpu\\lib\\site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in d:\\anacondainstalled\\envs\\tf-gpu\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in d:\\anacondainstalled\\envs\\tf-gpu\\lib\\site-packages (from pandas) (1.18.1)\n",
      "Requirement already satisfied: six>=1.5 in d:\\anacondainstalled\\envs\\tf-gpu\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pathlib\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyQt5 in d:\\anacondainstalled\\envs\\tf-gpu\\lib\\site-packages (5.15.4)\n",
      "Requirement already satisfied: PyQt5-sip<13,>=12.8 in d:\\anacondainstalled\\envs\\tf-gpu\\lib\\site-packages (from PyQt5) (12.9.0)\n",
      "Requirement already satisfied: PyQt5-Qt5>=5.15 in d:\\anacondainstalled\\envs\\tf-gpu\\lib\\site-packages (from PyQt5) (5.15.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install PyQt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.use('Qt5Agg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#paths Arush\n",
    "path_AB6_gonogo1 = 'data/sub-AB6/eeg/sub-AB6_task-gonogo_run-1_eeg.set'\n",
    "path_AB6_gonogo2 = 'data/sub-AB6/eeg/sub-AB6_task-gonogo_run-2_eeg.set'\n",
    "path_AB10_gonogo1 = 'data/other subjects set files/sub-AB10_eeg_sub-AB10_task-gonogo_run-1_eeg.set'\n",
    "path_AB10_gonogo2 = 'data/other subjects set files/sub-AB10_eeg_sub-AB10_task-gonogo_run-2_eeg.set'\n",
    "path_AB12_gonogo1 = 'data/other subjects set files/sub-AB12_eeg_sub-AB12_task-gonogo_run-1_eeg.set'\n",
    "path_AB12_gonogo2 = 'data/other subjects set files/sub-AB12_eeg_sub-AB12_task-gonogo_run-2_eeg.set'\n",
    "path_AB13_gonogo1 = 'data/other subjects set files/sub-AB13_eeg_sub-AB13_task-gonogo_run-1_eeg.set'\n",
    "path_AB13_gonogo2 = 'data/other subjects set files/sub-AB13_eeg_sub-AB13_task-gonogo_run-2_eeg.set'\n",
    "path_AB28_gonogo1 = 'data/other subjects set files/sub-AB28_eeg_sub-AB28_task-gonogo_run-1_eeg.set'\n",
    "path_AB28_gonogo2 = 'data/other subjects set files/sub-AB28_eeg_sub-AB28_task-gonogo_run-2_eeg.set'\n",
    "path_AB31_gonogo1 = 'data/other subjects set files/sub-AB31_eeg_sub-AB31_task-gonogo_run-1_eeg.set'\n",
    "path_AB31_gonogo2 = 'data/other subjects set files/sub-AB31_eeg_sub-AB31_task-gonogo_run-2_eeg.set'\n",
    "path_AB32_gonogo1 = 'data/other subjects set files/sub-AB32_eeg_sub-AB32_task-gonogo_run-1_eeg.set'\n",
    "path_AB32_gonogo2 = 'data/other subjects set files/sub-AB32_eeg_sub-AB32_task-gonogo_run-2_eeg.set'\n",
    "\n",
    "path_channels_tsv = 'data/other subjects set files/sub-AB10_eeg_sub-AB10_task-gonogo_run-1_channels.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#paths Sahil\n",
    "path_AB6_gonogo1 = '../../data/sub-AB6_task-gonogo_run-1_eeg.set'\n",
    "path_AB6_gonogo2 = '../../data/sub-AB6_task-gonogo_run-2_eeg.set'\n",
    "path_AB10_gonogo1 = '../../data/sub-AB10_task-gonogo_run-1_eeg.set'\n",
    "path_AB10_gonogo2 = '../../data/sub-AB10_task-gonogo_run-2_eeg.set'\n",
    "path_AB12_gonogo1 = '../../data/sub-AB12_task-gonogo_run-1_eeg.set'\n",
    "path_AB12_gonogo2 = '../../data/sub-AB12_task-gonogo_run-2_eeg.set'\n",
    "path_AB13_gonogo1 = '../../data/sub-AB13_task-gonogo_run-1_eeg.set'\n",
    "path_AB13_gonogo2 = '../../data/sub-AB13_task-gonogo_run-2_eeg.set'\n",
    "path_AB28_gonogo1 = '../../data/sub-AB28_task-gonogo_run-1_eeg.set'\n",
    "path_AB28_gonogo2 = '../../data/sub-AB28_task-gonogo_run-2_eeg.set'\n",
    "path_AB31_gonogo1 = '../../data/sub-AB31_task-gonogo_run-1_eeg.set'\n",
    "path_AB31_gonogo2 = '../../data/sub-AB31_task-gonogo_run-2_eeg.set'\n",
    "path_AB32_gonogo1 = '../../data/sub-AB32_task-gonogo_run-1_eeg.set'\n",
    "path_AB32_gonogo2 = '../../data/sub-AB32_task-gonogo_run-2_eeg.set'\n",
    "\n",
    "path_channels_tsv = '../../data\\sub-AB10_eeg_sub-AB10_task-gonogo_run-1_channels.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading raw data\n",
    "rawab6_1 = mne.io.read_raw_eeglab(path_AB6_gonogo1, eog=(), preload=True, uint16_codec=None, verbose=None)\n",
    "rawab6_2 = mne.io.read_raw_eeglab(path_AB6_gonogo2, eog=(), preload=True, uint16_codec=None, verbose=None)\n",
    "\n",
    "rawab10_1 = mne.io.read_raw_eeglab(path_AB10_gonogo1, eog=(), preload=True, uint16_codec=None, verbose=None)\n",
    "rawab10_2 = mne.io.read_raw_eeglab(path_AB10_gonogo2, eog=(), preload=True, uint16_codec=None, verbose=None)\n",
    "\n",
    "rawab12_1 = mne.io.read_raw_eeglab(path_AB12_gonogo1, eog=(), preload=True, uint16_codec=None, verbose=None)\n",
    "rawab12_2 = mne.io.read_raw_eeglab(path_AB12_gonogo2, eog=(), preload=True, uint16_codec=None, verbose=None)\n",
    "\n",
    "rawab13_1 = mne.io.read_raw_eeglab(path_AB13_gonogo1, eog=(), preload=True, uint16_codec=None, verbose=None)\n",
    "rawab13_2 = mne.io.read_raw_eeglab(path_AB13_gonogo1, eog=(), preload=True, uint16_codec=None, verbose=None)\n",
    "\n",
    "rawab28_1 = mne.io.read_raw_eeglab(path_AB28_gonogo1, eog=(), preload=True, uint16_codec=None, verbose=None)\n",
    "rawab28_2 = mne.io.read_raw_eeglab(path_AB28_gonogo2, eog=(), preload=True, uint16_codec=None, verbose=None)\n",
    "\n",
    "rawab31_1 = mne.io.read_raw_eeglab(path_AB31_gonogo1, eog=(), preload=True, uint16_codec=None, verbose=None)\n",
    "rawab31_2 = mne.io.read_raw_eeglab(path_AB31_gonogo2, eog=(), preload=True, uint16_codec=None, verbose=None)\n",
    "\n",
    "rawab32_1 = mne.io.read_raw_eeglab(path_AB32_gonogo1, eog=(), preload=True, uint16_codec=None, verbose=None)\n",
    "rawab32_2 = mne.io.read_raw_eeglab(path_AB32_gonogo2, eog=(), preload=True, uint16_codec=None, verbose=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels marked as bad: none\n",
      "Channels marked as bad: none\n",
      "Channels marked as bad: none\n"
     ]
    }
   ],
   "source": [
    "#plotting raw data\n",
    "# rawab6_1.plot();\n",
    "# rawab6_2.plot();\n",
    "rawab10_1.plot();\n",
    "# rawab10_2.plot();\n",
    "rawab12_1.plot();\n",
    "# rawab12_2.plot();\n",
    "# rawab13_1.plot();\n",
    "# rawab13_2.plot();\n",
    "# rawab28_1.plot();\n",
    "# rawab28_2.plot();\n",
    "# rawab31_1.plot();\n",
    "# rawab31_2.plot();\n",
    "# rawab32_1.plot();\n",
    "# rawab32_2.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assigning channel types and filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AF3': 'eeg',\n",
       " 'AF4': 'eeg',\n",
       " 'F7': 'eeg',\n",
       " 'F5': 'eeg',\n",
       " 'F3': 'eeg',\n",
       " 'F1': 'eeg',\n",
       " 'Fz': 'eeg',\n",
       " 'F2': 'eeg',\n",
       " 'F4': 'eeg',\n",
       " 'F6': 'eeg',\n",
       " 'F8': 'eeg',\n",
       " 'FT7': 'eeg',\n",
       " 'FC5': 'eeg',\n",
       " 'FC3': 'eeg',\n",
       " 'FC1': 'eeg',\n",
       " 'FCz': 'eeg',\n",
       " 'FC2': 'eeg',\n",
       " 'FC4': 'eeg',\n",
       " 'FC6': 'eeg',\n",
       " 'FT8': 'eeg',\n",
       " 'T7': 'eeg',\n",
       " 'C5': 'eeg',\n",
       " 'C3': 'eeg',\n",
       " 'C1': 'eeg',\n",
       " 'Cz': 'eeg',\n",
       " 'C2': 'eeg',\n",
       " 'C4': 'eeg',\n",
       " 'C6': 'eeg',\n",
       " 'T8': 'eeg',\n",
       " 'M1': 'eeg',\n",
       " 'TP7': 'eeg',\n",
       " 'CP5': 'eeg',\n",
       " 'CP3': 'eeg',\n",
       " 'CP1': 'eeg',\n",
       " 'CPz': 'eeg',\n",
       " 'CP2': 'eeg',\n",
       " 'CP4': 'eeg',\n",
       " 'CP6': 'eeg',\n",
       " 'TP8': 'eeg',\n",
       " 'M2': 'eeg',\n",
       " 'P7': 'eeg',\n",
       " 'P5': 'eeg',\n",
       " 'P3': 'eeg',\n",
       " 'P1': 'eeg',\n",
       " 'Pz': 'eeg',\n",
       " 'P2': 'eeg',\n",
       " 'P4': 'eeg',\n",
       " 'P6': 'eeg',\n",
       " 'P8': 'eeg',\n",
       " 'PO7': 'eeg',\n",
       " 'PO5': 'eeg',\n",
       " 'PO3': 'eeg',\n",
       " 'POz': 'eeg',\n",
       " 'PO4': 'eeg',\n",
       " 'PO6': 'eeg',\n",
       " 'PO8': 'eeg',\n",
       " 'CB1': 'eeg',\n",
       " 'O1': 'eeg',\n",
       " 'Oz': 'eeg',\n",
       " 'O2': 'eeg',\n",
       " 'CB2': 'eeg',\n",
       " 'VEO': 'eog',\n",
       " 'HEO': 'eog',\n",
       " 'EKG': 'ecg',\n",
       " 'R-Dia-X-(mm)': 'misc',\n",
       " 'R-Dia-Y-(mm)': 'misc'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get type of channels from tsv file\n",
    "import pandas as pd\n",
    "channel_types_tsv = pd.read_csv(path_channels_tsv, delimiter = '\\t')\n",
    "\n",
    "def get_channel_types_dic(channel_types_tsv):\n",
    "    channel_types = {}\n",
    "    for i in range(channel_types_tsv.shape[0]):\n",
    "        channel_types[channel_types_tsv['name'][i]] = channel_types_tsv['type'][i].lower()\n",
    "    reassign_dic = {'HEO':'eog', 'VEO':'eog', 'R-Dia-X-(mm)':'misc', 'R-Dia-Y-(mm)':'misc'}\n",
    "    for k in list(reassign_dic.keys()):\n",
    "        if k in list(channel_types):\n",
    "            channel_types[k] = reassign_dic[k]\n",
    "    return channel_types\n",
    "\n",
    "channel_types = get_channel_types_dic(channel_types_tsv)\n",
    "channel_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "<table class=\"table table-hover\">\n",
       "    <tr>\n",
       "        <th>Measurement date</th>\n",
       "<td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Experimenter</th>\n",
       "<td>Unknown</td>\n",
       "    </tr>\n",
       "        <th>Participant</th>\n",
       "<td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Digitized points</th>\n",
       "        <td>66 points</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Good channels</th>\n",
       "        <td>0 magnetometer, 0 gradiometer,\n",
       "            and 61 EEG channels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Bad channels</th>\n",
       "        <td></td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>EOG channels</th>\n",
       "        <td>VEO, HEO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>ECG channels</th>\n",
       "        <td>EKG</td>\n",
       "    <tr>\n",
       "        <th>Sampling frequency</th>\n",
       "        <td>500.00 Hz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Highpass</th>\n",
       "        <td>0.00 Hz</td>\n",
       "    </tr>\n",
       "     <tr>\n",
       "        <th>Lowpass</th>\n",
       "        <td>250.00 Hz</td>\n",
       "    </tr>\n",
       "\n",
       "    <tr>\n",
       "        <th>Filenames</th>\n",
       "        <td>sub-AB32_eeg_sub-AB32_task-gonogo_run-2_eeg.set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Duration</th>\n",
       "        <td>00:08:16 (HH:MM:SS)</td>\n",
       "    </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<RawEEGLAB | sub-AB32_eeg_sub-AB32_task-gonogo_run-2_eeg.set, 66 x 248300 (496.6 s), ~125.1 MB, data loaded>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#assigning channel types\n",
    "#rawab6_1.set_channel_types(channel_types)\n",
    "#rawab6_2.set_channel_types(channel_types)\n",
    "rawab10_1.set_channel_types(channel_types)\n",
    "rawab10_2.set_channel_types(channel_types)\n",
    "rawab12_1.set_channel_types(channel_types)\n",
    "rawab12_2.set_channel_types(channel_types)\n",
    "rawab13_1.set_channel_types(channel_types)\n",
    "rawab13_2.set_channel_types(channel_types)\n",
    "rawab28_1.set_channel_types(channel_types)\n",
    "rawab28_2.set_channel_types(channel_types)\n",
    "rawab31_1.set_channel_types(channel_types)\n",
    "rawab31_2.set_channel_types(channel_types)\n",
    "rawab32_1.set_channel_types(channel_types)\n",
    "rawab32_2.set_channel_types(channel_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.5 - 60 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.50\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
      "- Upper passband edge: 60.00 Hz\n",
      "- Upper transition bandwidth: 15.00 Hz (-6 dB cutoff frequency: 67.50 Hz)\n",
      "- Filter length: 3301 samples (6.602 sec)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.5 - 60 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.50\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
      "- Upper passband edge: 60.00 Hz\n",
      "- Upper transition bandwidth: 15.00 Hz (-6 dB cutoff frequency: 67.50 Hz)\n",
      "- Filter length: 3301 samples (6.602 sec)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.5 - 60 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.50\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
      "- Upper passband edge: 60.00 Hz\n",
      "- Upper transition bandwidth: 15.00 Hz (-6 dB cutoff frequency: 67.50 Hz)\n",
      "- Filter length: 3301 samples (6.602 sec)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.5 - 60 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.50\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
      "- Upper passband edge: 60.00 Hz\n",
      "- Upper transition bandwidth: 15.00 Hz (-6 dB cutoff frequency: 67.50 Hz)\n",
      "- Filter length: 3301 samples (6.602 sec)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.5 - 60 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.50\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
      "- Upper passband edge: 60.00 Hz\n",
      "- Upper transition bandwidth: 15.00 Hz (-6 dB cutoff frequency: 67.50 Hz)\n",
      "- Filter length: 3301 samples (6.602 sec)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.5 - 60 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.50\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
      "- Upper passband edge: 60.00 Hz\n",
      "- Upper transition bandwidth: 15.00 Hz (-6 dB cutoff frequency: 67.50 Hz)\n",
      "- Filter length: 3301 samples (6.602 sec)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.5 - 60 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.50\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
      "- Upper passband edge: 60.00 Hz\n",
      "- Upper transition bandwidth: 15.00 Hz (-6 dB cutoff frequency: 67.50 Hz)\n",
      "- Filter length: 3301 samples (6.602 sec)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.5 - 60 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.50\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
      "- Upper passband edge: 60.00 Hz\n",
      "- Upper transition bandwidth: 15.00 Hz (-6 dB cutoff frequency: 67.50 Hz)\n",
      "- Filter length: 3301 samples (6.602 sec)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.5 - 60 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.50\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
      "- Upper passband edge: 60.00 Hz\n",
      "- Upper transition bandwidth: 15.00 Hz (-6 dB cutoff frequency: 67.50 Hz)\n",
      "- Filter length: 3301 samples (6.602 sec)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.5 - 60 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.50\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
      "- Upper passband edge: 60.00 Hz\n",
      "- Upper transition bandwidth: 15.00 Hz (-6 dB cutoff frequency: 67.50 Hz)\n",
      "- Filter length: 3301 samples (6.602 sec)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.5 - 60 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.50\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
      "- Upper passband edge: 60.00 Hz\n",
      "- Upper transition bandwidth: 15.00 Hz (-6 dB cutoff frequency: 67.50 Hz)\n",
      "- Filter length: 3301 samples (6.602 sec)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.5 - 60 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.50\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
      "- Upper passband edge: 60.00 Hz\n",
      "- Upper transition bandwidth: 15.00 Hz (-6 dB cutoff frequency: 67.50 Hz)\n",
      "- Filter length: 3301 samples (6.602 sec)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "<table class=\"table table-hover\">\n",
       "    <tr>\n",
       "        <th>Measurement date</th>\n",
       "<td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Experimenter</th>\n",
       "<td>Unknown</td>\n",
       "    </tr>\n",
       "        <th>Participant</th>\n",
       "<td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Digitized points</th>\n",
       "        <td>66 points</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Good channels</th>\n",
       "        <td>0 magnetometer, 0 gradiometer,\n",
       "            and 61 EEG channels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Bad channels</th>\n",
       "        <td></td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>EOG channels</th>\n",
       "        <td>VEO, HEO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>ECG channels</th>\n",
       "        <td>EKG</td>\n",
       "    <tr>\n",
       "        <th>Sampling frequency</th>\n",
       "        <td>500.00 Hz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Highpass</th>\n",
       "        <td>0.50 Hz</td>\n",
       "    </tr>\n",
       "     <tr>\n",
       "        <th>Lowpass</th>\n",
       "        <td>60.00 Hz</td>\n",
       "    </tr>\n",
       "\n",
       "    <tr>\n",
       "        <th>Filenames</th>\n",
       "        <td>sub-AB32_eeg_sub-AB32_task-gonogo_run-2_eeg.set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Duration</th>\n",
       "        <td>00:08:16 (HH:MM:SS)</td>\n",
       "    </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<RawEEGLAB | sub-AB32_eeg_sub-AB32_task-gonogo_run-2_eeg.set, 66 x 248300 (496.6 s), ~125.1 MB, data loaded>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filtering the signals\n",
    "#rawab6_1.filter(1, 60)\n",
    "#rawab6_2.filter(1, 60)\n",
    "rawab10_1.filter(0.50, 60)\n",
    "rawab10_2.filter(0.50, 60)\n",
    "rawab12_1.filter(0.50, 60)\n",
    "rawab12_2.filter(0.50, 60)\n",
    "rawab13_1.filter(0.50, 60)\n",
    "rawab13_2.filter(0.50, 60)\n",
    "rawab28_1.filter(0.50, 60)\n",
    "rawab28_2.filter(0.50, 60)\n",
    "rawab31_1.filter(0.50, 60)\n",
    "rawab31_2.filter(0.50, 60)\n",
    "rawab32_1.filter(0.50, 60)\n",
    "rawab32_2.filter(0.50, 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plotting Electrode positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rawab6_1.plot_sensors(ch_type = 'eeg', sphere = 10);\n",
    "# # rawab6_2.plot_sensors(ch_type = 'eeg', sphere = 10);\n",
    "\n",
    "# rawab10_1.plot_sensors(ch_type = 'eeg', sphere = 10);\n",
    "# # rawab10_2.plot_sensors(ch_type = 'eeg', sphere = 10);\n",
    "\n",
    "rawab12_1.plot_sensors(ch_type = 'eeg', sphere = 10);\n",
    "# # rawab12_2.plot_sensors(ch_type = 'eeg', sphere = 10);\n",
    "\n",
    "# rawab13_1.plot_sensors(ch_type = 'eeg', sphere = 10);\n",
    "# # rawab13_2.plot_sensors(ch_type = 'eeg', sphere = 10);\n",
    "\n",
    "# rawab28_1.plot_sensors(ch_type = 'eeg', sphere = 10);\n",
    "# # rawab28_2.plot_sensors(ch_type = 'eeg', sphere = 10);\n",
    "\n",
    "# rawab31_1.plot_sensors(ch_type = 'eeg', sphere = 10);\n",
    "# # rawab31_2.plot_sensors(ch_type = 'eeg', sphere = 10);\n",
    "\n",
    "# rawab32_1.plot_sensors(ch_type = 'eeg', sphere = 10);\n",
    "# # rawab32_2.plot_sensors(ch_type = 'eeg', sphere = 10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rawab6_1.plot_sensors(ch_type = 'eeg', kind = '3d');\n",
    "# # rawab6_2.plot_sensors(ch_type = 'eeg', kind = '3d');\n",
    "\n",
    "# rawab10_1.plot_sensors(ch_type = 'eeg', kind = '3d');\n",
    "# # rawab10_2.plot_sensors(ch_type = 'eeg', kind = '3d');\n",
    "\n",
    "rawab12_1.plot_sensors(ch_type = 'eeg', kind = '3d');\n",
    "# # rawab12_2.plot_sensors(ch_type = 'eeg', kind = '3d');\n",
    "\n",
    "# rawab13_1.plot_sensors(ch_type = 'eeg', kind = '3d');\n",
    "# # rawab13_2.plot_sensors(ch_type = 'eeg', kind = '3d');\n",
    "\n",
    "# rawab28_1.plot_sensors(ch_type = 'eeg', kind = '3d');\n",
    "# # rawab28_2.plot_sensors(ch_type = 'eeg', kind = '3d');\n",
    "\n",
    "# rawab31_1.plot_sensors(ch_type = 'eeg', kind = '3d');\n",
    "# # rawab31_2.plot_sensors(ch_type = 'eeg', kind = '3d');\n",
    "\n",
    "# rawab32_1.plot_sensors(ch_type = 'eeg', kind = '3d');\n",
    "# # rawab32_2.plot_sensors(ch_type = 'eeg', kind = '3d');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "<table class=\"table table-hover\">\n",
       "    <tr>\n",
       "        <th>Measurement date</th>\n",
       "<td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Experimenter</th>\n",
       "<td>Unknown</td>\n",
       "    </tr>\n",
       "        <th>Participant</th>\n",
       "<td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Digitized points</th>\n",
       "        <td>64 points</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Good channels</th>\n",
       "        <td>0 magnetometer, 0 gradiometer,\n",
       "            and 64 EEG channels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Bad channels</th>\n",
       "        <td></td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>EOG channels</th>\n",
       "        <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>ECG channels</th>\n",
       "        <td>Not available</td>\n",
       "    <tr>\n",
       "        <th>Sampling frequency</th>\n",
       "        <td>500.00 Hz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Highpass</th>\n",
       "        <td>0.00 Hz</td>\n",
       "    </tr>\n",
       "     <tr>\n",
       "        <th>Lowpass</th>\n",
       "        <td>250.00 Hz</td>\n",
       "    </tr>\n",
       "\n",
       "    <tr>\n",
       "        <th>Filenames</th>\n",
       "        <td>sub-AB6_task-gonogo_run-1_eeg.set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Duration</th>\n",
       "        <td>00:08:10 (HH:MM:SS)</td>\n",
       "    </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<RawEEGLAB | sub-AB6_task-gonogo_run-1_eeg.set, 64 x 245200 (490.4 s), ~119.8 MB, data loaded>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawab6_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing ICA and SSP Projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating copy\n",
    "#ab6_1 = rawab6_1.copy()\n",
    "#ab6_2 = rawab6_2.copy()\n",
    "ab10_1 = rawab10_1.copy()\n",
    "ab10_2 = rawab10_2.copy()\n",
    "ab12_1 = rawab12_1.copy()\n",
    "ab12_2 = rawab12_2.copy()\n",
    "ab13_1 = rawab13_1.copy()\n",
    "ab13_2 = rawab13_2.copy()\n",
    "ab28_1 = rawab28_1.copy()\n",
    "ab28_2 = rawab28_2.copy()\n",
    "ab31_1 = rawab31_1.copy()\n",
    "ab31_2 = rawab31_2.copy()\n",
    "ab32_1 = rawab32_1.copy()\n",
    "ab32_2 = rawab32_2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "The scikit-learn package is required for method=\"fastica\".",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-a04830e131a8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#ica6_1 = mne.preprocessing.ICA(n_components = 20, random_state = 42)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#ica6_2 = mne.preprocessing.ICA(n_components = 20, random_state = 42)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mica10_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmne\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mICA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_components\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mica10_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmne\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mICA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_components\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mica12_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmne\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mICA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_components\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-419>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, n_components, noise_cov, random_state, method, fit_params, max_iter, allow_ref_meg, verbose)\u001b[0m\n",
      "\u001b[1;32mD:\\anacondainstalled\\envs\\tf-gpu\\lib\\site-packages\\mne\\preprocessing\\ica.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, n_components, noise_cov, random_state, method, fit_params, max_iter, allow_ref_meg, verbose)\u001b[0m\n\u001b[0;32m    385\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'fastica'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_version\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'sklearn'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m             raise ImportError(\n\u001b[1;32m--> 387\u001b[1;33m                 'The scikit-learn package is required for method=\"fastica\".')\n\u001b[0m\u001b[0;32m    388\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'picard'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_version\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'picard'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m             raise ImportError(\n",
      "\u001b[1;31mImportError\u001b[0m: The scikit-learn package is required for method=\"fastica\"."
     ]
    }
   ],
   "source": [
    "#Creating ICA objects\n",
    "#ica6_1 = mne.preprocessing.ICA(n_components = 20, random_state = 42)\n",
    "#ica6_2 = mne.preprocessing.ICA(n_components = 20, random_state = 42)\n",
    "ica10_1 = mne.preprocessing.ICA(n_components = 20, random_state = 42)\n",
    "ica10_2 = mne.preprocessing.ICA(n_components = 20, random_state = 42)\n",
    "ica12_1 = mne.preprocessing.ICA(n_components = 20, random_state = 42)\n",
    "ica12_2 = mne.preprocessing.ICA(n_components = 20, random_state = 42)\n",
    "ica13_1 = mne.preprocessing.ICA(n_components = 20, random_state = 42)\n",
    "ica13_2 = mne.preprocessing.ICA(n_components = 20, random_state = 42)\n",
    "ica28_1 = mne.preprocessing.ICA(n_components = 20, random_state = 42)\n",
    "ica28_2 = mne.preprocessing.ICA(n_components = 20, random_state = 42)\n",
    "ica31_1 = mne.preprocessing.ICA(n_components = 20, random_state = 42)\n",
    "ica31_2 = mne.preprocessing.ICA(n_components = 20, random_state = 42)\n",
    "ica32_1 = mne.preprocessing.ICA(n_components = 20, random_state = 42)\n",
    "ica32_2 = mne.preprocessing.ICA(n_components = 20, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Fitting ICA objects\n",
    "ica10_1.fit(ab10_1)\n",
    "ica10_2.fit(ab10_2)\n",
    "ica12_1.fit(ab12_1)\n",
    "ica12_2.fit(ab12_2)\n",
    "ica13_1.fit(ab13_1)\n",
    "ica13_2.fit(ab13_2)\n",
    "ica28_1.fit(ab28_1)\n",
    "ica28_2.fit(ab28_2)\n",
    "ica31_1.fit(ab31_1)\n",
    "ica31_2.fit(ab31_2)\n",
    "ica32_1.fit(ab32_1)\n",
    "ica32_2.fit(ab32_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plotting sources and components\n",
    "ica10_1.plot_sources(ab10_1)\n",
    "ica10_2.plot_components(outlines = 'head', sphere = 10, ch_type = 'eeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To find and mark bad components\n",
    "def mark_artifacts(ica, ab):\n",
    "    ica.exclude = []\n",
    "    ica.detect_artifacts(ab)\n",
    "    eeg_bads = list(ica.exclude)\n",
    "    ecg_bads = ica.find_bads_ecg(ab)[0]\n",
    "    eog_bads = ica.find_bads_eog(ab)[0]\n",
    "    ica.exclude = list(set(eeg_bads+ecg_bads+eog_bads))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Marking bad components\n",
    "mark_artifacts(ica10_1, ab10_1)\n",
    "mark_artifacts(ica10_2, ab10_2)\n",
    "mark_artifacts(ica12_1, ab12_1)\n",
    "mark_artifacts(ica12_2, ab12_2)\n",
    "mark_artifacts(ica13_1, ab13_1)\n",
    "mark_artifacts(ica13_2, ab13_2)\n",
    "mark_artifacts(ica28_1, ab28_1)\n",
    "mark_artifacts(ica28_2, ab28_2)\n",
    "mark_artifacts(ica31_1, ab31_1)\n",
    "mark_artifacts(ica31_2, ab31_2)\n",
    "mark_artifacts(ica32_1, ab32_1)\n",
    "mark_artifacts(ica32_2, ab32_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica10_1.plot_sources(ab10_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#applying ica\n",
    "ica10_1.apply(ab10_1, exclude = ica10_1.exclude)\n",
    "ica10_2.apply(ab10_2, exclude = ica10_2.exclude)\n",
    "ica12_1.apply(ab12_1, exclude = ica12_1.exclude)\n",
    "ica12_2.apply(ab12_2, exclude = ica12_2.exclude)\n",
    "ica13_1.apply(ab13_1, exclude = ica13_1.exclude)\n",
    "ica13_2.apply(ab13_2, exclude = ica13_2.exclude)\n",
    "ica28_1.apply(ab28_1, exclude = ica28_1.exclude)\n",
    "ica28_2.apply(ab28_2, exclude = ica28_2.exclude)\n",
    "ica31_1.apply(ab31_1, exclude = ica31_1.exclude)\n",
    "ica31_2.apply(ab31_2, exclude = ica31_2.exclude)\n",
    "ica32_1.apply(ab32_1, exclude = ica32_1.exclude)\n",
    "ica32_2.apply(ab32_2, exclude = ica32_2.exclude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Events for all subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eventsab10_1 = mne.events_from_annotations(ab10_1)\n",
    "eventsab10_2 = mne.events_from_annotations(ab10_2)\n",
    "\n",
    "eventsab12_1 = mne.events_from_annotations(ab12_1)\n",
    "eventsab12_2 = mne.events_from_annotations(ab12_2)\n",
    "\n",
    "eventsab13_1 = mne.events_from_annotations(ab13_1)\n",
    "eventsab13_2 = mne.events_from_annotations(ab13_2)\n",
    "\n",
    "eventsab28_1 = mne.events_from_annotations(ab28_1)\n",
    "eventsab28_2 = mne.events_from_annotations(ab28_2)\n",
    "\n",
    "eventsab31_1 = mne.events_from_annotations(ab31_1)\n",
    "eventsab31_2 = mne.events_from_annotations(ab31_2)\n",
    "\n",
    "eventsab32_1 = mne.events_from_annotations(ab32_1)\n",
    "eventsab32_2 = mne.events_from_annotations(ab32_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating event id Dictionary\n",
    "event_id = {\n",
    "    \"taskstart\" : '9',\n",
    "    \"cue\" : \"1\",\n",
    "    \"go\" : \"2\",\n",
    "    \"button press\" : \"5\",\n",
    "    \"no-go\" : \"4\",\n",
    "    \"task end\": \"10\",\n",
    "    \"error 1\" : \"3\",\n",
    "    \"error 2\" : \"6\",\n",
    "    \"error 3\" : \"7\",\n",
    "    \"error 4\" : \"8\",\n",
    "    \"error 5\" : \"11\"\n",
    "}\n",
    "event_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "Not setting metadata\n",
      "155 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "153 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "154 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "158 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "153 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "153 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "154 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "157 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "155 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "159 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "167 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "154 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n"
     ]
    }
   ],
   "source": [
    "#Creating epochs\n",
    "\n",
    "epochsab10_1 = mne.Epochs(ab10_1,\n",
    "                   events = eventsab10_1[0],\n",
    "                   event_id = eventsab10_1[1],)\n",
    "epochsab10_2 = mne.Epochs(ab10_2,\n",
    "                   events = eventsab10_2[0],\n",
    "                   event_id = eventsab10_2[1],)\n",
    "\n",
    "epochsab12_1 = mne.Epochs(ab12_1,\n",
    "                   events = eventsab12_1[0],\n",
    "                   event_id = eventsab12_1[1],)\n",
    "epochsab12_2 = mne.Epochs(ab12_2,\n",
    "                   events = eventsab12_2[0],\n",
    "                   event_id = eventsab12_2[1],)\n",
    "\n",
    "epochsab13_1 = mne.Epochs(ab13_1,\n",
    "                   events = eventsab13_1[0],\n",
    "                   event_id = eventsab13_1[1],)\n",
    "epochsab13_2 = mne.Epochs(ab13_2,\n",
    "                   events = eventsab13_2[0],\n",
    "                   event_id = eventsab13_2[1],)\n",
    "\n",
    "epochsab28_1 = mne.Epochs(ab28_1,\n",
    "                   events = eventsab28_1[0],\n",
    "                   event_id = eventsab28_1[1],)\n",
    "epochsab28_2 = mne.Epochs(ab28_2,\n",
    "                   events = eventsab28_2[0],\n",
    "                   event_id = eventsab28_2[1],)\n",
    "\n",
    "epochsab31_1 = mne.Epochs(ab31_1,\n",
    "                   events = eventsab31_1[0],\n",
    "                   event_id = eventsab31_1[1],)\n",
    "epochsab31_2 = mne.Epochs(ab31_2,\n",
    "                   events = eventsab31_2[0],\n",
    "                   event_id = eventsab31_2[1],)\n",
    "\n",
    "epochsab32_1 = mne.Epochs(ab32_1,\n",
    "                   events = eventsab32_1[0],\n",
    "                   event_id = eventsab32_1[1],)\n",
    "epochsab32_2 = mne.Epochs(ab32_2,\n",
    "                   events = eventsab32_2[0],\n",
    "                   event_id = eventsab32_2[1],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for 155 events and 351 original time points ...\n",
      "0 bad epochs dropped\n",
      "Loading data for 155 events and 351 original time points ...\n"
     ]
    }
   ],
   "source": [
    "epochsab10_1.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to fix event ids\n",
    "def get_keys_from_value(d, val):\n",
    "    return [k for k, v in d.items() if v == val]\n",
    "def fix_event_ids(epochsab, eventsab):\n",
    "    for i in range(epochsab.events.shape[0]):\n",
    "        epochsab.events[i][2] = int(get_keys_from_value(eventsab[1], epochsab.events[i][2])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix event ids\n",
    "fix_event_ids(epochsab10_1, eventsab10_1)\n",
    "fix_event_ids(epochsab12_1, eventsab12_1)\n",
    "fix_event_ids(epochsab13_1, eventsab13_1)\n",
    "fix_event_ids(epochsab28_1, eventsab28_1)\n",
    "fix_event_ids(epochsab31_1, eventsab31_1)\n",
    "fix_event_ids(epochsab32_1, eventsab32_1)\n",
    "fix_event_ids(epochsab10_2, eventsab10_2)\n",
    "fix_event_ids(epochsab12_2, eventsab12_2)\n",
    "fix_event_ids(epochsab13_2, eventsab13_2)\n",
    "fix_event_ids(epochsab28_2, eventsab28_2)\n",
    "fix_event_ids(epochsab31_2, eventsab31_2)\n",
    "fix_event_ids(epochsab32_2, eventsab32_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Machine learning for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading important libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Softmax\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for 155 events and 351 original time points ...\n",
      "0 bad epochs dropped\n",
      "Loading data for 153 events and 351 original time points ...\n",
      "0 bad epochs dropped\n",
      "Loading data for 154 events and 351 original time points ...\n",
      "0 bad epochs dropped\n",
      "Loading data for 158 events and 351 original time points ...\n",
      "0 bad epochs dropped\n",
      "Loading data for 153 events and 351 original time points ...\n",
      "0 bad epochs dropped\n",
      "Loading data for 153 events and 351 original time points ...\n",
      "0 bad epochs dropped\n",
      "Loading data for 154 events and 351 original time points ...\n",
      "0 bad epochs dropped\n",
      "Loading data for 157 events and 351 original time points ...\n",
      "0 bad epochs dropped\n",
      "Loading data for 155 events and 351 original time points ...\n",
      "0 bad epochs dropped\n",
      "Loading data for 159 events and 351 original time points ...\n",
      "0 bad epochs dropped\n",
      "Loading data for 167 events and 351 original time points ...\n",
      "0 bad epochs dropped\n",
      "Loading data for 154 events and 351 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "#Getting epoch data\n",
    "\n",
    "dataab10_1 = epochsab10_1.get_data()\n",
    "dataab10_2 = epochsab10_2.get_data()\n",
    "dataab12_1 = epochsab12_1.get_data()\n",
    "dataab12_2 = epochsab12_2.get_data()\n",
    "dataab13_1 = epochsab13_1.get_data()\n",
    "dataab13_2 = epochsab13_2.get_data()\n",
    "dataab28_1 = epochsab28_1.get_data()\n",
    "dataab28_2 = epochsab28_2.get_data()\n",
    "dataab31_1 = epochsab31_1.get_data()\n",
    "dataab31_2 = epochsab31_2.get_data()\n",
    "dataab32_1 = epochsab32_1.get_data()\n",
    "dataab32_2 = epochsab32_2.get_data()\n",
    "\n",
    "\n",
    "# data10_1 = ab10_1.get_data()\n",
    "# data10_2 = ab10_2.get_data()\n",
    "# data12_1 = ab12_1.get_data()\n",
    "# data12_2 = ab12_2.get_data()\n",
    "# data13_1 = ab13_1.get_data()\n",
    "# data13_2 = ab13_2.get_data()\n",
    "# data28_1 = ab28_1.get_data()\n",
    "# data28_2 = ab28_2.get_data()\n",
    "# data31_1 = ab31_1.get_data()\n",
    "# data31_2 = ab31_2.get_data()\n",
    "# data32_1 = ab32_1.get_data()\n",
    "# data32_2 = ab32_2.get_data()\n",
    "\n",
    "# print(\"shape from ab10_1 data epochs : \", dataab10_1.shape)\n",
    "# print(\"shape from ab10_1 data directly: \", data10_1.shape)\n",
    "\n",
    "\n",
    "# data12_1 = ab12_1.get_data()\n",
    "# data12_1 = data12_1.transpose()\n",
    "# data12_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1872, 66, 351)\n",
      "351 X 66\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1872, 351, 66)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Concatenating data\n",
    "data = np.concatenate([dataab10_1, dataab10_2,\n",
    "                      dataab12_1, dataab12_2,\n",
    "                      dataab13_1, dataab13_2,\n",
    "                      dataab28_1, dataab28_2,\n",
    "                      dataab31_1, dataab31_2,\n",
    "                      dataab32_1, dataab32_2], \n",
    "                      axis = 0)\n",
    "print(data.shape)\n",
    "\n",
    "#Changing the shape of data from (events, channel, time points) to (events, time points, channel)\n",
    "datars = np.zeros((data.shape[0], data.shape[2], data.shape[1]))\n",
    "for i in range(datars.shape[0]):\n",
    "    datars[i] = np.transpose(data[i])\n",
    "    \n",
    "dims_lstm_1 = datars.shape[1]\n",
    "dims_lstm_2 = datars.shape[2]\n",
    "print(dims_lstm_1, \"X\", dims_lstm_2)\n",
    "datars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1872, 23166)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "23166"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_trials = data.shape[0]\n",
    "\n",
    "\n",
    "data = data.reshape(n_trials, -1)\n",
    "print(data.shape)\n",
    "dims_ip = data.shape[1]\n",
    "dims_ip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting y\n",
    "yab10_1 = epochsab10_1.events[:, 2]\n",
    "yab10_2 = epochsab10_2.events[:, 2]\n",
    "\n",
    "yab12_1 = epochsab12_1.events[:, 2]\n",
    "yab12_2 = epochsab12_2.events[:, 2]\n",
    "\n",
    "yab13_1 = epochsab13_1.events[:, 2]\n",
    "yab13_2 = epochsab13_2.events[:, 2]\n",
    "\n",
    "yab28_1 = epochsab28_1.events[:, 2]\n",
    "yab28_2 = epochsab28_2.events[:, 2]\n",
    "\n",
    "yab31_1 = epochsab31_1.events[:, 2]\n",
    "yab31_2 = epochsab31_2.events[:, 2]\n",
    "\n",
    "yab32_1 = epochsab32_1.events[:, 2]\n",
    "yab32_2 = epochsab32_2.events[:, 2]\n",
    "\n",
    "y = np.concatenate([yab10_1, yab10_2,\n",
    "                   yab12_1, yab12_2,\n",
    "                   yab13_1, yab13_2,\n",
    "                   yab28_1, yab28_2,\n",
    "                   yab31_1, yab31_2,\n",
    "                   yab32_1, yab32_2],\n",
    "                   axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1872, 351, 66)\n",
      "(1872, 1)\n",
      "(1872, 23167)\n",
      "(1872, 23166)\n",
      "(1872,)\n"
     ]
    }
   ],
   "source": [
    "#Preparing main dataset\n",
    "y = y.reshape(-1, 1)\n",
    "# y = y[...,np.newaxis]\n",
    "datarscopy = datars.copy()\n",
    "datarscopy = datarscopy.reshape(datars.shape[0], -1)\n",
    "\n",
    "print(datars.shape)\n",
    "print(y.shape)\n",
    "main_dataset = np.concatenate((datarscopy, y), axis = 1)\n",
    "print(main_dataset.shape)\n",
    "\n",
    "#Defining main x and y for training\n",
    "main_x = main_dataset[:, :-1]\n",
    "main_y = main_dataset[:, -1]\n",
    "print(main_x.shape)\n",
    "print(main_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classfying go/no/cue/button press"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1872, 23167)\n",
      "(1796, 23167)\n",
      "(1796, 23166)\n",
      "(1796,)\n",
      "[1.0, 2.0, 4.0, 5.0]\n"
     ]
    }
   ],
   "source": [
    "#Removing events which are not needed for current task\n",
    "dataset = main_dataset.copy()\n",
    "print(dataset.shape)\n",
    "dataset = dataset[dataset[:, -1]!=9]\n",
    "dataset = dataset[dataset[:, -1]!=10]\n",
    "\n",
    "dataset = dataset[dataset[:, -1]!=3]\n",
    "dataset = dataset[dataset[:, -1]!=6]\n",
    "dataset = dataset[dataset[:, -1]!=7]\n",
    "dataset = dataset[dataset[:, -1]!=8]\n",
    "dataset = dataset[dataset[:, -1]!=11]\n",
    "\n",
    "print(dataset.shape)\n",
    "\n",
    "#Defining x and y\n",
    "x = dataset[:, :-1]\n",
    "y = dataset[:, -1]\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "print(list(set(y)))\n",
    "\n",
    "xmlp = x.copy()\n",
    "ymlp = y.copy()\n",
    "\n",
    "xlstm = x.copy().reshape((-1, dims_lstm_1, dims_lstm_2))\n",
    "ylstm = y.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 1.0, 2.0, 3.0]\n"
     ]
    }
   ],
   "source": [
    "#Encoding y\n",
    "dict = {1.0: 0,2.0: 1, 4.0: 2, 5.0: 3}\n",
    "\n",
    "for i in range(len(y)):\n",
    "    y[i] = dict[y[i]]\n",
    "    ylstm[i] = dict[ylstm[i]]\n",
    "\n",
    "print(list(set(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "num_classes = 4\n",
    "y = tf.keras.utils.to_categorical(y, num_classes)\n",
    "ymlp = y.copy()\n",
    "ylstm = y.copy()\n",
    "# yab10_1[0]\n",
    "print(y[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training on MLP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         [(None, 23166)]           0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 32)                741344    \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 4)                 68        \n",
      "=================================================================\n",
      "Total params: 741,940\n",
      "Trainable params: 741,940\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Creating model architecture\n",
    "inp_shape = (dims_ip, )\n",
    "ip = tf.keras.Input(shape = inp_shape)\n",
    "dense1 = tf.keras.layers.Dense(units = 32, activation = 'relu', kernel_initializer = 'random_normal')(ip)\n",
    "dense2 = tf.keras.layers.Dense(units = 16, activation = 'relu', kernel_initializer = 'random_normal')(dense1)\n",
    "out = tf.keras.layers.Dense(num_classes, activation = 'softmax')(dense2)\n",
    "\n",
    "mlp = tf.keras.Model(inputs = ip, outputs = out)\n",
    "mlp.summary()\n",
    "# inp_shape = (None, )\n",
    "# review_sequence = tf.keras.Input(shape = inp_shape)\n",
    "# embedding_sequence = tf.keras.layers.Embedding(input_dim=100+1, output_dim=32, input_shape=(review_sequence.shape), mask_zero=False)(review_sequence)\n",
    "# average_embedding = tf.keras.layers.GlobalAveragePooling1D()(embedding_sequence)\n",
    "# positive_probability = tf.keras.layers.Dense(units=1, activation='sigmoid')(average_embedding)\n",
    "\n",
    "# model = tf.keras.Model(inputs = review_sequence, outputs = positive_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "mlp_earlystop = EarlyStopping(patience = 50, min_delta = 0.0001, monitor = 'acc')\n",
    "\n",
    "path = 'mlp_checkpoint/checkpoint_{epoch:02d}';\n",
    "mlp_checkpoint = ModelCheckpoint(filepath = path,\n",
    "                            verbose = 1,\n",
    "                            monitor = 'acc',\n",
    "                            save_freq = 'epoch',\n",
    "                            save_best_only = True,\n",
    "                            save_weights_only = True)\n",
    "\n",
    "mlp.compile(loss = 'categorical_crossentropy', metrics = ['acc'], optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1796 samples\n",
      "Epoch 1/100\n",
      "1664/1796 [==========================>...] - ETA: 0s - loss: 1.3793 - acc: 0.3852\n",
      "Epoch 00001: acc improved from -inf to 0.38753, saving model to mlp_checkpoint/checkpoint_01\n",
      "1796/1796 [==============================] - 5s 3ms/sample - loss: 1.3786 - acc: 0.3875\n",
      "Epoch 2/100\n",
      "1792/1796 [============================>.] - ETA: 0s - loss: 1.3595 - acc: 0.4018\n",
      "Epoch 00002: acc improved from 0.38753 to 0.40089, saving model to mlp_checkpoint/checkpoint_02\n",
      "1796/1796 [==============================] - 1s 705us/sample - loss: 1.3595 - acc: 0.4009\n",
      "Epoch 3/100\n",
      "1792/1796 [============================>.] - ETA: 0s - loss: 1.3334 - acc: 0.4012- ETA: 0s - loss: 1.3411 - acc: \n",
      "Epoch 00003: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 360us/sample - loss: 1.3334 - acc: 0.4009\n",
      "Epoch 4/100\n",
      "1792/1796 [============================>.] - ETA: 0s - loss: 1.3020 - acc: 0.4007\n",
      "Epoch 00004: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 301us/sample - loss: 1.3019 - acc: 0.4009\n",
      "Epoch 5/100\n",
      "1792/1796 [============================>.] - ETA: 0s - loss: 1.2729 - acc: 0.4012\n",
      "Epoch 00005: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 297us/sample - loss: 1.2734 - acc: 0.4009\n",
      "Epoch 6/100\n",
      "1792/1796 [============================>.] - ETA: 0s - loss: 1.2596 - acc: 0.4007\n",
      "Epoch 00006: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 310us/sample - loss: 1.2594 - acc: 0.4009\n",
      "Epoch 7/100\n",
      "1792/1796 [============================>.] - ETA: 0s - loss: 1.2545 - acc: 0.4007- ETA: 0s - loss: 1.2571 - acc: 0.\n",
      "Epoch 00007: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 325us/sample - loss: 1.2542 - acc: 0.4009\n",
      "Epoch 8/100\n",
      "1728/1796 [===========================>..] - ETA: 0s - loss: 1.2541 - acc: 0.4005\n",
      "Epoch 00008: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 362us/sample - loss: 1.2526 - acc: 0.4009\n",
      "Epoch 9/100\n",
      "1792/1796 [============================>.] - ETA: 0s - loss: 1.2522 - acc: 0.4007\n",
      "Epoch 00009: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 370us/sample - loss: 1.2519 - acc: 0.4009\n",
      "Epoch 10/100\n",
      "1792/1796 [============================>.] - ETA: 0s - loss: 1.2520 - acc: 0.4012\n",
      "Epoch 00010: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 337us/sample - loss: 1.2519 - acc: 0.4009\n",
      "Epoch 11/100\n",
      "1792/1796 [============================>.] - ETA: 0s - loss: 1.2514 - acc: 0.4018\n",
      "Epoch 00011: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 298us/sample - loss: 1.2516 - acc: 0.4009\n",
      "Epoch 12/100\n",
      "1792/1796 [============================>.] - ETA: 0s - loss: 1.2510 - acc: 0.4007\n",
      "Epoch 00012: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 302us/sample - loss: 1.2514 - acc: 0.4009\n",
      "Epoch 13/100\n",
      "1792/1796 [============================>.] - ETA: 0s - loss: 1.2517 - acc: 0.4007\n",
      "Epoch 00013: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 320us/sample - loss: 1.2514 - acc: 0.4009\n",
      "Epoch 14/100\n",
      "1792/1796 [============================>.] - ETA: 0s - loss: 1.2510 - acc: 0.4001\n",
      "Epoch 00014: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 298us/sample - loss: 1.2512 - acc: 0.4009\n",
      "Epoch 15/100\n",
      "1792/1796 [============================>.] - ETA: 0s - loss: 1.2520 - acc: 0.4007\n",
      "Epoch 00015: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 307us/sample - loss: 1.2517 - acc: 0.4009\n",
      "Epoch 16/100\n",
      "1792/1796 [============================>.] - ETA: 0s - loss: 1.2522 - acc: 0.3996\n",
      "Epoch 00016: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 306us/sample - loss: 1.2514 - acc: 0.4009\n",
      "Epoch 17/100\n",
      "1792/1796 [============================>.] - ETA: 0s - loss: 1.2517 - acc: 0.4001\n",
      "Epoch 00017: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 315us/sample - loss: 1.2511 - acc: 0.4009\n",
      "Epoch 18/100\n",
      "1728/1796 [===========================>..] - ETA: 0s - loss: 1.2566 - acc: 0.3953\n",
      "Epoch 00018: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 337us/sample - loss: 1.2512 - acc: 0.4009\n",
      "Epoch 19/100\n",
      "1728/1796 [===========================>..] - ETA: 0s - loss: 1.2511 - acc: 0.4022\n",
      "Epoch 00019: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 359us/sample - loss: 1.2513 - acc: 0.4009\n",
      "Epoch 20/100\n",
      "1728/1796 [===========================>..] - ETA: 0s - loss: 1.2509 - acc: 0.4022\n",
      "Epoch 00020: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 350us/sample - loss: 1.2511 - acc: 0.4009\n",
      "Epoch 21/100\n",
      "1792/1796 [============================>.] - ETA: 0s - loss: 1.2507 - acc: 0.4012\n",
      "Epoch 00021: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 328us/sample - loss: 1.2506 - acc: 0.4009\n",
      "Epoch 22/100\n",
      "1792/1796 [============================>.] - ETA: 0s - loss: 1.2508 - acc: 0.4007\n",
      "Epoch 00022: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 301us/sample - loss: 1.2505 - acc: 0.4009\n",
      "Epoch 23/100\n",
      "1792/1796 [============================>.] - ETA: 0s - loss: 1.2508 - acc: 0.4007\n",
      "Epoch 00023: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 307us/sample - loss: 1.2505 - acc: 0.4009\n",
      "Epoch 24/100\n",
      "1792/1796 [============================>.] - ETA: 0s - loss: 1.2506 - acc: 0.4007\n",
      "Epoch 00024: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 301us/sample - loss: 1.2503 - acc: 0.4009\n",
      "Epoch 25/100\n",
      "1792/1796 [============================>.] - ETA: 0s - loss: 1.2502 - acc: 0.4012\n",
      "Epoch 00025: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 302us/sample - loss: 1.2509 - acc: 0.4009\n",
      "Epoch 26/100\n",
      "1792/1796 [============================>.] - ETA: 0s - loss: 1.2512 - acc: 0.4001\n",
      "Epoch 00026: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 308us/sample - loss: 1.2508 - acc: 0.4009\n",
      "Epoch 27/100\n",
      "1728/1796 [===========================>..] - ETA: 0s - loss: 1.2522 - acc: 0.3987\n",
      "Epoch 00027: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 325us/sample - loss: 1.2500 - acc: 0.4009\n",
      "Epoch 28/100\n",
      "1792/1796 [============================>.] - ETA: 0s - loss: 1.2489 - acc: 0.4018\n",
      "Epoch 00028: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 311us/sample - loss: 1.2499 - acc: 0.4009\n",
      "Epoch 29/100\n",
      "1792/1796 [============================>.] - ETA: 0s - loss: 1.2501 - acc: 0.4007\n",
      "Epoch 00029: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 329us/sample - loss: 1.2498 - acc: 0.4009\n",
      "Epoch 30/100\n",
      "1792/1796 [============================>.] - ETA: 0s - loss: 1.2500 - acc: 0.4012\n",
      "Epoch 00030: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 342us/sample - loss: 1.2499 - acc: 0.4009\n",
      "Epoch 31/100\n",
      "1792/1796 [============================>.] - ETA: 0s - loss: 1.2528 - acc: 0.400 - ETA: 0s - loss: 1.2503 - acc: 0.4001\n",
      "Epoch 00031: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 347us/sample - loss: 1.2498 - acc: 0.4009\n",
      "Epoch 32/100\n",
      "1792/1796 [============================>.] - ETA: 0s - loss: 1.2500 - acc: 0.4001\n",
      "Epoch 00032: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 302us/sample - loss: 1.2495 - acc: 0.4009\n",
      "Epoch 33/100\n",
      "1792/1796 [============================>.] - ETA: 0s - loss: 1.2501 - acc: 0.4007\n",
      "Epoch 00033: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 304us/sample - loss: 1.2498 - acc: 0.4009\n",
      "Epoch 34/100\n",
      "1792/1796 [============================>.] - ETA: 0s - loss: 1.2493 - acc: 0.4012\n",
      "Epoch 00034: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 337us/sample - loss: 1.2493 - acc: 0.4009\n",
      "Epoch 35/100\n",
      "1792/1796 [============================>.] - ETA: 0s - loss: 1.2496 - acc: 0.4001\n",
      "Epoch 00035: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 356us/sample - loss: 1.2491 - acc: 0.4009\n",
      "Epoch 36/100\n",
      "1664/1796 [==========================>...] - ETA: 0s - loss: 1.2454 - acc: 0.4069\n",
      "Epoch 00036: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 365us/sample - loss: 1.2490 - acc: 0.4009\n",
      "Epoch 37/100\n",
      "1792/1796 [============================>.] - ETA: 0s - loss: 1.2497 - acc: 0.4001\n",
      "Epoch 00037: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 316us/sample - loss: 1.2491 - acc: 0.4009\n",
      "Epoch 38/100\n",
      "1792/1796 [============================>.] - ETA: 0s - loss: 1.2486 - acc: 0.4012\n",
      "Epoch 00038: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 297us/sample - loss: 1.2493 - acc: 0.4009\n",
      "Epoch 39/100\n",
      "1792/1796 [============================>.] - ETA: 0s - loss: 1.2489 - acc: 0.4012\n",
      "Epoch 00039: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 308us/sample - loss: 1.2489 - acc: 0.4009\n",
      "Epoch 40/100\n",
      "1792/1796 [============================>.] - ETA: 0s - loss: 1.2488 - acc: 0.4012\n",
      "Epoch 00040: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 341us/sample - loss: 1.2488 - acc: 0.4009\n",
      "Epoch 41/100\n",
      "1728/1796 [===========================>..] - ETA: 0s - loss: 1.2526 - acc: 0.3941\n",
      "Epoch 00041: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 342us/sample - loss: 1.2486 - acc: 0.4009\n",
      "Epoch 42/100\n",
      "1792/1796 [============================>.] - ETA: 0s - loss: 1.2495 - acc: 0.3996\n",
      "Epoch 00042: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 334us/sample - loss: 1.2487 - acc: 0.4009\n",
      "Epoch 43/100\n",
      "1792/1796 [============================>.] - ETA: 0s - loss: 1.2482 - acc: 0.4007\n",
      "Epoch 00043: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 322us/sample - loss: 1.2487 - acc: 0.4009\n",
      "Epoch 44/100\n",
      "1792/1796 [============================>.] - ETA: 0s - loss: 1.2481 - acc: 0.4012\n",
      "Epoch 00044: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 314us/sample - loss: 1.2481 - acc: 0.4009\n",
      "Epoch 45/100\n",
      "1792/1796 [============================>.] - ETA: 0s - loss: 1.2482 - acc: 0.4007\n",
      "Epoch 00045: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 313us/sample - loss: 1.2480 - acc: 0.4009\n",
      "Epoch 46/100\n",
      "1792/1796 [============================>.] - ETA: 0s - loss: 1.2469 - acc: 0.4018\n",
      "Epoch 00046: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 322us/sample - loss: 1.2478 - acc: 0.4009\n",
      "Epoch 47/100\n",
      "1792/1796 [============================>.] - ETA: 0s - loss: 1.2481 - acc: 0.4001\n",
      "Epoch 00047: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 341us/sample - loss: 1.2476 - acc: 0.4009\n",
      "Epoch 48/100\n",
      "1792/1796 [============================>.] - ETA: 0s - loss: 1.2477 - acc: 0.4007\n",
      "Epoch 00048: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 344us/sample - loss: 1.2474 - acc: 0.4009\n",
      "Epoch 49/100\n",
      "1792/1796 [============================>.] - ETA: 0s - loss: 1.2477 - acc: 0.4001\n",
      "Epoch 00049: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 345us/sample - loss: 1.2472 - acc: 0.4009\n",
      "Epoch 50/100\n",
      "1792/1796 [============================>.] - ETA: 0s - loss: 1.2468 - acc: 0.4007\n",
      "Epoch 00050: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 337us/sample - loss: 1.2472 - acc: 0.4009\n",
      "Epoch 51/100\n",
      "1792/1796 [============================>.] - ETA: 0s - loss: 1.2469 - acc: 0.4007\n",
      "Epoch 00051: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 340us/sample - loss: 1.2466 - acc: 0.4009\n",
      "Epoch 52/100\n",
      "1792/1796 [============================>.] - ETA: 0s - loss: 1.2470 - acc: 0.4007\n",
      "Epoch 00052: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 341us/sample - loss: 1.2467 - acc: 0.4009\n"
     ]
    }
   ],
   "source": [
    "mlp_history = mlp.fit(xmlp, ymlp, epochs=100, batch_size = 64, callbacks = [mlp_earlystop, mlp_checkpoint]) #Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deXxd1X3v/c9Pk2UNljUZz5ZsPAKWDcYG44TB4WEIQ4HcEKAMgYT2PmXIpc0tuYGkIX3apJDbQJtCmWIgxBRIMCQQSEqYB4Mxo23wPMijLMuyZVnj+T1/rCNbliVZtnV0LO3v+/XaL+nsvc85a3PM+Wqttdda5u6IiEh0pSS7ACIiklwKAhGRiFMQiIhEnIJARCTiFAQiIhGnIBARiTgFgUSamZWYmZtZWhfOvcbM3jyM9xppZjVmlnqoryGSCAoC6TXMbLWZNZhZUZv9H8W/zEuSU7KOA8XM5pjZPwK4+1p3z3H35gO81mEFjsjBUhBIb7MKuKzlgZkdB/RPXnGOPF2p3Yi0piCQ3uYx4KpWj68GHm19gpnlmdmjZlZhZmvM7DYzS4kfSzWzu8xsq5mtBL7aznMfMrONZrbezP6xu5py2tYa4n/5rzSznWa2ysyuMLOJwH3AyfFmpO1duKZrzOwtM/tXM9sG/NjMtsVDsuW9B5nZbjMr7o5rkb5FQSC9zbvAADObGP+CvhT4VZtz/g3IA0YDpxKC45vxY98GzgOmAtOAr7V57iNAE3B0/Jz/B/hWd1+EmWUD9wDnuHsuMBP4yN2XAH8NvBNvRhrYhWsCmAGsBAYBdwBPAH/Z6vhlwH+7e0V3X4v0fgoC6Y1aagVnAp8D61sOtAqH77n7TndfDfwMuDJ+yteBn7v7OnffBvxzq+ceBZwDfMfdd7n7FuBfgW8cRNm2mtn2lg24vJNzY8CxZtbf3Te6+6L2TurCNQFscPd/c/cmd99NCLTLW2oN8XMfO4jrkAhRW6L0Ro8BrwOltGkWAoqADGBNq31rgGHx34cC69ocazEKSAc2mlnLvpQ25x9Ikbs3tTwwszntneTuu8zsUuDvgIfM7C3gb9398/Zek86vibZldPf5ZrYLONXMNhJqOM8dxHVIhKhGIL2Ou68hdBqfC/y2zeGtQCPhS73FSPbWGjYCI9oca7EOqCd8mQ+MbwPc/ZjuLH8Ld3/J3c8EhhBqNg+0HGpz6oGuqb3nQKgV/CWhNvC0u9d1R7ml71EQSG91HXCGu+9qvTN+a+aTwP9nZrlmNgq4hb39CE8CN5nZcDPLB25t9dyNwB+Bn5nZADNLMbMxZnZqdxfezI4yswvifQX1QA3QclvpZmC4mWV08Zo68hhwESEM2tacRPZQEEiv5O4r3H1BB4dvBHYROk/fBH4NPBw/9gDwEvAxsJD9axRXEZphFgNVwNOEv9i7Wwrwt8AGYBuhA/j/jR/7M7AI2GRmW+P7Orumdrl7OeEaHXijm8svfYhpYRqRvsvMHiZ0JN+W7LLIkUudxSJ9VHyk9cWE22BFOqSmIZE+yMx+DHwG3Onuq5JdHjmyqWlIRCTiVCMQEYm4XtdHUFRU5CUlJckuhohIr/LBBx9sdfd255rqdUFQUlLCggUd3TUoIiLtMbM1HR1LWNOQmT1sZlvM7LMDnHeimTWbWdvJv0REpAckso9gDnB2ZyfEJ9P6KWGAj4iIJEHCgsDdXyeMmOzMjcBvgC2JKoeIiHQuaX0EZjaMMA/KGcCJBzj3euB6gJEjR3Z2qoj0Yo2NjZSXl1NXp/nxDlVmZibDhw8nPT29y89JZmfxz4G/d/fmVlP+tsvd7wfuB5g2bZoGPoj0UeXl5eTm5lJSUsKBvhdkf+5OZWUl5eXllJaWdvl5yQyCacAT8Q+7CDjXzJrcfV4SyyQiSVRXV6cQOAxmRmFhIRUVB7cQXdKCwN33xFV88Y7fKwRERCFweA7lv18ibx+dC7wDjDezcjO7zsz+2sz+OlHv2anKFfCHW6G5MSlvLyJypEpYjcDdLzuIc69JVDn22LoM5t8LR02C469K+NuJSO/1zDPPcPHFF7NkyRImTJiQ7OIkXHTmGhp3Fgw9Hl6/E5oakl0aETmCzZ07l1mzZvHEE08k7D2am5sPfFIPiU4QmMFp34Pta+HjXye7NCJyhKqpqeGtt97ioYce2icI/uVf/oXjjjuOsrIybr01rHC6fPlyvvKVr1BWVsbxxx/PihUrePXVVznvvPP2PO+GG25gzpw5QJgi54477mDWrFk89dRTPPDAA5x44omUlZVxySWXUFtbC8DmzZu56KKLKCsro6ysjLfffpvbb7+du+++e8/rfv/73+eee+7plmvudXMNHZaxZ8KwafD6XVB2OaRlJLtEItKBH/1uEYs37OjW15w0dAA/PP+YTs+ZN28eZ599NuPGjaOgoICFCxeyefNm5s2bx/z588nKymLbtjBW9oorruDWW2/loosuoq6ujlgsxrp16zp9/czMTN58800AKisr+fa3vw3AbbfdxkMPPcSNN97ITTfdxKmnnsozzzxDc3MzNTU1DB06lIsvvpibb76ZWCzGE088wXvvvdcN/1WiFgQttYLHL4GPfgXTrk12iUTkCDN37ly+853vAPCNb3yDuXPnEovF+OY3v0lWVhYABQUF7Ny5k/Xr13PRRRcB4Qu+Ky699NI9v3/22WfcdtttbN++nZqaGs466ywA/vznP/Poo48CkJqaSl5eHnl5eRQWFvLhhx+yefNmpk6dSmFhYbdcc7SCAODo2TD8RHj9ZzDlCkjrl+wSiUg7DvSXeyJUVlby5z//mc8++wwzo7m5GTPjkksu2e+2zI4W9UpLSyMWi+153HaUdHZ29p7fr7nmGubNm0dZWRlz5szh1Vdf7bR83/rWt5gzZw6bNm3i2mu77w/Z6PQRtGipFewoh4/nJrs0InIEefrpp7nqqqtYs2YNq1evZt26dZSWllJQUMDDDz+8pw1/27ZtDBgwgOHDhzNvXhj+VF9fT21tLaNGjWLx4sXU19dTXV3Nyy+/3OH77dy5kyFDhtDY2Mjjjz++Z//s2bO59957gdCpvGNHaCK76KKLePHFF3n//ff31B66Q/SCAGDMGTCkDN7+N2iV3CISbXPnzt3T1NPikksuYcOGDVxwwQVMmzaNKVOmcNdddwHw2GOPcc899zB58mRmzpzJpk2bGDFiBF//+teZPHkyV1xxBVOnTu3w/X784x8zY8YMzjzzzH1uU7377rt55ZVXOO644zjhhBNYtGgRABkZGZx++ul8/etfJzU1tduuu9etWTxt2jTvloVpPvsNPH0tXPo4TDzvwOeLSMItWbKEiRMnJrsYR6xYLMbxxx/PU089xdixYzs8r73/jmb2gbtPa+/8aNYIACZeCANHwVs/h14WhiISPYsXL+boo49m9uzZnYbAoYheZ3GL1DSYeSO88Hew9l0YdXKySyQi0qFJkyaxcuXKhLx2dGsEEO4ayiqEt+4+8LkiIn1UtIMgIwum/xUs/QNs6nRpZRGRPivaQQAw/dvQvwCev0V3EIlIJCkIsgrg7H+GdfPh/QeTXRoRkR6nIACYfGkYW/Dyj2B75/OEiEjflpOTk+wi9DgFAYTRxuf9HDwWmoh0O6mIRIiCoEX+KDjjdlj2xzDiWEQkbs2aNcyePZvJkycze/Zs1q5dC8BTTz3FscceS1lZGV/+8pcBWLRoEdOnT2fKlClMnjyZZcuWJbPoXRLdcQTtmfFXsO5d+NPt0LALTrs11BZEpOf94VbY9Gn3vubg4+Ccnxz002644Qauuuoqrr76ah5++GFuuukm5s2bxx133MFLL73EsGHD2L59OwD33XcfN998M1dccQUNDQ1H1AI0HVGNoLWUVLjk4TC+4LWfwEv/R81EIsI777zD5ZdfDsCVV165Zz2BU045hWuuuYYHHnhgzxf+ySefzD/90z/x05/+lDVr1tC/f/+klburVCNoKzUNLvh36DcA3v0PqPgcvvozKBid7JKJRMsh/OXeU1qmpL7vvvuYP38+zz//PFOmTOGjjz7i8ssvZ8aMGTz//POcddZZPPjgg5xxxhlJLnHnVCNoT0pKuKX03Ltg3fvwHyfDa3dCU32ySyYiSTBz5sw9y1Y+/vjjzJo1C4AVK1YwY8YM7rjjDoqKili3bh0rV65k9OjR3HTTTVxwwQV88sknySx6l6hG0BGzMNhswlfhxe/BK/8I7z8Q9p1wLWR3z8pAInJkqa2tZfjw4Xse33LLLdxzzz1ce+213HnnnRQXF/PLX/4SgO9+97ssW7YMd2f27NmUlZXxk5/8hF/96lekp6czePBgfvCDHyTrUrosutNQH6yVr8Hb98Dy/4a0TBh3Fow+LWz5pepUFukGmoa6exzsNNSqEXTV6FPDtmUJzP9PWPoSLH42HEvPDjWErCLoPxAysiEjJ2yZeWHrlxvflxWWx7RUsHjLXKwRmpvAm8OxtMy9W3r/+O/9IDVj708Fj4h0EwXBwRo0Ec6Pr2FQuRxWvgrbVkHtVti1FeqqYcdGaNwFdTugfkcYqNatDNKzID0zHigW9qWkQWp62NL7Q0Yu9IsHUsvPPcHSEi7pewMmIyeEWGoGNDeGgEpJgwHDwpaW0c3XISJHAgXBoTKDorFh64w71O8MW2NtGJ/QVBf2ewxwSIl/eVsKNDdA4+5wTlMdNNZB025oaoDm+vj++nBO4+5Qi3APrxNrDl/gzfHjDbtgxwZoqAm/19eEgDq0C4bsohAU6VkhUNKzwpaRFWpFGVnheHYx5A6GnMHx2lBOuAurX264TpFOuPt+C8VL1x1Kc7+CINHMIHNA2I4E7iFsWgKl5S//xroQFg014XhqegioWCNUl4dtx4Z4ANXGtzqo2QQNtfHgiQdOrLHj98/IgcyBe2sjKWlhTYj8krDljYCcQfEgGRTO1ZdCZGRmZlJZWUlhYaHC4BC4O5WVlWRmZh7U8xQEUWMW74fol5jXd4fdVVCzGXZuCk1j9TWhRlRXDXXbYff2UGtpboRYUzj3899DbeX+r5faD3KPgpz4ljsYcoeEpqq84eH3zAGhxpF+cP/45cgzfPhwysvLqaioSHZReq3MzMx97nrqCgWBdC+zMLV3VkHoTzkY9TtD/0rN5r3bzk17f1Yuh9VvhjBpT0YODJoUphE4ahLkjYS8eGBk5h3+tUnCpaenU1pamuxiRI6CQI4c/XKhOBeKx3V+XkNtaKbasT6ERF112Go2w+ZF8OlTsGDHvs/JKgr9OQVjQjAMGBpqFYVjYOCoMIhQJKIUBNL7ZGRB0dFha4/73qCoXhfWmNi2AipXwPI/Qc0WoFWHWlpmCIn8Uhg4MmwFo0NI5I0M046I9GEJ+xduZg8D5wFb3P3Ydo5fAfx9/GEN8D/d/eNElUcixCzeJDQMRkzf/3hzY2hq2rEeti6Fii/i2+dhGvKmur3npqSHfoicQWErGA1Dp4Ytv1Q1CekTEvmnzhzg34FHOzi+CjjV3avM7BzgfmBGAssjEqSmw8ARYRt50r7H3GFXBWxbGfokKpfv7beoWgPLXw4d3RDGWwwYCgOGhzueisdD8YTQtDVguGoS0msk7F+qu79uZiWdHH+71cN3gYPr5hZJBLO9f/23DQkItYktS2DDh6G5qXp9qFks/xN89Ku956WkhVthC0pDLaL1ll+SuLu2RA7BkfIny3XAH5JdCJEDSk2HIZPD1lbtttDEtHUpbF8TRpxvWwnlH0B9dasTLYRE8XgYNAGKJ0LRuNBP0X9gj12KSIukB4GZnU4IglmdnHM9cD3AyJEje6hkIgcpqwBGnRy21lrGVlSugKpV4Wfl8hAaq17f29QEkD0oBELh0Xs7sPNLwlKq/XJ79HIkOpIaBGY2GXgQOMfd2xlNFLj7/YQ+BKZNm9a7pksVaT22YsSJ+x5rboKq1VC5LNQkti6FrcvbH2CXVRRCoaA03PKaPyrc4ZRdHAbUtUxuqBG5cpCSFgRmNhL4LXCluy9NVjlEkio1be+tsOPP2fdY7bbQxFS1OjQzVa0O27r58NlvwzxTbfXL29vkVDQu3i8xBvrnh6lDmhvCtB1aT0NaSeTto3OB04AiMysHfgikA7j7fcAPgELgP+JzijR1NFe2SCS11CKGTt3/WHNj6KTevjbUHOp2hEF1VatDk9Pnz0NtRzfsEUZgl3wJhk8Ldz7lDglbRlbCLkeOXFqYRqSv2l0Vvw12ZeisTo2vZbFjPax+A9a8E2a2bS1v5N5ZdfNLQzPUgKGAhXmhUtJCTUNTkvc6WphGJIr658OwE8LW1pduCVObb1sRBtft3BRGYbf0Uyx8t+Mpy9Myw2uOmBFCoWXm2OxijZ3opfSpiURVWkaYGLC9yQHdw0JLVavCdB2WAimpYbrx9Qth7Tvw1t3791P0z987r9PgyWECwMKjw+C9jOyeuS45aAoCEdmfGeQUh62t474WfjbVh3mcqlbD9tVQUxFW6qvZEqbr+OIP7DOnU//8EAqDJoWt8OgwAWDe8LB4kSSNgkBEDk1av84n/2vYBZsXhzuftq+NNz0tgyW/g4WP7HtudjEUjQ93PLXc7VQ4Jtweq1XtEk5BICKJkZEdxk20HTvhHmoNVatDOFSvC4PsKr6AT5/edxR2Slrofyg8OoRDy91NecPDmhNaZ6JbKAhEpGeZhVXnco9iv3kmW/omtq3YO/Hf1mXh56rXwxKpreWXhGamAUPjq9cNjU/+N14jsQ+CgkBEjhyt+ybamxm2fke4w6lqDWz+FDZ9GmoSa98Jt8u2ljcivg0LP0tmhbETuvV1PxpHICJ9Q2NdGCNR8TlsWQwVS6G6POzbsQFijWEqjqO/EqbnyMgJTUslsw5+WdVeSOMIRKTvS88MHcyFY2DCV/c91rgbVr4aRlwvfxmWPBcGyLUYNg2OvxImnAfZRT1a7COBagQiEj3u4fbX2q2w+FlY+BhULAnHCsaEZqmicZBzVGimOurY0AfRi3VWI1AQiIi4w4aFsOqNMKnfuvn7z/46fDpMPB/GnB7uYkrvn5yyHiI1DYmIdMZs3+k43KGhJtzmWrMZ1rwVxj/86Xb4E4CFMQ5DJsO4c2Dc2b16RlfVCEREuqpqDaxfEG5prfgC1r4LO+NTcAybBqNmwsiTYcT0MHPsEUQ1AhGR7pAfXxCohTts/Ag+fwFWvgLv/ALe+nk4ljM4rAsxpAzKLjui70xSjUBEpLs01ML6D8JW8TlsWQKbF4VbV0ecFO5MGjUzTPHdwyvJqUYgItITMrKg9Etha7GrEj7+NXwwB579m7Cvfz4MPT40I406OfRNJLHzWTUCEZGe4B5GQq//INyhVL4gDHyDsGBQyZfCcqXjzg7Tdncz3T4qInIkqt0WblVd9QYsfTHMsQRhDEPpl8OoZ0uFXVvCHUzDp8PYrxzSWykIRER6g63LQiCsfA3WvN1mlTgLK8vN/sEhvbT6CEREeoOW9aJn3gjNjaEpKSUtjHDOKkzYUqAKAhGRI1FqOgw7vkfeKqVH3kVERI5YCgIRkYhTEIiIRJyCQEQk4hQEIiIRpyAQEYk4BYGISMQpCEREIk5BICIScQoCEZGIUxCIiERcwoLAzB42sy1m9lkHx83M7jGz5Wb2iZn1zKQaIiKyj0TWCOYAZ3dy/BxgbHy7Hrg3gWUREZEOJCwI3P11YFsnp1wIPOrBu8BAMxuSqPKIiEj7ktlHMAxY1+pxeXzffszsejNbYGYLKioqeqRwIiJRkcwgsHb2tbtcmrvf7+7T3H1acXFxgoslIhItyQyCcqD1Cs3DgQ1JKouISGQlMwieA66K3z10ElDt7huTWB4RkUhK2FKVZjYXOA0oMrNy4IdAOoC73we8AJwLLAdqgW8mqiwiItKxhAWBu192gOMO/E2i3l9ERLpGI4tFRCJOQSAiEnEKAhGRiFMQiIhEnIJARCTiFAQiIhF3wCAws6PM7CEz+0P88SQzuy7xRRMRkZ7QlRrBHOAlYGj88VLgO4kqkIiI9KyuBEGRuz8JxADcvQloTmipRESkx3QlCHaZWSHxmUFb5gVKaKlERKTHdGWKiVsIE8SNMbO3gGLgawktlYiI9JgDBoG7LzSzU4HxhDUEvnD3xoSXTEREesQBg8DMrmqz63gzw90fTVCZRESkB3WlaejEVr9nArOBhYCCQESkD+hK09CNrR+bWR7wWMJKJCIiPepQRhbXAmO7uyAiIpIcXekj+B17F5VPASYBTyayUCIi0nO60kdwV6vfm4A17l6eoPKIiEgP60ofwWs9URAREUmODoPAzHayt0lon0OEJYcHJKxUIiLSYzoMAnfP7cmCiIhIcnSljwAAMxtEGEcAgLuvTUiJRESkR3VlPYILzGwZsAp4DVgN/CHB5RIRkR7SlXEEPwZOApa6eylhZPFbCS2ViIj0mK4EQaO7VwIpZpbi7q8AUxJcLhER6SFd6SPYbmY5wBvA42a2hTCeQERE+oAOawRm9u9mdgpwIWFaie8ALwIrgPN7pngiIpJondUIlhFGFQ8B/guY6+6P9EipRESkx3RYI3D3u939ZOBUYBvwSzNbYma3m9m4HiuhiIgk1AE7i919jbv/1N2nApcDFwNLEl4yERHpEV0ZR5BuZueb2eOE8QNLgUsSXjIREekRnXUWn2lmDwPlwPXAC8AYd7/U3ed15cXN7Gwz+8LMlpvZre0cH2lmr5jZh2b2iZmde6gXIiIih6azzuL/A/wa+Dt333awL2xmqcAvgDMJYfK+mT3n7otbnXYb8KS732tmkwhhU3Kw7yUiIoeus0nnTj/M154OLHf3lQBm9gThVtTWQeBAyyymecCGw3xPERE5SF2edO4QDAPWtXpcDsxoc84/AH80sxuBbOArCSyPiIi041DWLO4qa2df2/UNLgPmuPtw4FzgMTPbr0xmdr2ZLTCzBRUVFQkoqohIdCUyCMqBEa0eD2f/pp/riK9/7O7vEKa5Lmr7Qu5+v7tPc/dpxcXFCSquiEg0JTII3gfGmlmpmWUA3wCea3POWsJsppjZREIQ6E9+EZEelLAgcPcm4AbgJcIAtCfdfZGZ3WFmF8RP+1vg22b2MTAXuMbd21seU0REEiSRncW4+wuEW0Jb7/tBq98XA6cksgwiItK5RDYNiYhIL6AgEBGJOAWBiEjEKQhERCJOQSAiEnEKAhGRiFMQiIhEnIJARCTiFAQiIhGnIBARiTgFgYhIxCkIREQiTkEgIhJxCgIRkYhTEIiIRJyCQEQk4hQEIiIRpyAQEYk4BYGISMQpCEREIk5BICIScQoCEZGIUxCIiEScgkBEJOIUBCIiEacgEBGJOAWBiEjEKQhERCJOQSAiEnEKAhGRiFMQiIhEnIJARCTiEhoEZna2mX1hZsvN7NYOzvm6mS02s0Vm9utElkdERPaXlqgXNrNU4BfAmUA58L6ZPefui1udMxb4HnCKu1eZ2aBElUdERNqXyBrBdGC5u6909wbgCeDCNud8G/iFu1cBuPuWBJZHRETakcggGAasa/W4PL6vtXHAODN7y8zeNbOz23shM7vezBaY2YKKiooEFVdEJJoSGQTWzj5v8zgNGAucBlwGPGhmA/d7kvv97j7N3acVFxd3e0FFRKIskUFQDoxo9Xg4sKGdc55190Z3XwV8QQgGERHpIYkMgveBsWZWamYZwDeA59qcMw84HcDMighNRSsTWCYREWkjYUHg7k3ADcBLwBLgSXdfZGZ3mNkF8dNeAirNbDHwCvBdd69MVJlERGR/5t622f7INm3aNF+wYEGyiyEi0quY2QfuPq29YxpZLCIScQoCEZGIUxCIiPQCNfVN1Dc1J+S1FQQiIke4lxZt4sz/+xr3vZqYmyoTNteQiIgcnvXbd/PDZxfx30s2M2FwLrPGFiXkfRQEIiJHkMbmGK8vreC3C9fzpyWbSTG49ZwJXDerlPTUxDTiKAhERHpA9e5GXl9aQWqKkZmeQmpKChU769lUvZuN1XVsqq5jQ3Ud5dtq2VnfREF2BpdPH8l1s0oZUZCV0LIpCEREDtOu+iY27aijtDCblJR9p1mrqW9izluruP/1leyoa2r3+flZ6QzJ68/QvExOGDWQ08YN4tTxxQmrAbSlIBAR6aJtuxqobWhieH74Cz0Wc575cD0/efFzKnbWk5+VzsljChk7KJetNfVsqq5j4doqqmob+crEQfzVqWPIzUxjd0MzTTGnOKcfg/MyyUxPTep1KQhEJPJ21DXyWXk1/dJTKC3KIT8rHbPwl727886KSh5/by1/XLSJxmZneH5/Zo4pZNmWGj5cu50pIwZy8+yxfLh2O2+v2MoLn24iPyudwXn9mXl0Ed+aVcrUkflJvsqOKQhEJHJ21Tfx5vKtvPpFBR+s2cayLTW0nm1nQGYaWRlp7G5sZndjMw1NMfL6p3PVySWMyO/POysreWnRZtJTU7jza5O55PjhpKQYf3nSKNydhuYY/dKS+1f+wVAQiEif5e7srG9ifdVuvti0kyUbd/Dp+moWrK6ioTlGbr80ppXkc97koZSNGEgs5qzcuovVW3fR0BQjMz2FzPRUJgzJ5Zxjh+xpwrnmlFJisZAcbfsEzKxXhQAoCESkF4jFnJg7aW06T5uaY2zZWc+QvMw9TTnVtY088f5anvlwPeu21bKrYe9o3IzUFMYelcPVM0dx+oRBnFhSsF+H7OldLFPbAOjNFAQi0uNisdB80iIjNWXPF2tdYzOvfrGFFz7dxKfrq6mqbaB6dyPpqSmcMDKfmWMKGTKwP28sq+C1pRVsr21kYFY6U0YMpCinH89/spHdjc1MLyng0hNHMiQvk8F5mYw7KpfRxdk9didOb6IgEJEuaY45izZU0y8tlfysdAZmZZCRtu+X6obtu3lywTqyM9KYOGQAE4bk0hxzNlbXsXH7bhZt2MHCtVV8vG77Pn+pm0Fe/3TyszLYvKOO2oZmCrIzOGl0AYXZ/cjPSmdXQzPvrKjkZ39aCkBhdgZnTBjEccPy+HzjTj5cV8X8lds497ghXDurhGOG5vXof5/eTEEgIp1qaIox78P13PvaClZt3bVnf4rB1JH5nDFhEFNHDuTZDzfw2w/LaYo5HS1zkppiTBoygFwcL2wAAAxKSURBVEtOGM7gvMw9++samqmqbaSqtoFTji7knGOHMKO0YL+mIICqXQ1s2lHH+KNy+1TzTDIpCEQipjnmpB7gC7S6tpH5qyp5e0Ulf1y0iQ3VdRwzdAB3/Y8yMtNTqKptZOP23byxbCt3vvQFAP3SUrh8+kiuP3UMmWkpLNm4ky8276RfWgqDB4TmmTHFOfTPOLyO1PzsDPKzMw7rNWRfWqFMpI/ZtquBv37sA9JSjZ9eMnnP9AQrKmq4+YkPWVWxiwunDuPy6SM5ZugANlbXsWTjjvgW7qxZVbkLd8hMT2FGaSHfPKWEU8cV7+mQbW3LjjBo6oRRBRTn9uvpy5Uu6myFMgWBSB+yfvturnxoPuurdpORmoIDPzx/Eilm3P7sZ/RLS+FLY4v54+JN1DXGyM5I3aetfmRBFhOH5HLM0DxOGl1I2Yi8XncrpLSvsyBQ05BIL1Kxs57ffbyBdVW1bK9tZHttA0U5/Zg4ZABDB/bnR79bRE19E49dN4OhAzO55cmP+e7TnwAwo7SAu78xlcF5mVTXNvLbD8tZUVHD+KNymThkAOMH55KbmZ7kK5RkUI1A5AhU29DEa19U0Bhz+qen0hxzfvfJhj1THOT0S2NgVjp5/dPZVF1H5a4GAIpz+/HIN6czaegAIPQHPPbOahqaY1w3a/QB+wak71KNQKSX2FRdxyPvrObX89dSvbtxn2MDs9K5+uQSLpsxkjHFOXv2uzsVO+tZurmG8YNz92mnT00xrjmltKeKL72UgkAkSbbsrOPFzzbxxrKtbNi+e89f9ikGZx0zmKtOLqE4N4O6xhgNzTEmDRnQ7iyVZsagAZkMGpDZzruIHJiCQKQHvLxkM/M+2rBnfpotO+tYsKYKdygpzGJ0cQ5lIwYybGB/LigbmvCFSERaUxCIHKaWEbcfrt3OwrVVNMec88uGcvr4Qeyqb+JHv1vEvI82UJzbj7z+oTM2OyOVm2eP5avHDWHsUblJvgKJOgWByGGoa2zmqoff471V2wA4akA/mmPw+082kp+VTooZ1bsbuWn2WG44/ej9pmQQORIoCEQOUSzm3PLkR7y3ahu3nzeJc44dzJC8TJpjzhvLt/KbD8rZUdfE3589XvPeyBFNQSByiP7phSW88Okmvn/uRK6btffOnLRU4/Txgzh9/KAklk6k6xQEIgfJ3bnvtZU8+OYqrplZwre+pNszpXdTEIgchOraRv73bz7mpUWb+erkIdx+3qR2598R6U0UBCLtcHfeWl7J4/PX0Ngco7Qom8F5/Xn4zVVs3lG3pzlI0yBLX5DQIDCzs4G7gVTgQXf/SQfnfQ14CjjR3TV/hPSI+qZm5q/cxitfbOGdFZVkZaRSWpTD0IGZ/HHRZr7YvJOinAwKs/vxxrKt1DfFGFmQxW/+50zKRgxMdvFFuk3CgsDMUoFfAGcC5cD7Zvacuy9uc14ucBMwP1Flkb5vR10j5dt24+w/d1ZdY4ylm3fy+cYdLN1cQ+WueqriE7Y1Njv90lKYXlpAY3OMN5dXsHlHPRMG53Ln1yZzftlQMtNTicWczTvrKMjO0Gyc0uckskYwHVju7isBzOwJ4EJgcZvzfgz8C/B3CSzLHo3NMdZtq6W8ajfNvWzCvT7Pw+ezu7GZ+sYYTbG9n09TLEZdYzO7G2LUNTVT1xi2rTUNLNm4g/Kq3Qd8+Zx+aYw7KofSomyOzwqLm5xYks/Jo4v2WSylvqmZjNSUfdr+U1KMIXn9u/d6RY4QiQyCYcC6Vo/LgRmtTzCzqcAId/+9mSU0CF75fAs/+t0i1lXtpjmmAOjN0lONzLRUMjNSGdg/LFp+2fSRlBZltzu7ZnqqMaY4hxH5WV1q09df/BI1iQyC9v6P2/MNbGYpwL8C1xzwhcyuB64HGDly5CEVpiA7g2OG5XF+2VBKCrMZUZBFeqo6+o406akpZKankpmeQnqr9WpTUyzsT0tpdx1bETl0CVuPwMxOBv7B3c+KP/4egLv/c/xxHrACqIk/ZTCwDbigsw5jrUcgInLwOluPIJF/Wr0PjDWzUjPLAL4BPNdy0N2r3b3I3UvcvQR4lwOEgIiIdL+EBYG7NwE3AC8BS4An3X2Rmd1hZhck6n1FROTgJHQcgbu/ALzQZt8POjj3tESWRURE2qdeNxGRiFMQiIhEnIJARCTiFAQiIhGnIBARibiEDShLFDOrANYc4tOLgK3dWJzeIorXHcVrhmhedxSvGQ7+uke5e3F7B3pdEBwOM1vQ0ci6viyK1x3Fa4ZoXncUrxm697rVNCQiEnEKAhGRiItaENyf7AIkSRSvO4rXDNG87iheM3TjdUeqj0BERPYXtRqBiIi0oSAQEYm4yASBmZ1tZl+Y2XIzuzXZ5UkEMxthZq+Y2RIzW2RmN8f3F5jZn8xsWfxnfrLLmghmlmpmH5rZ7+OPS81sfvy6/yu+LkafYWYDzexpM/s8/pmfHIXP2sz+V/zf92dmNtfMMvviZ21mD5vZFjP7rNW+dj9fC+6Jf799YmbHH8x7RSIIzCwV+AVwDjAJuMzMJiW3VAnRBPytu08ETgL+Jn6dtwIvu/tY4OX4477oZsLaFy1+Cvxr/LqrgOuSUqrEuRt40d0nAGWEa+/Tn7WZDQNuAqa5+7FAKmHRq774Wc8Bzm6zr6PP9xxgbHy7Hrj3YN4oEkEATAeWu/tKd28AngAuTHKZup27b3T3hfHfdxK+GIYRrvWR+GmPAH+RnBImjpkNB74KPBh/bMAZwNPxU/rUdZvZAODLwEMA7t7g7tuJwGdNWEelv5mlAVnARvrgZ+3urxOW722to8/3QuBRD94FBprZkK6+V1SCYBiwrtXj8vi+PsvMSoCpwHzgKHffCCEsgEHJK1nC/Bz430As/rgQ2B5fKQ/63mc+GqgAfhlvDnvQzLLp45+1u68H7gLWEgKgGviAvv1Zt9bR53tY33FRCQJrZ1+fvW/WzHKA3wDfcfcdyS5PopnZecAWd/+g9e52Tu1Ln3kacDxwr7tPBXbRx5qB2hNvE78QKAWGAtmEZpG2+tJn3RWH9e89KkFQDoxo9Xg4sCFJZUkoM0snhMDj7v7b+O7NLdXE+M8tySpfgpwCXGBmqwnNfmcQaggD480H0Pc+83Kg3N3nxx8/TQiGvv5ZfwVY5e4V7t4I/BaYSd/+rFvr6PM9rO+4qATB+8DY+J0FGYTOpeeSXKZuF28XfwhY4u7/t9Wh54Cr479fDTzb02VLJHf/nrsPd/cSwmf7Z3e/AngF+Fr8tD513e6+CVhnZuPju2YDi+njnzWhSegkM8uK/3tvue4++1m30dHn+xxwVfzuoZOA6pYmpC5x90hswLnAUmAF8P1klydB1ziLUB38BPgovp1LaC9/GVgW/1mQ7LIm8L/BacDv47+PBt4DlgNPAf2SXb5uvtYpwIL45z0PyI/CZw38CPgc+Ax4DOjXFz9rYC6hH6SR8Bf/dR19voSmoV/Ev98+JdxV1eX30hQTIiIRF5WmIRER6YCCQEQk4hQEIiIRpyAQEYk4BYGISMQpCEQSzMxOa5kRVeRIpCAQEYk4BYFInJn9pZm9Z2Yfmdl/xtc3qDGzn5nZQjN72cyK4+dOMbN343O/P9NqXvijzey/zezj+HPGxF8+p9XaAY/HR8ViZj8xs8Xx17krSZcuEacgEAHMbCJwKXCKu08BmoErCJOaLXT344HXgB/Gn/Io8PfuPpkwkrNl/+PAL9y9jDAHTssw/6nAdwjrYYwGTjGzAuAi4Jj46/xjYq9SpH0KApFgNnAC8L6ZfRR/PJowrfV/xc/5FTDLzPKAge7+Wnz/I8CXzSwXGObuzwC4e52718bPec/dy909Rpj6owTYAdQBD5rZxUDLuSI9SkEgEhjwiLtPiW/j3f0f2jmvszlZ2psKuEV9q9+bgTQP8+dPJ8wW+xfAiwdZZpFuoSAQCV4GvmZmg2DP2rCjCP+PtMxqeTnwprtXA1Vm9qX4/iuB1zys/VBuZn8Rf41+ZpbV0RvG143Ic/cXCM1GUxJxYSIHknbgU0T6PndfbGa3AX80sxTCjI9/Q1jw5Rgz+4CwGtal8adcDdwX/6JfCXwzvv9K4D/N7I74a/yPTt42F3jWzDIJtYn/1c2XJdIlmn1UpBNmVuPuOckuh0giqWlIRCTiVCMQEYk41QhERCJOQSAiEnEKAhGRiFMQiIhEnIJARCTi/n/qT7nSfyuWDwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial accuracy is:  0.3986637\n",
      "Final accuracy is:  0.55233854\n",
      "Initial loss is:  1.374165994021834\n",
      "Final loss is:  1.083096171540513\n"
     ]
    }
   ],
   "source": [
    "#Plotting model history\n",
    "plt.plot(mlp_history.history['acc'])\n",
    "plt.plot(mlp_history.history['loss'])\n",
    "plt.legend(['Accuracy', 'Loss'])\n",
    "plt.title('Model History')\n",
    "plt.ylabel('Value')\n",
    "plt.xlabel('epochs')\n",
    "plt.show()\n",
    "print(\"Initial accuracy is: \", mlp_history.history['acc'][0])\n",
    "print(\"Final accuracy is: \", mlp_history.history['acc'][-1])\n",
    "\n",
    "print(\"Initial loss is: \", mlp_history.history['loss'][0])\n",
    "print(\"Final loss is: \", mlp_history.history['loss'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cyclic_generator(features, labels, batch_size = 1):\n",
    "  while True:\n",
    "    for n in range(features.shape[0]//batch_size):\n",
    "      yield (features[n*batch_size: (n+1)*batch_size], labels[n*batch_size: (n+1)*batch_size])\n",
    "    permuted = np.random.permutation(len(features))\n",
    "    features = features[permuted]\n",
    "    labels = labels[permuted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 32\n",
    "train_cyclic_generator = get_cyclic_generator(xlstm, ylstm, batch_size = train_batch_size)\n",
    "# test_cyclic_generator = get_cyclic_generator(x_test, y_test, batch_size = train_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 351, 66)]         0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 351, 32)           12672     \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 11232)             0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 32)                359456    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 4)                 68        \n",
      "=================================================================\n",
      "Total params: 372,724\n",
      "Trainable params: 372,724\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Creating model architecture\n",
    "inp_shape = (dims_lstm_1, dims_lstm_2)\n",
    "ip = tf.keras.Input(shape = inp_shape)\n",
    "lstm = tf.keras.layers.LSTM(32, return_sequences=True)(ip)\n",
    "drop = tf.keras.layers.Dropout(.4)(lstm)\n",
    "# lstm = tf.keras.layers.LSTM(16, return_sequences=True)(ip)\n",
    "# drop = tf.keras.layers.Dropout(.4)(lstm)\n",
    "flatten = tf.keras.layers.Flatten()(lstm)\n",
    "dense1 = tf.keras.layers.Dense(units = 32, activation = 'relu', kernel_initializer = 'random_normal')(flatten)\n",
    "dense2 = tf.keras.layers.Dense(units = 16, activation = 'relu', kernel_initializer = 'random_normal')(dense1)\n",
    "out = tf.keras.layers.Dense(num_classes, activation = 'softmax')(dense2)\n",
    "\n",
    "lstm = tf.keras.Model(inputs = ip, outputs = out)\n",
    "lstm.summary()\n",
    "# inp_shape = (None, )\n",
    "# review_sequence = tf.keras.Input(shape = inp_shape)\n",
    "# embedding_sequence = tf.keras.layers.Embedding(input_dim=100+1, output_dim=32, input_shape=(review_sequence.shape), mask_zero=False)(review_sequence)\n",
    "# average_embedding = tf.keras.layers.GlobalAveragePooling1D()(embedding_sequence)\n",
    "# positive_probability = tf.keras.layers.Dense(units=1, activation='sigmoid')(average_embedding)\n",
    "\n",
    "# model = tf.keras.Model(inputs = review_sequence, outputs = positive_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "lstm_earlystop = EarlyStopping(patience = 5, min_delta = 0.0001, monitor = 'acc')\n",
    "\n",
    "\n",
    "\n",
    "path = 'lstm_checkpoint/checkpoint_{epoch:02d}';\n",
    "lstm_checkpoint = ModelCheckpoint(filepath = path,\n",
    "                            verbose = 1,\n",
    "                            monitor = 'acc',\n",
    "                            save_freq = 'epoch',\n",
    "                            save_best_only = True,\n",
    "                            save_weights_only = True)\n",
    "\n",
    "lstm.compile(loss = 'categorical_crossentropy', metrics = ['acc'], optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 449 steps\n",
      "Epoch 1/20\n",
      "448/449 [============================>.] - ETA: 0s - loss: 1.2637 - acc: 0.4004\n",
      "Epoch 00001: acc improved from -inf to 0.40019, saving model to lstm_checkpoint/checkpoint_01\n",
      "449/449 [==============================] - 23s 52ms/step - loss: 1.2637 - acc: 0.4002\n",
      "Epoch 2/20\n",
      "447/449 [============================>.] - ETA: 0s - loss: 1.2558 - acc: 0.3996\n",
      "Epoch 00002: acc did not improve from 0.40019\n",
      "449/449 [==============================] - 18s 41ms/step - loss: 1.2561 - acc: 0.3995\n",
      "Epoch 3/20\n",
      "448/449 [============================>.] - ETA: 0s - loss: 1.2531 - acc: 0.4007\n",
      "Epoch 00003: acc improved from 0.40019 to 0.40089, saving model to lstm_checkpoint/checkpoint_03\n",
      "449/449 [==============================] - 19s 42ms/step - loss: 1.2531 - acc: 0.4009\n",
      "Epoch 4/20\n",
      "447/449 [============================>.] - ETA: 0s - loss: 1.2544 - acc: 0.4002\n",
      "Epoch 00004: acc did not improve from 0.40089\n",
      "449/449 [==============================] - 18s 40ms/step - loss: 1.2546 - acc: 0.3998\n",
      "Epoch 5/20\n",
      "447/449 [============================>.] - ETA: 0s - loss: 1.2540 - acc: 0.4011\n",
      "Epoch 00005: acc improved from 0.40089 to 0.40103, saving model to lstm_checkpoint/checkpoint_05\n",
      "449/449 [==============================] - 19s 43ms/step - loss: 1.2539 - acc: 0.4010\n",
      "Epoch 6/20\n",
      "447/449 [============================>.] - ETA: 0s - loss: 1.2527 - acc: 0.4017- ETA:\n",
      "Epoch 00006: acc improved from 0.40103 to 0.40214, saving model to lstm_checkpoint/checkpoint_06\n",
      "449/449 [==============================] - 19s 43ms/step - loss: 1.2526 - acc: 0.4021\n",
      "Epoch 7/20\n",
      "448/449 [============================>.] - ETA: 0s - loss: 1.2534 - acc: 0.4004\n",
      "Epoch 00007: acc did not improve from 0.40214\n",
      "449/449 [==============================] - 18s 41ms/step - loss: 1.2534 - acc: 0.4005\n",
      "Epoch 8/20\n",
      "448/449 [============================>.] - ETA: 0s - loss: 1.2535 - acc: 0.4006\n",
      "Epoch 00008: acc did not improve from 0.40214\n",
      "449/449 [==============================] - 18s 41ms/step - loss: 1.2533 - acc: 0.4010\n",
      "Epoch 9/20\n",
      "448/449 [============================>.] - ETA: 0s - loss: 1.2529 - acc: 0.4003- ETA:\n",
      "Epoch 00009: acc did not improve from 0.40214\n",
      "449/449 [==============================] - 18s 40ms/step - loss: 1.2531 - acc: 0.4002\n",
      "Epoch 10/20\n",
      "447/449 [============================>.] - ETA: 0s - loss: 1.2499 - acc: 0.4007\n",
      "Epoch 00010: acc did not improve from 0.40214\n",
      "449/449 [==============================] - 18s 41ms/step - loss: 1.2498 - acc: 0.4007\n",
      "Epoch 11/20\n",
      "448/449 [============================>.] - ETA: 0s - loss: 1.2376 - acc: 0.4025- ET\n",
      "Epoch 00011: acc improved from 0.40214 to 0.40256, saving model to lstm_checkpoint/checkpoint_11\n",
      "449/449 [==============================] - 19s 43ms/step - loss: 1.2376 - acc: 0.4026\n",
      "Epoch 12/20\n",
      "447/449 [============================>.] - ETA: 0s - loss: 1.1618 - acc: 0.4662\n",
      "Epoch 00012: acc improved from 0.40256 to 0.46631, saving model to lstm_checkpoint/checkpoint_12\n",
      "449/449 [==============================] - 19s 43ms/step - loss: 1.1616 - acc: 0.4663\n",
      "Epoch 13/20\n",
      "448/449 [============================>.] - ETA: 0s - loss: 1.0846 - acc: 0.5174\n",
      "Epoch 00013: acc improved from 0.46631 to 0.51782, saving model to lstm_checkpoint/checkpoint_13\n",
      "449/449 [==============================] - 19s 42ms/step - loss: 1.0843 - acc: 0.5178\n",
      "Epoch 14/20\n",
      "447/449 [============================>.] - ETA: 0s - loss: 1.0921 - acc: 0.5011\n",
      "Epoch 00014: acc did not improve from 0.51782\n",
      "449/449 [==============================] - 18s 41ms/step - loss: 1.0920 - acc: 0.5011\n",
      "Epoch 15/20\n",
      "448/449 [============================>.] - ETA: 0s - loss: 1.0423 - acc: 0.5375\n",
      "Epoch 00015: acc improved from 0.51782 to 0.53758, saving model to lstm_checkpoint/checkpoint_15\n",
      "449/449 [==============================] - 19s 42ms/step - loss: 1.0422 - acc: 0.5376\n",
      "Epoch 16/20\n",
      "448/449 [============================>.] - ETA: 0s - loss: 1.0001 - acc: 0.5712- ETA: 0s - loss: 1.0003 - acc\n",
      "Epoch 00016: acc improved from 0.53758 to 0.57127, saving model to lstm_checkpoint/checkpoint_16\n",
      "449/449 [==============================] - 19s 42ms/step - loss: 1.0001 - acc: 0.5713\n",
      "Epoch 17/20\n",
      "447/449 [============================>.] - ETA: 0s - loss: 0.9584 - acc: 0.5955\n",
      "Epoch 00017: acc improved from 0.57127 to 0.59507, saving model to lstm_checkpoint/checkpoint_17\n",
      "449/449 [==============================] - 19s 42ms/step - loss: 0.9587 - acc: 0.5951\n",
      "Epoch 18/20\n",
      "448/449 [============================>.] - ETA: 0s - loss: 0.9209 - acc: 0.6180\n",
      "Epoch 00018: acc improved from 0.59507 to 0.61783, saving model to lstm_checkpoint/checkpoint_18\n",
      "449/449 [==============================] - 19s 43ms/step - loss: 0.9208 - acc: 0.6178\n",
      "Epoch 19/20\n",
      "447/449 [============================>.] - ETA: 0s - loss: 0.8824 - acc: 0.6408- ETA: 3s  - ETA: 0s - loss: 0.8841 - ac\n",
      "Epoch 00019: acc improved from 0.61783 to 0.64066, saving model to lstm_checkpoint/checkpoint_19\n",
      "449/449 [==============================] - 20s 44ms/step - loss: 0.8825 - acc: 0.6407\n",
      "Epoch 20/20\n",
      "447/449 [============================>.] - ETA: 0s - loss: 0.8567 - acc: 0.6507\n",
      "Epoch 00020: acc improved from 0.64066 to 0.65096, saving model to lstm_checkpoint/checkpoint_20\n",
      "449/449 [==============================] - 19s 41ms/step - loss: 0.8564 - acc: 0.6510\n"
     ]
    }
   ],
   "source": [
    "lstm_history = lstm.fit(train_cyclic_generator,\n",
    "                        steps_per_epoch= 449,\n",
    "                        epochs = 20,\n",
    "#                         batch_size = 64,\n",
    "                        callbacks = [lstm_earlystop, lstm_checkpoint]) #Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial accuracy is:  0.40019488\n",
      "Final accuracy is:  0.65096045\n",
      "Initial loss is:  1.2637264489596565\n",
      "Final loss is:  0.8564158318302945\n"
     ]
    }
   ],
   "source": [
    "#Plotting model history\n",
    "plt.plot(lstm_history.history['acc'])\n",
    "plt.plot(lstm_history.history['loss'])\n",
    "plt.legend(['Accuracy', 'Loss'])\n",
    "plt.title('Model History')\n",
    "plt.ylabel('Value')\n",
    "plt.xlabel('epochs')\n",
    "plt.show()\n",
    "print(\"Initial accuracy is: \", lstm_history.history['acc'][0])\n",
    "print(\"Final accuracy is: \", lstm_history.history['acc'][-1])\n",
    "\n",
    "print(\"Initial loss is: \", lstm_history.history['loss'][0])\n",
    "print(\"Final loss is: \", lstm_history.history['loss'][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training on CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, 351, 66)]         0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 349, 32)           6368      \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 347, 16)           1552      \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 5552)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 32)                177696    \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 4)                 68        \n",
      "=================================================================\n",
      "Total params: 186,212\n",
      "Trainable params: 186,212\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inp_shape = (dims_lstm_1, dims_lstm_2)\n",
    "ip = tf.keras.Input(shape = inp_shape)\n",
    "conv1 = tf.keras.layers.Conv1D(32, 3, activation = 'relu')(ip)\n",
    "conv2 = tf.keras.layers.Conv1D(16, 3, activation = 'relu')(conv1)\n",
    "# lstm = tf.keras.layers.LSTM(16, return_sequences=True)(ip)\n",
    "flatten = tf.keras.layers.Flatten()(conv2)\n",
    "dense1 = tf.keras.layers.Dense(units = 32, activation = 'relu', kernel_initializer = 'random_normal')(flatten)\n",
    "dense2 = tf.keras.layers.Dense(units = 16, activation = 'relu', kernel_initializer = 'random_normal')(dense1)\n",
    "out = tf.keras.layers.Dense(num_classes, activation = 'softmax')(dense2)\n",
    "\n",
    "cnn = tf.keras.Model(inputs = ip, outputs = out)\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "cnn_earlystop = EarlyStopping(patience = 50, min_delta = 0.0001, monitor = 'acc')\n",
    "\n",
    "path = 'cnn_checkpoint/checkpoint_{epoch:02d}';\n",
    "cnn_checkpoint = ModelCheckpoint(filepath = path,\n",
    "                            verbose = 1,\n",
    "                            monitor = 'acc',\n",
    "                            save_freq = 'epoch',\n",
    "                            save_best_only = True,\n",
    "                            save_weights_only = True)\n",
    "\n",
    "cnn.compile(loss = 'categorical_crossentropy', metrics = ['acc'], optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1796 samples\n",
      "Epoch 1/500\n",
      "1728/1796 [===========================>..] - ETA: 0s - loss: 1.3136 - acc: 0.2824\n",
      "Epoch 00001: acc improved from -inf to 0.28619, saving model to cnn_checkpoint/checkpoint_01\n",
      "1796/1796 [==============================] - 2s 1ms/sample - loss: 1.3105 - acc: 0.2862\n",
      "Epoch 2/500\n",
      "1728/1796 [===========================>..] - ETA: 0s - loss: 1.2609 - acc: 0.3976- ETA: 0s - loss: 1.2685 - acc: 0.3\n",
      "Epoch 00002: acc improved from 0.28619 to 0.40089, saving model to cnn_checkpoint/checkpoint_02\n",
      "1796/1796 [==============================] - 1s 725us/sample - loss: 1.2571 - acc: 0.4009\n",
      "Epoch 3/500\n",
      "1728/1796 [===========================>..] - ETA: 0s - loss: 1.2540 - acc: 0.3999\n",
      "Epoch 00003: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 517us/sample - loss: 1.2553 - acc: 0.4009\n",
      "Epoch 4/500\n",
      "1728/1796 [===========================>..] - ETA: 0s - loss: 1.2556 - acc: 0.4016\n",
      "Epoch 00004: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 504us/sample - loss: 1.2561 - acc: 0.4009\n",
      "Epoch 5/500\n",
      "1728/1796 [===========================>..] - ETA: 0s - loss: 1.2602 - acc: 0.4039\n",
      "Epoch 00005: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 508us/sample - loss: 1.2619 - acc: 0.4009\n",
      "Epoch 6/500\n",
      "1728/1796 [===========================>..] - ETA: 0s - loss: 1.2602 - acc: 0.3987\n",
      "Epoch 00006: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 507us/sample - loss: 1.2564 - acc: 0.4009\n",
      "Epoch 7/500\n",
      "1728/1796 [===========================>..] - ETA: 0s - loss: 1.2582 - acc: 0.3976\n",
      "Epoch 00007: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 507us/sample - loss: 1.2562 - acc: 0.4009\n",
      "Epoch 8/500\n",
      "1728/1796 [===========================>..] - ETA: 0s - loss: 1.2548 - acc: 0.4010\n",
      "Epoch 00008: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 507us/sample - loss: 1.2537 - acc: 0.4009\n",
      "Epoch 9/500\n",
      "1728/1796 [===========================>..] - ETA: 0s - loss: 1.2559 - acc: 0.4022\n",
      "Epoch 00009: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 507us/sample - loss: 1.2553 - acc: 0.4009\n",
      "Epoch 10/500\n",
      "1728/1796 [===========================>..] - ETA: 0s - loss: 1.2538 - acc: 0.3999\n",
      "Epoch 00010: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 513us/sample - loss: 1.2546 - acc: 0.4009\n",
      "Epoch 11/500\n",
      "1728/1796 [===========================>..] - ETA: 0s - loss: 1.2545 - acc: 0.4016\n",
      "Epoch 00011: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 528us/sample - loss: 1.2557 - acc: 0.4009\n",
      "Epoch 12/500\n",
      "1728/1796 [===========================>..] - ETA: 0s - loss: 1.2557 - acc: 0.3999\n",
      "Epoch 00012: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 509us/sample - loss: 1.2542 - acc: 0.4009\n",
      "Epoch 13/500\n",
      "1728/1796 [===========================>..] - ETA: 0s - loss: 1.2544 - acc: 0.3999\n",
      "Epoch 00013: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 507us/sample - loss: 1.2528 - acc: 0.4009\n",
      "Epoch 14/500\n",
      "1728/1796 [===========================>..] - ETA: 0s - loss: 1.2513 - acc: 0.3999\n",
      "Epoch 00014: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 520us/sample - loss: 1.2532 - acc: 0.4009\n",
      "Epoch 15/500\n",
      "1728/1796 [===========================>..] - ETA: 0s - loss: 1.2538 - acc: 0.3987\n",
      "Epoch 00015: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 513us/sample - loss: 1.2539 - acc: 0.4009\n",
      "Epoch 16/500\n",
      "1728/1796 [===========================>..] - ETA: 0s - loss: 1.2524 - acc: 0.4016\n",
      "Epoch 00016: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 505us/sample - loss: 1.2545 - acc: 0.4009\n",
      "Epoch 17/500\n",
      "1728/1796 [===========================>..] - ETA: 0s - loss: 1.2534 - acc: 0.4028\n",
      "Epoch 00017: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 505us/sample - loss: 1.2543 - acc: 0.4009\n",
      "Epoch 18/500\n",
      "1728/1796 [===========================>..] - ETA: 0s - loss: 1.2518 - acc: 0.4022\n",
      "Epoch 00018: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 505us/sample - loss: 1.2531 - acc: 0.4009\n",
      "Epoch 19/500\n",
      "1728/1796 [===========================>..] - ETA: 0s - loss: 1.2527 - acc: 0.4016\n",
      "Epoch 00019: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 509us/sample - loss: 1.2579 - acc: 0.4009\n",
      "Epoch 20/500\n",
      "1728/1796 [===========================>..] - ETA: 0s - loss: 1.2540 - acc: 0.3981\n",
      "Epoch 00020: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 504us/sample - loss: 1.2532 - acc: 0.4009\n",
      "Epoch 21/500\n",
      "1728/1796 [===========================>..] - ETA: 0s - loss: 1.2544 - acc: 0.3999\n",
      "Epoch 00021: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 503us/sample - loss: 1.2544 - acc: 0.4009\n",
      "Epoch 22/500\n",
      "1728/1796 [===========================>..] - ETA: 0s - loss: 1.2536 - acc: 0.4010\n",
      "Epoch 00022: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 505us/sample - loss: 1.2555 - acc: 0.4009\n",
      "Epoch 23/500\n",
      "1728/1796 [===========================>..] - ETA: 0s - loss: 1.2584 - acc: 0.3964\n",
      "Epoch 00023: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 503us/sample - loss: 1.2570 - acc: 0.4009\n",
      "Epoch 24/500\n",
      "1728/1796 [===========================>..] - ETA: 0s - loss: 1.2561 - acc: 0.4005\n",
      "Epoch 00024: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 508us/sample - loss: 1.2554 - acc: 0.4009\n",
      "Epoch 25/500\n",
      "1728/1796 [===========================>..] - ETA: 0s - loss: 1.2518 - acc: 0.4022\n",
      "Epoch 00025: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 509us/sample - loss: 1.2536 - acc: 0.4009\n",
      "Epoch 26/500\n",
      "1728/1796 [===========================>..] - ETA: 0s - loss: 1.2521 - acc: 0.4022\n",
      "Epoch 00026: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 502us/sample - loss: 1.2537 - acc: 0.4009\n",
      "Epoch 27/500\n",
      "1728/1796 [===========================>..] - ETA: 0s - loss: 1.2563 - acc: 0.3987\n",
      "Epoch 00027: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 516us/sample - loss: 1.2541 - acc: 0.4009\n",
      "Epoch 28/500\n",
      "1728/1796 [===========================>..] - ETA: 0s - loss: 1.2547 - acc: 0.4022\n",
      "Epoch 00028: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 518us/sample - loss: 1.2547 - acc: 0.4009\n",
      "Epoch 29/500\n",
      "1728/1796 [===========================>..] - ETA: 0s - loss: 1.2507 - acc: 0.4039\n",
      "Epoch 00029: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 515us/sample - loss: 1.2524 - acc: 0.4009\n",
      "Epoch 30/500\n",
      "1728/1796 [===========================>..] - ETA: 0s - loss: 1.2533 - acc: 0.4016\n",
      "Epoch 00030: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 502us/sample - loss: 1.2532 - acc: 0.4009\n",
      "Epoch 31/500\n",
      "1728/1796 [===========================>..] - ETA: 0s - loss: 1.2507 - acc: 0.4010\n",
      "Epoch 00031: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 505us/sample - loss: 1.2546 - acc: 0.4009\n",
      "Epoch 32/500\n",
      "1728/1796 [===========================>..] - ETA: 0s - loss: 1.2580 - acc: 0.3964- ETA: 0s - loss: 1.2656 - a\n",
      "Epoch 00032: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 505us/sample - loss: 1.2569 - acc: 0.4009\n",
      "Epoch 33/500\n",
      "1728/1796 [===========================>..] - ETA: 0s - loss: 1.2550 - acc: 0.3970\n",
      "Epoch 00033: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 507us/sample - loss: 1.2535 - acc: 0.4009\n",
      "Epoch 34/500\n",
      "1728/1796 [===========================>..] - ETA: 0s - loss: 1.2519 - acc: 0.4034\n",
      "Epoch 00034: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 504us/sample - loss: 1.2534 - acc: 0.4009\n",
      "Epoch 35/500\n",
      "1728/1796 [===========================>..] - ETA: 0s - loss: 1.2546 - acc: 0.3999\n",
      "Epoch 00035: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 508us/sample - loss: 1.2538 - acc: 0.4009\n",
      "Epoch 36/500\n",
      "1728/1796 [===========================>..] - ETA: 0s - loss: 1.2533 - acc: 0.3987\n",
      "Epoch 00036: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 505us/sample - loss: 1.2527 - acc: 0.4009\n",
      "Epoch 37/500\n",
      "1728/1796 [===========================>..] - ETA: 0s - loss: 1.2546 - acc: 0.3993\n",
      "Epoch 00037: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 504us/sample - loss: 1.2544 - acc: 0.4009\n",
      "Epoch 38/500\n",
      "1728/1796 [===========================>..] - ETA: 0s - loss: 1.2549 - acc: 0.3981\n",
      "Epoch 00038: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 505us/sample - loss: 1.2534 - acc: 0.4009\n",
      "Epoch 39/500\n",
      "1728/1796 [===========================>..] - ETA: 0s - loss: 1.2537 - acc: 0.4016\n",
      "Epoch 00039: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 503us/sample - loss: 1.2535 - acc: 0.4009\n",
      "Epoch 40/500\n",
      "1728/1796 [===========================>..] - ETA: 0s - loss: 1.2523 - acc: 0.3981\n",
      "Epoch 00040: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 505us/sample - loss: 1.2529 - acc: 0.4009\n",
      "Epoch 41/500\n",
      "1728/1796 [===========================>..] - ETA: 0s - loss: 1.2539 - acc: 0.3999\n",
      "Epoch 00041: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 567us/sample - loss: 1.2533 - acc: 0.4009\n",
      "Epoch 42/500\n",
      "1728/1796 [===========================>..] - ETA: 0s - loss: 1.2540 - acc: 0.4039\n",
      "Epoch 00042: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 506us/sample - loss: 1.2543 - acc: 0.4009\n",
      "Epoch 43/500\n",
      "1728/1796 [===========================>..] - ETA: 0s - loss: 1.2567 - acc: 0.4005\n",
      "Epoch 00043: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 560us/sample - loss: 1.2538 - acc: 0.4009\n",
      "Epoch 44/500\n",
      "1728/1796 [===========================>..] - ETA: 0s - loss: 1.2520 - acc: 0.4016\n",
      "Epoch 00044: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 507us/sample - loss: 1.2541 - acc: 0.4009\n",
      "Epoch 45/500\n",
      "1728/1796 [===========================>..] - ETA: 0s - loss: 1.2514 - acc: 0.4028\n",
      "Epoch 00045: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 512us/sample - loss: 1.2519 - acc: 0.4009\n",
      "Epoch 46/500\n",
      "1728/1796 [===========================>..] - ETA: 0s - loss: 1.2551 - acc: 0.3958\n",
      "Epoch 00046: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 517us/sample - loss: 1.2546 - acc: 0.4009\n",
      "Epoch 47/500\n",
      "1728/1796 [===========================>..] - ETA: 0s - loss: 1.2527 - acc: 0.4016\n",
      "Epoch 00047: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 513us/sample - loss: 1.2525 - acc: 0.4009\n",
      "Epoch 48/500\n",
      "1728/1796 [===========================>..] - ETA: 0s - loss: 1.2557 - acc: 0.3993\n",
      "Epoch 00048: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 514us/sample - loss: 1.2546 - acc: 0.4009\n",
      "Epoch 49/500\n",
      "1728/1796 [===========================>..] - ETA: 0s - loss: 1.2535 - acc: 0.4057\n",
      "Epoch 00049: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 507us/sample - loss: 1.2528 - acc: 0.4009\n",
      "Epoch 50/500\n",
      "1728/1796 [===========================>..] - ETA: 0s - loss: 1.2551 - acc: 0.3981\n",
      "Epoch 00050: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 504us/sample - loss: 1.2528 - acc: 0.4009\n",
      "Epoch 51/500\n",
      "1728/1796 [===========================>..] - ETA: 0s - loss: 1.2547 - acc: 0.4022\n",
      "Epoch 00051: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 510us/sample - loss: 1.2529 - acc: 0.4009\n",
      "Epoch 52/500\n",
      "1728/1796 [===========================>..] - ETA: 0s - loss: 1.2544 - acc: 0.4005\n",
      "Epoch 00052: acc did not improve from 0.40089\n",
      "1796/1796 [==============================] - 1s 508us/sample - loss: 1.2545 - acc: 0.4009\n"
     ]
    }
   ],
   "source": [
    "cnn_history = cnn.fit(xlstm, ylstm, epochs=500, batch_size = 64, callbacks = [cnn_earlystop, cnn_checkpoint]) #Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial accuracy is:  0.28619152\n",
      "Final accuracy is:  0.40089086\n",
      "Initial loss is:  1.3104653618649014\n",
      "Final loss is:  1.2544584831841008\n"
     ]
    }
   ],
   "source": [
    "#Plotting model history\n",
    "plt.plot(cnn_history.history['acc'])\n",
    "plt.plot(cnn_history.history['loss'])\n",
    "plt.legend(['Accuracy', 'Loss'])\n",
    "plt.title('Model History')\n",
    "plt.ylabel('Value')\n",
    "plt.xlabel('epochs')\n",
    "plt.show()\n",
    "print(\"Initial accuracy is: \", cnn_history.history['acc'][0])\n",
    "print(\"Final accuracy is: \", cnn_history.history['acc'][-1])\n",
    "\n",
    "print(\"Initial loss is: \", cnn_history.history['loss'][0])\n",
    "print(\"Final loss is: \", cnn_history.history['loss'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training for go/no-go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1872, 23167)\n",
      "(600, 23167)\n",
      "(600, 23166)\n",
      "(600,)\n",
      "[2.0, 4.0]\n"
     ]
    }
   ],
   "source": [
    "#Creating dataset\n",
    "datasetgonogo = main_dataset.copy()\n",
    "print(datasetgonogo.shape)\n",
    "\n",
    "unwanted_events_gonogo = [9, 10, 3, 6, 7, 8, 11, 1, 5]\n",
    "\n",
    "for e in unwanted_events_gonogo:\n",
    "    datasetgonogo = datasetgonogo[datasetgonogo[:, -1]!=e]\n",
    "\n",
    "print(datasetgonogo.shape)\n",
    "\n",
    "xgonogo = datasetgonogo[:, :-1]\n",
    "ygonogo = datasetgonogo[:, -1]\n",
    "print(xgonogo.shape)\n",
    "print(ygonogo.shape)\n",
    "print(list(set(ygonogo)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "#Encoding y\n",
    "dict = {2.0: 0, 4.0: 1}\n",
    "\n",
    "for i in range(len(ygonogo)):\n",
    "    ygonogo[i] = dict[ygonogo[i]]\n",
    "\n",
    "print(list(set(ygonogo)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = 2\n",
    "ygonogo = tf.keras.utils.to_categorical(ygonogo, num_classes)\n",
    "ygonogo[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, 23166)]           0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 32)                741344    \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 2)                 34        \n",
      "=================================================================\n",
      "Total params: 741,906\n",
      "Trainable params: 741,906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Creating model archtecture\n",
    "inp_shape = (dims_ip, )\n",
    "ip = tf.keras.Input(shape = inp_shape)\n",
    "dense1 = tf.keras.layers.Dense(units = 32, activation = 'relu', kernel_initializer = 'random_normal')(ip)\n",
    "dense2 = tf.keras.layers.Dense(units = 16, activation = 'relu', kernel_initializer = 'random_normal')(dense1)\n",
    "out = tf.keras.layers.Dense(num_classes, activation = 'softmax')(dense2)\n",
    "\n",
    "modelgonogo = tf.keras.Model(inputs = ip, outputs = out)\n",
    "modelgonogo.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compiling the model\n",
    "earlystop = EarlyStopping(patience = 50, min_delta = 0.0001, monitor = 'acc')\n",
    "\n",
    "path = 'new_model_checkpoint/checkpoint_{epoch:02d}';\n",
    "model_checkpoint = ModelCheckpoint(filepath = path,\n",
    "                            verbose = 0,\n",
    "                            monitor = 'accuracy',\n",
    "                            save_freq = 'epoch',\n",
    "                            save_best_only = True,\n",
    "                            save_weights_only = True)\n",
    "\n",
    "modelgonogo.compile(loss = 'categorical_crossentropy', metrics = ['acc'], optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "576/600 [===========================>..] - ETA: 0s - loss: 0.6787 - acc: 0.7917WARNING:tensorflow:Can save best model only with accuracy available, skipping.\n",
      "600/600 [==============================] - 0s 665us/sample - loss: 0.6780 - acc: 0.7917\n",
      "Epoch 2/300\n",
      "480/600 [=======================>......] - ETA: 0s - loss: 0.6417 - acc: 0.8021WARNING:tensorflow:Can save best model only with accuracy available, skipping.\n",
      "600/600 [==============================] - 0s 394us/sample - loss: 0.6380 - acc: 0.8000\n",
      "Epoch 3/300\n",
      "448/600 [=====================>........] - ETA: 0s - loss: 0.5975 - acc: 0.8013WARNING:tensorflow:Can save best model only with accuracy available, skipping.\n",
      "600/600 [==============================] - 0s 391us/sample - loss: 0.5920 - acc: 0.8000\n",
      "Epoch 4/300\n",
      "480/600 [=======================>......] - ETA: 0s - loss: 0.5476 - acc: 0.8021WARNING:tensorflow:Can save best model only with accuracy available, skipping.\n",
      "600/600 [==============================] - 0s 389us/sample - loss: 0.5453 - acc: 0.8000\n",
      "Epoch 5/300\n",
      "576/600 [===========================>..] - ETA: 0s - loss: 0.5155 - acc: 0.7986WARNING:tensorflow:Can save best model only with accuracy available, skipping.\n",
      "600/600 [==============================] - 0s 420us/sample - loss: 0.5136 - acc: 0.8000\n",
      "Epoch 6/300\n",
      "512/600 [========================>.....] - ETA: 0s - loss: 0.4969 - acc: 0.8047WARNING:tensorflow:Can save best model only with accuracy available, skipping.\n",
      "600/600 [==============================] - 0s 380us/sample - loss: 0.5028 - acc: 0.8000\n",
      "Epoch 7/300\n",
      "512/600 [========================>.....] - ETA: 0s - loss: 0.5099 - acc: 0.7930WARNING:tensorflow:Can save best model only with accuracy available, skipping.\n",
      "600/600 [==============================] - 0s 383us/sample - loss: 0.5003 - acc: 0.8000\n",
      "Epoch 8/300\n",
      "544/600 [==========================>...] - ETA: 0s - loss: 0.4902 - acc: 0.8070WARNING:tensorflow:Can save best model only with accuracy available, skipping.\n",
      "600/600 [==============================] - 0s 449us/sample - loss: 0.5001 - acc: 0.8000\n",
      "Epoch 9/300\n",
      "576/600 [===========================>..] - ETA: 0s - loss: 0.4923 - acc: 0.8056WARNING:tensorflow:Can save best model only with accuracy available, skipping.\n",
      "600/600 [==============================] - 0s 535us/sample - loss: 0.5003 - acc: 0.8000\n",
      "Epoch 10/300\n",
      "576/600 [===========================>..] - ETA: 0s - loss: 0.4996 - acc: 0.8003WARNING:tensorflow:Can save best model only with accuracy available, skipping.\n",
      "600/600 [==============================] - 0s 420us/sample - loss: 0.5000 - acc: 0.8000\n",
      "Epoch 11/300\n",
      "512/600 [========================>.....] - ETA: 0s - loss: 0.5042 - acc: 0.7969WARNING:tensorflow:Can save best model only with accuracy available, skipping.\n",
      "600/600 [==============================] - 0s 594us/sample - loss: 0.5000 - acc: 0.8000\n",
      "Epoch 12/300\n",
      "544/600 [==========================>...] - ETA: 0s - loss: 0.5129 - acc: 0.7904WARNING:tensorflow:Can save best model only with accuracy available, skipping.\n",
      "600/600 [==============================] - 0s 484us/sample - loss: 0.5000 - acc: 0.8000\n",
      "Epoch 13/300\n",
      "544/600 [==========================>...] - ETA: 0s - loss: 0.4950 - acc: 0.8033WARNING:tensorflow:Can save best model only with accuracy available, skipping.\n",
      "600/600 [==============================] - 0s 572us/sample - loss: 0.4997 - acc: 0.8000\n",
      "Epoch 14/300\n",
      "576/600 [===========================>..] - ETA: 0s - loss: 0.5039 - acc: 0.7969WARNING:tensorflow:Can save best model only with accuracy available, skipping.\n",
      "600/600 [==============================] - 0s 570us/sample - loss: 0.4995 - acc: 0.8000\n",
      "Epoch 15/300\n",
      "576/600 [===========================>..] - ETA: 0s - loss: 0.5021 - acc: 0.7986WARNING:tensorflow:Can save best model only with accuracy available, skipping.\n",
      "600/600 [==============================] - 0s 579us/sample - loss: 0.5002 - acc: 0.8000\n",
      "Epoch 16/300\n",
      "544/600 [==========================>...] - ETA: 0s - loss: 0.4997 - acc: 0.7996WARNING:tensorflow:Can save best model only with accuracy available, skipping.\n",
      "600/600 [==============================] - 0s 621us/sample - loss: 0.4991 - acc: 0.8000\n",
      "Epoch 17/300\n",
      "576/600 [===========================>..] - ETA: 0s - loss: 0.5034 - acc: 0.7969WARNING:tensorflow:Can save best model only with accuracy available, skipping.\n",
      "600/600 [==============================] - 0s 549us/sample - loss: 0.4991 - acc: 0.8000\n",
      "Epoch 18/300\n",
      "512/600 [========================>.....] - ETA: 0s - loss: 0.4980 - acc: 0.8008WARNING:tensorflow:Can save best model only with accuracy available, skipping.\n",
      "600/600 [==============================] - 0s 593us/sample - loss: 0.4990 - acc: 0.8000\n",
      "Epoch 19/300\n",
      "544/600 [==========================>...] - ETA: 0s - loss: 0.4973 - acc: 0.8015WARNING:tensorflow:Can save best model only with accuracy available, skipping.\n",
      "600/600 [==============================] - 0s 618us/sample - loss: 0.4993 - acc: 0.8000\n",
      "Epoch 20/300\n",
      "576/600 [===========================>..] - ETA: 0s - loss: 0.4884 - acc: 0.8073WARNING:tensorflow:Can save best model only with accuracy available, skipping.\n",
      "600/600 [==============================] - 0s 666us/sample - loss: 0.4987 - acc: 0.8000\n",
      "Epoch 21/300\n",
      "512/600 [========================>.....] - ETA: 0s - loss: 0.5085 - acc: 0.7930WARNING:tensorflow:Can save best model only with accuracy available, skipping.\n",
      "600/600 [==============================] - 0s 646us/sample - loss: 0.4986 - acc: 0.8000\n",
      "Epoch 22/300\n",
      "512/600 [========================>.....] - ETA: 0s - loss: 0.5136 - acc: 0.7891WARNING:tensorflow:Can save best model only with accuracy available, skipping.\n",
      "600/600 [==============================] - 0s 629us/sample - loss: 0.4987 - acc: 0.8000\n",
      "Epoch 23/300\n",
      "512/600 [========================>.....] - ETA: 0s - loss: 0.4868 - acc: 0.8086WARNING:tensorflow:Can save best model only with accuracy available, skipping.\n",
      "600/600 [==============================] - 0s 410us/sample - loss: 0.4988 - acc: 0.8000\n",
      "Epoch 24/300\n",
      "576/600 [===========================>..] - ETA: 0s - loss: 0.4976 - acc: 0.8003WARNING:tensorflow:Can save best model only with accuracy available, skipping.\n",
      "600/600 [==============================] - 0s 404us/sample - loss: 0.4981 - acc: 0.8000\n",
      "Epoch 25/300\n",
      "448/600 [=====================>........] - ETA: 0s - loss: 0.4903 - acc: 0.8058WARNING:tensorflow:Can save best model only with accuracy available, skipping.\n",
      "600/600 [==============================] - 0s 403us/sample - loss: 0.4982 - acc: 0.8000\n",
      "Epoch 26/300\n",
      "544/600 [==========================>...] - ETA: 0s - loss: 0.5009 - acc: 0.7978WARNING:tensorflow:Can save best model only with accuracy available, skipping.\n",
      "600/600 [==============================] - 0s 462us/sample - loss: 0.4980 - acc: 0.8000\n",
      "Epoch 27/300\n",
      "544/600 [==========================>...] - ETA: 0s - loss: 0.4958 - acc: 0.8015WARNING:tensorflow:Can save best model only with accuracy available, skipping.\n",
      "600/600 [==============================] - 0s 456us/sample - loss: 0.4979 - acc: 0.8000\n",
      "Epoch 28/300\n",
      "576/600 [===========================>..] - ETA: 0s - loss: 0.5027 - acc: 0.7969WARNING:tensorflow:Can save best model only with accuracy available, skipping.\n",
      "600/600 [==============================] - 0s 416us/sample - loss: 0.4984 - acc: 0.8000\n",
      "Epoch 29/300\n",
      "448/600 [=====================>........] - ETA: 0s - loss: 0.5093 - acc: 0.7924WARNING:tensorflow:Can save best model only with accuracy available, skipping.\n",
      "600/600 [==============================] - 0s 400us/sample - loss: 0.4992 - acc: 0.8000\n",
      "Epoch 30/300\n",
      "576/600 [===========================>..] - ETA: 0s - loss: 0.4944 - acc: 0.8021WARNING:tensorflow:Can save best model only with accuracy available, skipping.\n",
      "600/600 [==============================] - 0s 415us/sample - loss: 0.4974 - acc: 0.8000\n",
      "Epoch 31/300\n",
      "576/600 [===========================>..] - ETA: 0s - loss: 0.5042 - acc: 0.7951WARNING:tensorflow:Can save best model only with accuracy available, skipping.\n",
      "600/600 [==============================] - 0s 414us/sample - loss: 0.4976 - acc: 0.8000\n",
      "Epoch 32/300\n",
      "512/600 [========================>.....] - ETA: 0s - loss: 0.4830 - acc: 0.8105WARNING:tensorflow:Can save best model only with accuracy available, skipping.\n",
      "600/600 [==============================] - 0s 614us/sample - loss: 0.4979 - acc: 0.8000\n",
      "Epoch 33/300\n",
      "512/600 [========================>.....] - ETA: 0s - loss: 0.5009 - acc: 0.7969WARNING:tensorflow:Can save best model only with accuracy available, skipping.\n",
      "600/600 [==============================] - 0s 625us/sample - loss: 0.4968 - acc: 0.8000\n",
      "Epoch 34/300\n",
      "512/600 [========================>.....] - ETA: 0s - loss: 0.4996 - acc: 0.7988WARNING:tensorflow:Can save best model only with accuracy available, skipping.\n",
      "600/600 [==============================] - 0s 614us/sample - loss: 0.4979 - acc: 0.8000\n",
      "Epoch 35/300\n",
      "544/600 [==========================>...] - ETA: 0s - loss: 0.4947 - acc: 0.8015WARNING:tensorflow:Can save best model only with accuracy available, skipping.\n",
      "600/600 [==============================] - 0s 593us/sample - loss: 0.4967 - acc: 0.8000\n",
      "Epoch 36/300\n",
      "512/600 [========================>.....] - ETA: 0s - loss: 0.4982 - acc: 0.7988WARNING:tensorflow:Can save best model only with accuracy available, skipping.\n",
      "600/600 [==============================] - 0s 619us/sample - loss: 0.4967 - acc: 0.8000\n",
      "Epoch 37/300\n",
      "512/600 [========================>.....] - ETA: 0s - loss: 0.5087 - acc: 0.7910WARNING:tensorflow:Can save best model only with accuracy available, skipping.\n",
      "600/600 [==============================] - 0s 644us/sample - loss: 0.4965 - acc: 0.8000\n",
      "Epoch 38/300\n",
      "512/600 [========================>.....] - ETA: 0s - loss: 0.4954 - acc: 0.8008WARNING:tensorflow:Can save best model only with accuracy available, skipping.\n",
      "600/600 [==============================] - 0s 665us/sample - loss: 0.4965 - acc: 0.8000\n",
      "Epoch 39/300\n",
      "544/600 [==========================>...] - ETA: 0s - loss: 0.4970 - acc: 0.7996WARNING:tensorflow:Can save best model only with accuracy available, skipping.\n",
      "600/600 [==============================] - 0s 595us/sample - loss: 0.4964 - acc: 0.8000\n",
      "Epoch 40/300\n",
      "480/600 [=======================>......] - ETA: 0s - loss: 0.4819 - acc: 0.8104WARNING:tensorflow:Can save best model only with accuracy available, skipping.\n",
      "600/600 [==============================] - 0s 547us/sample - loss: 0.4960 - acc: 0.8000\n",
      "Epoch 41/300\n",
      "576/600 [===========================>..] - ETA: 0s - loss: 0.5025 - acc: 0.7951WARNING:tensorflow:Can save best model only with accuracy available, skipping.\n",
      "600/600 [==============================] - 0s 422us/sample - loss: 0.4958 - acc: 0.8000\n",
      "Epoch 42/300\n",
      "448/600 [=====================>........] - ETA: 0s - loss: 0.4728 - acc: 0.8170WARNING:tensorflow:Can save best model only with accuracy available, skipping.\n",
      "600/600 [==============================] - 0s 395us/sample - loss: 0.4964 - acc: 0.8000\n",
      "Epoch 43/300\n",
      "576/600 [===========================>..] - ETA: 0s - loss: 0.4901 - acc: 0.8038WARNING:tensorflow:Can save best model only with accuracy available, skipping.\n",
      "600/600 [==============================] - 0s 412us/sample - loss: 0.4953 - acc: 0.8000\n",
      "Epoch 44/300\n",
      "448/600 [=====================>........] - ETA: 0s - loss: 0.4717 - acc: 0.8170WARNING:tensorflow:Can save best model only with accuracy available, skipping.\n",
      "600/600 [==============================] - 0s 403us/sample - loss: 0.4952 - acc: 0.8000\n",
      "Epoch 45/300\n",
      "576/600 [===========================>..] - ETA: 0s - loss: 0.4923 - acc: 0.8021WARNING:tensorflow:Can save best model only with accuracy available, skipping.\n",
      "600/600 [==============================] - 0s 413us/sample - loss: 0.4950 - acc: 0.8000\n",
      "Epoch 46/300\n",
      "544/600 [==========================>...] - ETA: 0s - loss: 0.4907 - acc: 0.8033WARNING:tensorflow:Can save best model only with accuracy available, skipping.\n",
      "600/600 [==============================] - 0s 448us/sample - loss: 0.4951 - acc: 0.8000\n",
      "Epoch 47/300\n",
      "576/600 [===========================>..] - ETA: 0s - loss: 0.4923 - acc: 0.8021WARNING:tensorflow:Can save best model only with accuracy available, skipping.\n",
      "600/600 [==============================] - 0s 651us/sample - loss: 0.4951 - acc: 0.8000\n",
      "Epoch 48/300\n",
      "512/600 [========================>.....] - ETA: 0s - loss: 0.4854 - acc: 0.8066WARNING:tensorflow:Can save best model only with accuracy available, skipping.\n",
      "600/600 [==============================] - 0s 606us/sample - loss: 0.4942 - acc: 0.8000\n",
      "Epoch 49/300\n",
      "512/600 [========================>.....] - ETA: 0s - loss: 0.5090 - acc: 0.7891WARNING:tensorflow:Can save best model only with accuracy available, skipping.\n",
      "600/600 [==============================] - 0s 512us/sample - loss: 0.4942 - acc: 0.8000\n",
      "Epoch 50/300\n",
      "512/600 [========================>.....] - ETA: 0s - loss: 0.5119 - acc: 0.7871WARNING:tensorflow:Can save best model only with accuracy available, skipping.\n",
      "600/600 [==============================] - 0s 632us/sample - loss: 0.4947 - acc: 0.8000\n",
      "Epoch 51/300\n",
      "576/600 [===========================>..] - ETA: 0s - loss: 0.4905 - acc: 0.8021WARNING:tensorflow:Can save best model only with accuracy available, skipping.\n",
      "600/600 [==============================] - 0s 557us/sample - loss: 0.4936 - acc: 0.8000\n",
      "Epoch 52/300\n",
      "512/600 [========================>.....] - ETA: 0s - loss: 0.4927 - acc: 0.8008WARNING:tensorflow:Can save best model only with accuracy available, skipping.\n",
      "600/600 [==============================] - 0s 591us/sample - loss: 0.4937 - acc: 0.8000\n"
     ]
    }
   ],
   "source": [
    "historygonogo = modelgonogo.fit(xgonogo, ygonogo, epochs=300, callbacks = [earlystop, model_checkpoint]) #plotting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deZgV9Z3v8fenF2gWAVmUpUFQMXGjG+2AUScuRCUzBqMmBjVRY6I398YlyUzuxRknmcFMxkySm+hcnxiNDMYoRL0jQ26cGOOSSdxCo8QILiCKtCAiyC5Ld3/vH1UNh6aApjmnT3P683qees6pOr+q862mqU9X/WpRRGBmZtZaWbELMDOzzskBYWZmmRwQZmaWyQFhZmaZHBBmZpbJAWFmZpkcEGa7IWmkpJBU0Ya2V0j6w3581whJGySVt3cZZvnmgLCSIOlNSVslDWw1fV66kR9ZnMp2HzSSpkv6NkBEvBURvSOiaS/L2q8gMtsXDggrJW8AF7eMSDoe6FG8cjqftuwNmbVwQFgpuQe4LGf8cuBnuQ0k9ZX0M0krJS2RdKOksvSzcknfl/SepMXAX2XMe5ek5ZLelvTtfB0Sar2Xke4pLJa0XtIbki6VdDRwO/DR9HDUmjas0xWSnpL0Q0mrgZskrU7Ds+W7D5H0gaRB+VgXKx0OCCslzwJ9JB2dbrg/C/y8VZt/BfoChwOnkQTKF9LPrgLOBcYCdcCnW817N9AIHJm2ORv4Ur5XQlIv4FbgExFxEHAyMC8iXga+DDyTHo7q14Z1AhgPLAYOAaYCM4HP5Xx+MfDbiFiZ73WxA5sDwkpNy17EWcArwNstH+SExg0RsT4i3gR+AHw+bXIR8KOIWBoRq4F/zpn3UOATwFcjYmNEvAv8EJi8D7W9J2lNywBcsoe2zcBxknpExPKImJ/VqA3rBLAsIv41Ihoj4gOSoLukZS8jbXvPPqyHdRE+Hmml5h7gv4BRtDq8BAwEugFLcqYtAYal74cCS1t91uIwoBJYLqllWlmr9nszMCIaW0YkTc9qFBEbJX0W+BvgLklPAX8dEa9kLZM9rxOta4yI5yRtBE6TtJxkj2j2PqyHdRHeg7CSEhFLSDqr/xL491YfvwdsI9nYtxjBjr2M5cDwVp+1WApsIdnI90uHPhFxbD7rbxERj0TEWcAQkj2hO1s+atV0b+uUNQ8kexGfI9l7eDAiNuejbistDggrRV8EzoyIjbkT01NI7wf+SdJBkg4Dvs6Ofor7geskVUs6GJiSM+9y4DfADyT1kVQm6QhJp+W7eEmHSpqU9kVsATYALae/rgCqJXVr4zrtzj3A+SQh0XpPywxwQFgJiojXI6J+Nx9fC2wk6bT9A3AfMC397E7gEeBPwPPsugdyGcnhnAXA+8CDJH/h51sZ8NfAMmA1Scfz/0g/exyYD7wj6b102p7WKVNENJCsYwC/z3P9ViLkBwaZdU2SppF0YN9Y7Fqsc3IntVkXlF5ZfgHJ6bpmmXyIyayLkXQT8BLwvYh4o9j1WOflQ0xmZpbJexBmZpapZPogBg4cGCNHjix2GWZmB5S5c+e+FxGZ9+EqmYAYOXIk9fW7O7PRzMyySFqyu898iMnMzDI5IMzMLJMDwszMMjkgzMwskwPCzMwyFTQgJE2U9KqkRZKmZHw+QtITkl6Q9KKkv8z57IZ0vlclnVPIOs3MbFcFO801fdLVbSRP9moA5kiaHRELcprdCNwfET+WdAzwMDAyfT8ZOJbkIS6/lXRUemtjMzPrAIW8DmIcsCgiFgNImgmcR3Kr5BYB9Enf9yW5vTFpu5kRsQV4Q9KidHnPFLDenWxtbOa+55aweuPWjvpKM7N2Gdy3B5eMH7H3hvuokAExjJ0fddhA8vD0XP8A/EbStUAv4OM58z7bat5htCLpauBqgBEj8vfD2bClkf/+87n8fuF77Hi6pJlZ51Q7vN8BFxBZm9bWdwa8GJgeET+Q9FHgHknHtXFeIuIO4A6Aurq6vNx1cOX6LVw5fQ4Llq/je58ew2fqhu99JjOzElTIgGhg5+f7VrPjEFKLLwITASLiGUlVJA9hb8u8ebdk1UYum/ZHVqzbzJ2XnciZHz600F9pZtZpFfIspjnAaEmj0ufnTgZmt2rzFjABQNLRQBWwMm03WVJ3SaOA0cAfC1grL729lgt//DRrP9jGfVed5HAwsy6vYHsQEdEo6RqSZ/yWA9MiYr6kqUB9RMwmee7unZK+RnII6YpIHlAxX9L9JB3ajcBXCnkG0+8XruTL98ylX89uzLxyHEce0rtQX2VmdsAomQcG1dXVRXvu5rro3Q184pb/4ohBvbn7ynEc2qeqANWZmXVOkuZGRF3WZyVzu+/2OvKQ3nzrk8fyyZqh9O1RWexyzMw6jS4fEACfO+mwYpdgZtbp+F5MZmaWyQFhZmaZHBBmZpbJAWFmZpkcEGZmlskBYWZmmRwQZmaWyQFhZmaZHBBmZpbJAWFmZpkcEGZmlskBYWZmmRwQZmaWyQFhZmaZHBBmZpbJAWFmZpkcEGZmlskBYWZmmRwQZmaWyQFhZmaZHBBmZpapoAEhaaKkVyUtkjQl4/MfSpqXDq9JWpPzWVPOZ7MLWaeZme2qolALllQO3AacBTQAcyTNjogFLW0i4ms57a8FxuYs4oOIqC1UfWZmtmeF3IMYByyKiMURsRWYCZy3h/YXAzMKWI+Zme2DQgbEMGBpznhDOm0Xkg4DRgGP50yuklQv6VlJn9rNfFenbepXrlyZr7rNzIzCBoQypsVu2k4GHoyIppxpIyKiDrgE+JGkI3ZZWMQdEVEXEXWDBg3a/4rNzGy7QgZEAzA8Z7waWLabtpNpdXgpIpalr4uBJ9m5f8LMzAqskAExBxgtaZSkbiQhsMvZSJI+BBwMPJMz7WBJ3dP3A4FTgAWt5zUzs8Ip2FlMEdEo6RrgEaAcmBYR8yVNBeojoiUsLgZmRkTu4aejgZ9IaiYJsZtzz34yM7PC087b5QNXXV1d1NfXF7sMM7MDiqS5aX/vLnwltZmZZXJAmJlZJgeEmZllckCYmVkmB4SZmWVyQJiZWSYHhJmZZXJAmJlZJgeEmZllckCYmVkmB4SZmWVyQJiZWSYHhJmZZXJAmJlZJgeEmZllckCYmVkmB4SZmWVyQJiZWSYHhJmZZXJAmJlZJgeEmZllckCYmVkmB4SZmWVyQJiZWaaCBoSkiZJelbRI0pSMz38oaV46vCZpTc5nl0tamA6XF7JOMzPbVUWhFiypHLgNOAtoAOZImh0RC1raRMTXctpfC4xN3/cHvgXUAQHMTed9v1D1mpnZzgq5BzEOWBQRiyNiKzATOG8P7S8GZqTvzwEejYjVaSg8CkwsYK1mZtZKIQNiGLA0Z7whnbYLSYcBo4DH92VeSVdLqpdUv3LlyrwUbWZmiUIGhDKmxW7aTgYejIimfZk3Iu6IiLqIqBs0aFA7yzQzsyyFDIgGYHjOeDWwbDdtJ7Pj8NK+zmtmZgVQyICYA4yWNEpSN5IQmN26kaQPAQcDz+RMfgQ4W9LBkg4Gzk6nmZlZBynYWUwR0SjpGpINezkwLSLmS5oK1EdES1hcDMyMiMiZd7Wkm0hCBmBqRKwuVK1mZrYr5WyXD2h1dXVRX19f7DLMzA4okuZGRF3WZ76S2szMMjkgzMwskwPCzMwyOSDMzCyTA8LMzDI5IMzMLJMDwszMMjkg1r4NPz4V5s8qdiVmZp2KA6L3obB6MSx5utiVmJl1Kg6I8gqoPhHeembvbc3MuhAHBMDwk2DFS7BlfbErMTPrNBwQACPGQzRDg+/lZGbWomB3cz2gVH8EECx9Do44o9jVmFkr27Zto6Ghgc2bNxe7lANWVVUV1dXVVFZWtnkeBwRAVV849Fh469liV2JmGRoaGjjooIMYOXIkUtYDJ21PIoJVq1bR0NDAqFGj2jyfDzG1GHESNMyBpsZiV2JmrWzevJkBAwY4HNpJEgMGDNjnPTAHRIvhJ8HWDfDu/GJXYmYZHA77pz0/PwdEixHjk9e3nituHWbWaT300ENI4pVXXil2KR1irwEh6VBJd0n6z3T8GElfLHxpHazvcDhoKCx1P4SZZZsxYwannnoqM2fOLNh3NDU1FWzZ+6otexDTSZ4rPTQdfw34aqEKKhop2YvwHoSZZdiwYQNPPfUUd911104B8S//8i8cf/zx1NTUMGXKFAAWLVrExz/+cWpqajjhhBN4/fXXefLJJzn33HO3z3fNNdcwffp0AEaOHMnUqVM59dRTeeCBB7jzzjv5yEc+Qk1NDRdeeCGbNm0CYMWKFZx//vnU1NRQU1PD008/zd///d9zyy23bF/u3/3d33HrrbfmZZ3bchbTwIi4X9INABHRKKnzRFw+DT8J5j8Ea5ZCv+HFrsbMMvzjL+ezYNm6vC7zmKF9+NYnj91jm1mzZjFx4kSOOuoo+vfvz/PPP8+KFSuYNWsWzz33HD179mT16tUAXHrppUyZMoXzzz+fzZs309zczNKlS/e4/KqqKv7whz8AsGrVKq666ioAbrzxRu666y6uvfZarrvuOk477TQeeughmpqa2LBhA0OHDuWCCy7g+uuvp7m5mZkzZ/LHP/4xDz+VtgXERkkDgACQdBKwNi/f3tmMOCl5XfqcA8LMdjJjxgy++tXk4MnkyZOZMWMGzc3NfOELX6Bnz54A9O/fn/Xr1/P2229z/vnnA8mGvy0++9nPbn//0ksvceONN7JmzRo2bNjAOeecA8Djjz/Oz372MwDKy8vp27cvffv2ZcCAAbzwwgusWLGCsWPHMmDAgLysc1sC4uvAbOAISU8Bg4BP5+XbO5tDj4PKXsn1EMeX5iqaHej29pd+IaxatYrHH3+cl156CUk0NTUhiQsvvHCXs4MiInMZFRUVNDc3bx9vfcppr169tr+/4oormDVrFjU1NUyfPp0nn3xyj/V96UtfYvr06bzzzjtceeWV+7h2u7fXPoiIeB44DTgZ+G/AsRHxYt4q6EzKK6C6zh3VZraTBx98kMsuu4wlS5bw5ptvsnTpUkaNGkX//v2ZNm3a9j6C1atX06dPH6qrq5k1K3mEwJYtW9i0aROHHXYYCxYsYMuWLaxdu5bHHntst9+3fv16hgwZwrZt27j33nu3T58wYQI//vGPgaQze9265FDb+eefz69//WvmzJmzfW8jH9pyFtNlwCXAicAJwMXptL2SNFHSq5IWSZqymzYXSVogab6k+3KmN0malw6z27Y6eTDiJFgx3zfuM7PtZsyYsf2QUYsLL7yQZcuWMWnSJOrq6qitreX73/8+APfccw+33norY8aM4eSTT+add95h+PDhXHTRRYwZM4ZLL72UsWPH7vb7brrpJsaPH89ZZ53Fhz/84e3Tb7nlFp544gmOP/54TjzxRObPT67b6tatG2eccQYXXXQR5eXleVtv7W53aHsD6V9zRquACcDzEbHHYzCSyknOeDoLaADmABdHxIKcNqOB+4EzI+J9SYdExLvpZxsiondbV6Suri7q6/Nws71Fj8HPL4DPPwRHnLn/yzOz/fbyyy9z9NFHF7uMTqu5uZkTTjiBBx54gNGjR++2XdbPUdLciKjLat+WQ0zX5gxXAWOBbm2oeRywKCIWR8RWYCZwXqs2VwG3RcT76Xe924blFlb1R0Blvi+TmR0QFixYwJFHHsmECRP2GA7t0Z6b9W0C2lLFMCD3vK4GYHyrNkcBpJ3f5cA/RMSv08+qJNUDjcDNEbHLM0ElXQ1cDTBixIh9WYfdq+rjG/eZ2QHjmGOOYfHixQVZ9l4DQtIvSU9xJdnjOIbksNBeZ82Y1vp4VgVJ2JwOVAO/l3RcRKwBRkTEMkmHA49L+nNEvL7TwiLuAO6A5BBTG2pqm+Enwbz7khv3lfuGt2bWNbVl6/f9nPeNwJKIaGjDfA1A7sUE1cCyjDbPRsQ24A1Jr5IExpyIWAYQEYslPUlyaOt1OsKIk2DOnclT5obWdshXmpl1Nm3pg/hdzvBUG8MBkk7p0ZJGSeoGTCa5niLXLOAMAEkDSQ45LZZ0sKTuOdNPARbQUYanR8KW+rYbZtZ17TYgJK2XtC5jWC9pr9e5R0QjcA3JfZxeBu6PiPmSpkqalDZ7BFglaQHwBPCNiFgFHA3US/pTOv3m3LOfCq7fcOgzDN56psO+0syss9ntIaaIOGh/Fx4RDwMPt5r2zZz3QXKl9tdbtXkaOH5/v3+/DB+fdFRHJDfyM7MurXfv3mzYsKHYZXSoNj8PQtIhkka0DIUsqlMY8VFYvwzW7vkGW2ZmpaotV1JPkrQQeAP4HfAm8J8Frqv4/AAhM9uLJUuWMGHCBMaMGcOECRN46623AHjggQc47rjjqKmp4WMf+xgA8+fPZ9y4cdTW1jJmzBgWLlxYzNLbpC1nMd0EnAT8NiLGSjoDuLiwZXUChxwLFVWw7AUY85liV2NmLf5zCrzz5/wuc/Dx8Imb93m2a665hssuu4zLL7+cadOmcd111zFr1iymTp3KI488wrBhw1izZg0At99+O9dffz2XXnopW7du7VQPBtqdthxi2pZ2HJdJKouIJ4DSP/ezvCL5pVn2QrErMbNO6plnnuGSSy4B4POf//z25zmccsopXHHFFdx5553bg+CjH/0o3/nOd/jud7/LkiVL6NGjR9Hqbqu27EGskdQb+D1wr6R3Sa6HKH1DauFPM6C5Gcr8+G6zTqEdf+l3lJZbf99+++0899xz/OpXv6K2tpZ58+ZxySWXMH78eH71q19xzjnn8NOf/pQzz+zc93vb02mu/0fSKST3T9pE8pjRX5NcrPbJjimvyIaOha0bYNWiYldiZp3QySefvP3xo/feey+nnnoqAK+//jrjx49n6tSpDBw4kKVLl7J48WIOP/xwrrvuOiZNmsSLL3b+pybsaQ9iIclV1EOAXwAzIuLuDqmqs2i5inrZCzDoqOLWYmZFtWnTJqqrq7ePf/3rX+fWW2/lyiuv5Hvf+x6DBg3i3/7t3wD4xje+wcKFC4kIJkyYQE1NDTfffDM///nPqaysZPDgwXzzm9/c3Vd1Gm253fdhJFdBTya53fd9wC8i4rXCl9d2ebvdd66mRvjnaqj7Akz85/wu28zazLf7zo9C3O57SUR8NyLGkjw46AKSK6NLnzuqzawLa8t1EJWSPinpXpLrH14DLix4ZZ3F0FpY/iI0d/5T0szM8mlPndRnSZpGcsfVq0lumXFERHw269kMJWvoWNi20R3VZtbl7GkP4m+BZ4CjI+KTEXFvRGzsoLo6jyE5HdVmVjR76y+1PWvPz2+3ARERZ0TEnRGxer+qOtANPAoqesCyecWuxKzLqqqqYtWqVQ6JdooIVq1aRVVV1T7N58el7U15BQwZ4z0IsyKqrq6moaGBlStXFruUA1ZVVdVOp+m2hQOiLYbUwgv3JB3VZeXFrsasy6msrGTUqFHFLqPL8f0j2mLoWNi2Cd7r/HdfNDPLFwdEWwx1R7WZdT0OiLYYeBRU9oTl7qg2s67DAdEWZeUw2B3VZta1OCDaamht8pCSpq5xp3MzMwdEW23vqO5U9yg0MysYB0RbtVxR7X4IM+siHBBtNXA0VPbyFdVm1mUUNCAkTZT0qqRFkqbsps1FkhZImi/pvpzpl0tamA6XF7LONikr9xXVZtalFOxKaknlwG3AWSR3hJ0jaXZELMhpMxq4ATglIt6XdEg6vT/wLaAOCGBuOu/7haq3TYbUwtzpSUd1uS9CN7PSVsg9iHHAoohYHBFbgZkkz7fOdRVwW8uGPyLeTaefAzwaEavTzx4FJhaw1rYZOhYaP4D3Xi12JWZmBVfIgBgGLM0Zb0in5ToKOErSU5KelTRxH+ZF0tWS6iXVd8hNvLZfUe1+CDMrfYUMCGVMa32v3gpgNHA6cDHwU0n92jgvEXFHRNRFRN2gQYP2s9w2GHAkdOvtM5nMrEsoZEA0AMNzxquBZRlt/iMitkXEG8CrJIHRlnk7nq+oNrMupJABMQcYLWmUpG7AZGB2qzazgDMAJA0kOeS0GHgEOFvSwZIOBs5OpxXf0LG+otrMuoSCBURENALXkGzYXwbuj4j5kqZKmpQ2ewRYJWkB8ATwjYhYlT7F7iaSkJkDTO00T7YbWguNm2HlK8WuxMysoAp6rmZEPAw83GraN3PeB/D1dGg97zRgWiHra5fcK6oHH1fcWszMCshXUu+rlo5qn8lkZiXOAbGvysqSjmqfyWRmJc4B0R5Da+Gdl9xRbWYlzQHRHkNq0iuqfetvMytdDoj28K2/zawLcEC0h2/9bWZdgAOiPcrKYfDxsPxPxa7EzKxgHBDtNbQW3nkRmpuKXYmZWUE4INprSE36jOqFxa7EzKwgHBDt5Y5qMytxDoj2GngUVPRwP4SZlSwHRHuVVyQd1T6TycxKlANif2zvqG4udiVmZnnngNgfQ2pg6wZYtajYlZiZ5Z0DYn9s76h2P4SZlR4HxP4Y9GGoqPKZTGZWkhwQ+6O8Ag49zh3VZlaSHBD7a0hNcojJHdVmVmIcEPtraC1sXQ/vv1HsSszM8soBsb9aOqqXvVDcOszM8swBsb8OORrKu7uj2sxKjgNif5VXwqHHuqPazEqOAyIfhtTA8hchotiVmJnlTUEDQtJESa9KWiRpSsbnV0haKWleOnwp57OmnOmzC1nnfhtaC1vWuqPazEpKRaEWLKkcuA04C2gA5kiaHRELWjX9RURck7GIDyKitlD15dX2jup50P/w4tZiZpYnhdyDGAcsiojFEbEVmAmcV8DvK55DjoGySndUm1lJKWRADAOW5ow3pNNau1DSi5IelDQ8Z3qVpHpJz0r6VAHr3H8V3eDQY9xRbWYlpZABoYxprXtxfwmMjIgxwG+Bu3M+GxERdcAlwI8kHbHLF0hXpyFSv3LlynzV3T5DapMrqt1RbWYlopAB0QDk7hFUA8tyG0TEqojYko7eCZyY89my9HUx8CQwtvUXRMQdEVEXEXWDBg3Kb/X7amgtbF4Da5YUtw4zszwpZEDMAUZLGiWpGzAZ2OlsJElDckYnAS+n0w+W1D19PxA4BWjdud25DE3zq6G+uHWYmeVJwc5iiohGSdcAjwDlwLSImC9pKlAfEbOB6yRNAhqB1cAV6exHAz+R1EwSYjdnnP3UuQweAz36w8JH4fhPF7saM7P9VrCAAIiIh4GHW037Zs77G4AbMuZ7Gji+kLXlXVk5HPlxWPQoNDcl42ZmBzBfSZ1PR50Dm1b5xn1mVhIcEPl0xJmgMnjtkWJXYma23xwQ+dSzP1SPg4UOCDM78Dkg8u2os5PrIda/U+xKzMz2iwMi30afk7wufLS4dZiZ7ScHRL4deiz0GebDTGZ2wHNA5JsEo8+C15+Exq3FrsbMrN0cEIUw+hzYuh7eerrYlZiZtZsDohAOPw3Ku7kfwswOaA6IQujWC0ae6ushzOyA5oAolNHnwKqFsHpxsSsxM2sXB0ShHHV28vrab4pbh5lZOzkgCqX/4TBgNCx0QJjZgckBUUijz4Y3/wBbNxa7EjOzfeaAKKSjzoamLbD4d8WuxMxsnzkgCmnEydDtIF9VbWYHJAdEIVV0gyNOT66HiCh2NWZm+8QBUWijz4Z1b0PDnGJXYma2TxwQhfbhc6H3YHjwSli/otjVmJm1mQOi0Hr2h0tmJo8inXkxbPug2BWZmbWJA6IjDB0LF9wJbz8PD30ZmpuLXZGZ2V45IDrK0efCWVNhwSx44tvFrsbMbK8qil1Al3LytbBqEfz+B9D/CBh7abErMjPbLQdER5Lgr34Aa5bAL6+HfiNg1F8Uuyozs0wFPcQkaaKkVyUtkjQl4/MrJK2UNC8dvpTz2eWSFqbD5YWss0OVV8Jn7k7u1fSLS+G3/5hcab1tc7ErMzPbiaJAF3BJKgdeA84CGoA5wMURsSCnzRVAXURc02re/kA9UAcEMBc4MSLe39331dXVRX19fb5Xo3DefxNmfQXeegaiCSp6wGEfhcNPh8NOhR79kjAp756+doOyCmjamgyNW5LbeDRuheZtUFEFFd2T5VR0h8oeSXup49YpArZtSuqr6tex321m7SJpbkTUZX1WyENM44BFEbE4LWImcB6wYI9zJc4BHo2I1em8jwITgRkFqrXjHTwSvvAr2LwOljwNi5+AxU/Co9/M45coZyOdvuZutLf/cRA72lRUQWVVEjQtrxXdkyE3sCq6QzTDptXpsCoZmrYki6roAX2HQZ9h0Hd48r7nwB3fL+XUJygrB5XnvJYl9TVthcbNSSA2bk4CUWVJgFb1TYKoqm8yXtmj1TLKk7aQ1NrclIRxc2PO++Zdp1VUQc8B0KM/lHfgUdjmZvhgNWxcmQwb3k1+tgcdCkNqoN9hDl3rUIX87R8GLM0ZbwDGZ7S7UNLHSPY2vhYRS3cz77DWM0q6GrgaYMSIEXkqu4NV9YEPTUwGgHXLk6uut32QbGybtkLTtmQD2bwt2UBXdE/2KFo23GUVyYazcXOrId1Ytw6CiOzgaG7K2RBvTmpoeW3aBls3QdP7O+qBZEPatzrZgPXsn4yXVcC6ZbCuAda+Da8/Buvf2fH9B5Kqvsk69RyQBEdLiOQGjsp37OXl7u2VVSQB1RJUSl8bN8OW9bB1A2xZl7zfsiEJh9jDKdBVfWHwmORnPfh46NY7DbacoWlbsvytG5N/t20fwLaNyb9XzwFJyPQbnvR/9RsB3Q9KfnfWvQ1rl8Kapcnr+uVJoB88csfQZ2iyLtZlFDIgsv7Uab2F+CUwIyK2SPoycDdwZhvnJSLuAO6A5BDT/pXbSfQZAsdMKnYV+de0DTavTcMqdrxCq7/ucza+UhqG3XP2Yron7Tavg81rkmV+sCZ5v+2DXZcRzcn35O5R5O5hlFXsuvfS+MHOe0WbVsOm95J1KCsHVe680Y/mnCDfvOP9LmES6R5K92TD3L0P9KlO3/dONuC9BkGvgdDrkOR9z/7JBnv5i7D8T/DOizDnp8n37I3KoLJXsmdVUQUb3911vu59koDa6b+Xku/9YE1Sb4uyymRPsLx7TtOcPzRafpbllUnblp9v8o+cvuT8u++0t1eR7DWWVUK3nslNLrv3Th7f2y193b7MtH4bf/oAAAfzSURBVL3SsNqyLv0dWJv+TqxJQq/P0OSPl34j0r3Y6uQPMmuzQgZEAzA8Z7waWJbbICJW5YzeCXw3Z97TW837ZN4rtI5TXpls+PKiAnoPSoauoPchMOzEHeNNjbD69WSvoGVPpbxix/uKqmSDWt5t10OKG1fCmrd2DOuWQY+Dk72KvsOT1z7DkhBr2gZrG5Kz7t5/MxnWNiTTkwXmLLs5OUTWvC0Nx3SPZnsgZRzujOakTcuhvubGZP6tG5Nhl+Bqg8qeyWHH8opkr7Vpa6vPeyWfKeOPg7Kcn2HuHw87/VEDO/2BE81piem0im7Q+9Dk36z34OTwYO/BySHQ3H+H7f+WW3es79YN6V7lhuT/S9/qdEj/TSqr9u1nkQeFDIg5wGhJo4C3gcnAJbkNJA2JiOXp6CTg5fT9I8B3JB2cjp8N3FDAWs0OHOUVMOhD+z6flG64DoHqzD7JVt9TCf1HJUMxtJz00LLxbE73DreHSmPSrnvaB9W9T7KBbtHcnOw1rVkKa99Kwm39ip3n37632bhj2a3ft+4vg+S9ynaeLiWBuPbt5K4JG1fSvsOqyp6v16Ak/KJ512HwmOSWPnlWsICIiEZJ15Bs7MuBaRExX9JUoD4iZgPXSZoENAKrgSvSeVdLuokkZACmtnRYm1kXIaWHmHoBh+z7/GVlcNDgZBj+kbyXt1dNjenJBu8kh0R3OsEgfV9WkXMo7aDktbJHsmexblkSatuHt5LlbD+8mdOv1X9kQVahYKe5drQD7jRXM7NOYE+nufpeTGZmlskBYWZmmRwQZmaWyQFhZmaZHBBmZpbJAWFmZpkcEGZmlskBYWZmmUrmQjlJK4El+7GIgcB7eSqns+tK6wpe31LWldYVCrO+h0VE5o3NSiYg9pek+t1dTVhqutK6gte3lHWldYWOX18fYjIzs0wOCDMzy+SA2OGOYhfQgbrSuoLXt5R1pXWFDl5f90GYmVkm70GYmVkmB4SZmWXq8gEhaaKkVyUtkjSl2PXkm6Rpkt6V9FLOtP6SHpW0MH09eE/LOFBIGi7pCUkvS5ov6fp0eqmub5WkP0r6U7q+/5hOHyXpuXR9fyGp296WdSCRVC7pBUn/Lx0v2fWV9KakP0uaJ6k+ndZhv89dOiAklQO3AZ8AjgEulnRMcavKu+nAxFbTpgCPRcRo4LF0vBQ0An8dEUcDJwFfSf89S3V9twBnRkQNUAtMlHQS8F3gh+n6vg98sYg1FsL17Hh+PZT++p4REbU51z902O9zlw4IYBywKCIWR8RWYCZwXpFryquI+C+S533nOg+4O31/N/CpDi2qQCJieUQ8n75fT7IRGUbprm9ExIZ0tDIdAjgTeDCdXjLrCyCpGvgr4KfpuCjh9d2NDvt97uoBMQxYmjPekE4rdYdGxHJINqq064nwnZukkcBY4DlKeH3Twy3zgHeBR4HXgTUR0Zg2KbXf6R8B/xNoTscHUNrrG8BvJM2VdHU6rcN+nysKteADhDKm+bzfA5yk3sD/Bb4aEeuSPzJLU0Q0AbWS+gEPAUdnNevYqgpD0rnAuxExV9LpLZMzmpbE+qZOiYhlkg4BHpX0Skd+eVffg2gAhueMVwPLilRLR1ohaQhA+vpukevJG0mVJOFwb0T8ezq5ZNe3RUSsAZ4k6XvpJ6nlj79S+p0+BZgk6U2Sw8FnkuxRlOr6EhHL0td3Sf4AGEcH/j539YCYA4xOz4LoBkwGZhe5po4wG7g8fX858B9FrCVv0uPRdwEvR8T/zvmoVNd3ULrngKQewMdJ+l2eAD6dNiuZ9Y2IGyKiOiJGkvxffTwiLqVE11dSL0kHtbwHzgZeogN/n7v8ldSS/pLkr5ByYFpE/FORS8orSTOA00luE7wC+BYwC7gfGAG8BXwmIlp3ZB9wJJ0K/B74MzuOUf8tST9EKa7vGJJOynKSP/buj4ipkg4n+Qu7P/AC8LmI2FK8SvMvPcT0NxFxbqmub7peD6WjFcB9EfFPkgbQQb/PXT4gzMwsW1c/xGRmZrvhgDAzs0wOCDMzy+SAMDOzTA4IMzPL5IAwKyJJp7fcldSss3FAmJlZJgeEWRtI+lz67IV5kn6S3iRvg6QfSHpe0mOSBqVtayU9K+lFSQ+13K9f0pGSfps+v+F5SUeki+8t6UFJr0i6N70iHEk3S1qQLuf7RVp168IcEGZ7Ielo4LMkN06rBZqAS4FewPMRcQLwO5Kr1AF+BvyviBhDclV3y/R7gdvS5zecDCxPp48FvkryTJLDgVMk9QfOB45Nl/Ptwq6l2a4cEGZ7NwE4EZiT3lp7AsmGvBn4Rdrm58CpkvoC/SLid+n0u4GPpffUGRYRDwFExOaI2JS2+WNENEREMzAPGAmsAzYDP5V0AdDS1qzDOCDM9k7A3elTvWoj4kMR8Q8Z7fZ035o93XM8975BTUBF+nyDcSR3pv0U8Ot9rNlsvzkgzPbuMeDT6T35W54JfBjJ/5+Wu4heAvwhItYC70v6i3T654HfRcQ6oEHSp9JldJfUc3dfmD7Tom9EPExy+Km2ECtmtidd/YFBZnsVEQsk3UjyZK8yYBvwFWAjcKykucBakn4KSG7BfHsaAIuBL6TTPw/8RNLUdBmf2cPXHgT8h6Qqkr2Pr+V5tcz2yndzNWsnSRsionex6zArFB9iMjOzTN6DMDOzTN6DMDOzTA4IMzPL5IAwM7NMDggzM8vkgDAzs0z/H7qdaUk2ydXTAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial accuracy is:  0.7916667\n",
      "Final accuracy is:  0.8\n",
      "Initial loss is:  0.6780384055773417\n",
      "Final loss is:  0.49366639971733095\n"
     ]
    }
   ],
   "source": [
    "#plotting model history\n",
    "plt.plot(historygonogo.history['acc'])\n",
    "plt.plot(historygonogo.history['loss'])\n",
    "plt.legend(['Accuracy', 'Loss'])\n",
    "plt.title('Model History')\n",
    "plt.ylabel('Value')\n",
    "plt.xlabel('epochs')\n",
    "plt.show()\n",
    "print(\"Initial accuracy is: \", historygonogo.history['acc'][0])\n",
    "print(\"Final accuracy is: \", historygonogo.history['acc'][-1])\n",
    "\n",
    "print(\"Initial loss is: \", historygonogo.history['loss'][0])\n",
    "print(\"Final loss is: \", historygonogo.history['loss'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n"
     ]
    }
   ],
   "source": [
    "print('Hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
