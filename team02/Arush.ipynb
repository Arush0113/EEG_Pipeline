{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23.0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import pathlib\n",
    "\n",
    "import mne\n",
    "print(mne.__version__)\n",
    "import mne_bids\n",
    "\n",
    "matplotlib.use('Qt5Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bids_root = pathlib.Path('data')\n",
    "\n",
    "# bids_path = mne_bids.BIDSPath(subject = 'AB6',\n",
    "#                              task = 'gonogo',\n",
    "#                              datatype = 'eeg',\n",
    "#                              root = bids_root,\n",
    "#                              run = '1')\n",
    "\n",
    "# bids_path = mne_bids.BIDSPath(subject = 'AB6',\n",
    "# #                              session = '1',\n",
    "#                              datatype = 'eeg',\n",
    "#                              run = '1',\n",
    "#                              task = 'gonogo',\n",
    "#                              root = bids_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path1 = pathlib.Path('data/sub-AB6/eeg/sub-AB6_task-gonogo_run-1_eeg.set')\n",
    "\n",
    "# raw = mne.io.read_raw_eeglab(path1)\n",
    "# raw.load_data()\n",
    "\n",
    "# events = mne.find_events(raw)\n",
    "# event_id = {\n",
    "#     'Auditory/Left': 1,\n",
    "#     'Auditory/Right': 2,\n",
    "#     'Visual/Left': 3,\n",
    "#     'Visual/Right': 4,\n",
    "#     'Smiley': 5,\n",
    "#     'Button': 32\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw = mne_bids.read_raw_bids(bids_path)\n",
    "# raw.load_data()\n",
    "# raw.data()\n",
    "# raw.filter(l_freq = 0.1, h_freq = 40)\n",
    "# events, event_id = mne.events_from_annotations(raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the data using EEGLAB module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawab6_1 = mne.io.read_raw_eeglab('data/sub-AB6/eeg/sub-AB6_task-gonogo_run-1_eeg.set', eog=(), preload=True, uint16_codec=None, verbose=None)\n",
    "rawab6_2 = mne.io.read_raw_eeglab('data/sub-AB6/eeg/sub-AB6_task-gonogo_run-2_eeg.set', eog=(), preload=True, uint16_codec=None, verbose=None)\n",
    "\n",
    "rawab10_1 = mne.io.read_raw_eeglab('data/other subjects set files/sub-AB10_eeg_sub-AB10_task-gonogo_run-1_eeg.set', eog=(), preload=True, uint16_codec=None, verbose=None)\n",
    "rawab10_2 = mne.io.read_raw_eeglab('data/other subjects set files/sub-AB10_eeg_sub-AB10_task-gonogo_run-2_eeg.set', eog=(), preload=True, uint16_codec=None, verbose=None)\n",
    "\n",
    "# rawab11_1 = mne.io.read_raw_eeglab('data/other subjects set files/sub-AB11_eeg_sub-AB11_task-gonogo_run-1_eeg.set', eog=(), preload=True, uint16_codec=None, verbose=None)\n",
    "# rawab11_2 = mne.io.read_raw_eeglab('data/other subjects set files/sub-AB11_eeg_sub-AB11_task-gonogo_run-2_eeg.set', eog=(), preload=True, uint16_codec=None, verbose=None)\n",
    "\n",
    "rawab12_1 = mne.io.read_raw_eeglab('data/other subjects set files/sub-AB12_eeg_sub-AB12_task-gonogo_run-1_eeg.set', eog=(), preload=True, uint16_codec=None, verbose=None)\n",
    "rawab12_2 = mne.io.read_raw_eeglab('data/other subjects set files/sub-AB12_eeg_sub-AB12_task-gonogo_run-2_eeg.set', eog=(), preload=True, uint16_codec=None, verbose=None)\n",
    "\n",
    "rawab13_1 = mne.io.read_raw_eeglab('data/other subjects set files/sub-AB13_eeg_sub-AB13_task-gonogo_run-1_eeg.set', eog=(), preload=True, uint16_codec=None, verbose=None)\n",
    "rawab13_2 = mne.io.read_raw_eeglab('data/other subjects set files/sub-AB13_eeg_sub-AB13_task-gonogo_run-2_eeg.set', eog=(), preload=True, uint16_codec=None, verbose=None)\n",
    "\n",
    "rawab28_1 = mne.io.read_raw_eeglab('data/other subjects set files/sub-AB28_eeg_sub-AB28_task-gonogo_run-1_eeg.set', eog=(), preload=True, uint16_codec=None, verbose=None)\n",
    "rawab28_2 = mne.io.read_raw_eeglab('data/other subjects set files/sub-AB28_eeg_sub-AB28_task-gonogo_run-2_eeg.set', eog=(), preload=True, uint16_codec=None, verbose=None)\n",
    "\n",
    "rawab31_1 = mne.io.read_raw_eeglab('data/other subjects set files/sub-AB31_eeg_sub-AB31_task-gonogo_run-1_eeg.set', eog=(), preload=True, uint16_codec=None, verbose=None)\n",
    "rawab31_2 = mne.io.read_raw_eeglab('data/other subjects set files/sub-AB31_eeg_sub-AB31_task-gonogo_run-2_eeg.set', eog=(), preload=True, uint16_codec=None, verbose=None)\n",
    "\n",
    "rawab32_1 = mne.io.read_raw_eeglab('data/other subjects set files/sub-AB32_eeg_sub-AB32_task-gonogo_run-1_eeg.set', eog=(), preload=True, uint16_codec=None, verbose=None)\n",
    "rawab32_2 = mne.io.read_raw_eeglab('data/other subjects set files/sub-AB32_eeg_sub-AB32_task-gonogo_run-2_eeg.set', eog=(), preload=True, uint16_codec=None, verbose=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MNEBrowseFigure size 1920x828 with 4 Axes>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawab6_1.plot()\n",
    "rawab10_1.plot()\n",
    "rawab12_1.plot()\n",
    "rawab13_1.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "The 64 eeg channels indices are:\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "66\n",
      "The 66 eeg channels indices are:\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65]\n"
     ]
    }
   ],
   "source": [
    "rawab13_2.info\n",
    "# rawab6_2.info\n",
    "channel_indices_ab6_1 = mne.pick_types(rawab6_1.info, eeg=True)\n",
    "channel_indices_ab13_1 = mne.pick_types(rawab13_1.info, eeg=True)\n",
    "print(len(channel_indices_ab6_1))\n",
    "print(f\"The {len(channel_indices_ab6_1)} eeg channels indices are:\\n{channel_indices_ab6_1}\")\n",
    "print(len(channel_indices_ab13_1))\n",
    "print(f\"The {len(channel_indices_ab13_1)} eeg channels indices are:\\n{channel_indices_ab13_1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eeg_indices = mne.pick_types(rawab13_1.info, meg=False, eeg=True)\n",
    "# reduced_info = mne.pick_info(rawab13_1.info, eeg_indices)\n",
    "# reduced_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the events for all Subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['1', '10', '2', '4', '5', '9']\n",
      "Used Annotations descriptions: ['1', '10', '2', '4', '5', '6', '7', '9']\n",
      "Used Annotations descriptions: ['1', '10', '11', '2', '3', '4', '5', '9']\n",
      "Used Annotations descriptions: ['1', '10', '2', '3', '4', '5', '9']\n",
      "Used Annotations descriptions: ['1', '10', '2', '4', '5', '6', '7', '9']\n",
      "Used Annotations descriptions: ['1', '10', '11', '2', '3', '4', '5', '6', '7', '9']\n",
      "Used Annotations descriptions: ['1', '10', '2', '3', '4', '5', '9']\n",
      "Used Annotations descriptions: ['1', '10', '11', '2', '4', '5', '6', '7', '9']\n",
      "Used Annotations descriptions: ['1', '10', '2', '4', '5', '6', '7', '9']\n",
      "Used Annotations descriptions: ['1', '10', '2', '3', '4', '5', '6', '7', '9']\n",
      "Used Annotations descriptions: ['1', '10', '2', '3', '4', '5', '9']\n",
      "Used Annotations descriptions: ['1', '10', '2', '3', '4', '5', '6', '7', '9']\n",
      "Used Annotations descriptions: ['1', '10', '11', '2', '3', '4', '5', '6', '7', '9']\n",
      "Used Annotations descriptions: ['1', '10', '2', '4', '5', '6', '7', '9']\n"
     ]
    }
   ],
   "source": [
    "eventsab6_1 = mne.events_from_annotations(rawab6_1)\n",
    "eventsab6_2 = mne.events_from_annotations(rawab6_2)\n",
    "\n",
    "eventsab10_1 = mne.events_from_annotations(rawab10_1)\n",
    "eventsab10_2 = mne.events_from_annotations(rawab10_2)\n",
    "\n",
    "eventsab12_1 = mne.events_from_annotations(rawab12_1)\n",
    "eventsab12_2 = mne.events_from_annotations(rawab12_2)\n",
    "\n",
    "eventsab13_1 = mne.events_from_annotations(rawab13_1)\n",
    "eventsab13_2 = mne.events_from_annotations(rawab13_2)\n",
    "\n",
    "eventsab28_1 = mne.events_from_annotations(rawab28_1)\n",
    "eventsab28_2 = mne.events_from_annotations(rawab28_2)\n",
    "\n",
    "eventsab31_1 = mne.events_from_annotations(rawab31_1)\n",
    "eventsab31_2 = mne.events_from_annotations(rawab31_2)\n",
    "\n",
    "eventsab32_1 = mne.events_from_annotations(rawab32_1)\n",
    "eventsab32_2 = mne.events_from_annotations(rawab32_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the event_id dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'taskstart': '9',\n",
       " 'cue': '1',\n",
       " 'go': '2',\n",
       " 'button press': '5',\n",
       " 'no-go': '4',\n",
       " 'task end': '10',\n",
       " 'error 1': '3',\n",
       " 'error 2': '6',\n",
       " 'error 3': '7',\n",
       " 'error 4': '8',\n",
       " 'error 5': '11'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_id = {\n",
    "    \"taskstart\" : '9',\n",
    "    \"cue\" : \"1\",\n",
    "    \"go\" : \"2\",\n",
    "    \"button press\" : \"5\",\n",
    "    \"no-go\" : \"4\",\n",
    "    \"task end\": \"10\",\n",
    "    \"error 1\" : \"3\",\n",
    "    \"error 2\" : \"6\",\n",
    "    \"error 3\" : \"7\",\n",
    "    \"error 4\" : \"8\",\n",
    "    \"error 5\" : \"11\"\n",
    "}\n",
    "event_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping unwanted channels from the various Subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "<table class=\"table table-hover\">\n",
       "    <tr>\n",
       "        <th>Measurement date</th>\n",
       "<td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Experimenter</th>\n",
       "<td>Unknown</td>\n",
       "    </tr>\n",
       "        <th>Participant</th>\n",
       "<td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Digitized points</th>\n",
       "        <td>66 points</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Good channels</th>\n",
       "        <td>0 magnetometer, 0 gradiometer,\n",
       "            and 63 EEG channels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Bad channels</th>\n",
       "        <td></td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>EOG channels</th>\n",
       "        <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>ECG channels</th>\n",
       "        <td>Not available</td>\n",
       "    <tr>\n",
       "        <th>Sampling frequency</th>\n",
       "        <td>500.00 Hz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Highpass</th>\n",
       "        <td>0.00 Hz</td>\n",
       "    </tr>\n",
       "     <tr>\n",
       "        <th>Lowpass</th>\n",
       "        <td>250.00 Hz</td>\n",
       "    </tr>\n",
       "\n",
       "    <tr>\n",
       "        <th>Filenames</th>\n",
       "        <td>sub-AB32_eeg_sub-AB32_task-gonogo_run-2_eeg.set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Duration</th>\n",
       "        <td>00:08:16 (HH:MM:SS)</td>\n",
       "    </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<RawEEGLAB | sub-AB32_eeg_sub-AB32_task-gonogo_run-2_eeg.set, 63 x 248300 (496.6 s), ~119.4 MB, data loaded>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawab6_1.drop_channels(ch_names = \"EKG\")\n",
    "rawab6_2.drop_channels(ch_names = \"EKG\")\n",
    "\n",
    "rawab10_1.drop_channels(ch_names = [\"EKG\", \"R-Dia-X-(mm)\", \"R-Dia-Y-(mm)\"])\n",
    "rawab10_2.drop_channels(ch_names = [\"EKG\", \"R-Dia-X-(mm)\", \"R-Dia-Y-(mm)\"])\n",
    "\n",
    "rawab12_1.drop_channels(ch_names = [\"EKG\", \"R-Dia-X-(mm)\", \"R-Dia-Y-(mm)\"])\n",
    "rawab12_2.drop_channels(ch_names = [\"EKG\", \"R-Dia-X-(mm)\", \"R-Dia-Y-(mm)\"])\n",
    "\n",
    "rawab13_1.drop_channels(ch_names = [\"EKG\", \"R-Dia-X-(mm)\", \"R-Dia-Y-(mm)\"])\n",
    "rawab13_2.drop_channels(ch_names = [\"EKG\", \"R-Dia-X-(mm)\", \"R-Dia-Y-(mm)\"])\n",
    "\n",
    "rawab28_1.drop_channels(ch_names = [\"EKG\", \"R-Dia-X-(mm)\", \"R-Dia-Y-(mm)\"])\n",
    "rawab28_2.drop_channels(ch_names = [\"EKG\", \"R-Dia-X-(mm)\", \"R-Dia-Y-(mm)\"])\n",
    "\n",
    "rawab31_1.drop_channels(ch_names = [\"EKG\", \"R-Dia-X-(mm)\", \"R-Dia-Y-(mm)\"])\n",
    "rawab31_2.drop_channels(ch_names = [\"EKG\", \"R-Dia-X-(mm)\", \"R-Dia-Y-(mm)\"])\n",
    "\n",
    "rawab32_1.drop_channels(ch_names = [\"EKG\", \"R-Dia-X-(mm)\", \"R-Dia-Y-(mm)\"])\n",
    "rawab32_2.drop_channels(ch_names = [\"EKG\", \"R-Dia-X-(mm)\", \"R-Dia-Y-(mm)\"])\n",
    "\n",
    "# rawab14_1.drop_channels(ch_names = [\"EKG\", \"R-Dia-X-(mm)\", \"R-Dia-Y-(mm)\"])\n",
    "# rawab14_2.drop_channels(ch_names = [\"EKG\", \"R-Dia-X-(mm)\", \"R-Dia-Y-(mm)\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting 2D and 3D positions of the 63 Sensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawab6_1.plot_sensors(ch_type = 'eeg', sphere = 10);\n",
    "# rawab6_2.plot_sensors(ch_type = 'eeg', sphere = 10);\n",
    "\n",
    "rawab10_1.plot_sensors(ch_type = 'eeg', sphere = 10);\n",
    "# rawab10_2.plot_sensors(ch_type = 'eeg', sphere = 10);\n",
    "\n",
    "rawab12_1.plot_sensors(ch_type = 'eeg', sphere = 10);\n",
    "# rawab12_2.plot_sensors(ch_type = 'eeg', sphere = 10);\n",
    "\n",
    "rawab13_1.plot_sensors(ch_type = 'eeg', sphere = 10);\n",
    "# rawab13_2.plot_sensors(ch_type = 'eeg', sphere = 10);\n",
    "\n",
    "rawab28_1.plot_sensors(ch_type = 'eeg', sphere = 10);\n",
    "# rawab28_2.plot_sensors(ch_type = 'eeg', sphere = 10);\n",
    "\n",
    "rawab31_1.plot_sensors(ch_type = 'eeg', sphere = 10);\n",
    "# rawab31_2.plot_sensors(ch_type = 'eeg', sphere = 10);\n",
    "\n",
    "rawab32_1.plot_sensors(ch_type = 'eeg', sphere = 10);\n",
    "# rawab32_2.plot_sensors(ch_type = 'eeg', sphere = 10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawab6_1.plot_sensors(ch_type = 'eeg', kind = '3d');\n",
    "# rawab6_2.plot_sensors(ch_type = 'eeg', kind = '3d');\n",
    "\n",
    "rawab10_1.plot_sensors(ch_type = 'eeg', kind = '3d');\n",
    "# rawab10_2.plot_sensors(ch_type = 'eeg', kind = '3d');\n",
    "\n",
    "rawab12_1.plot_sensors(ch_type = 'eeg', kind = '3d');\n",
    "# rawab12_2.plot_sensors(ch_type = 'eeg', kind = '3d');\n",
    "\n",
    "rawab13_1.plot_sensors(ch_type = 'eeg', kind = '3d');\n",
    "# rawab13_2.plot_sensors(ch_type = 'eeg', kind = '3d');\n",
    "\n",
    "rawab28_1.plot_sensors(ch_type = 'eeg', kind = '3d');\n",
    "# rawab28_2.plot_sensors(ch_type = 'eeg', kind = '3d');\n",
    "\n",
    "rawab31_1.plot_sensors(ch_type = 'eeg', kind = '3d');\n",
    "# rawab31_2.plot_sensors(ch_type = 'eeg', kind = '3d');\n",
    "\n",
    "rawab32_1.plot_sensors(ch_type = 'eeg', kind = '3d');\n",
    "# rawab32_2.plot_sensors(ch_type = 'eeg', kind = '3d');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rawab6_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rawab6_1.plot_sensors(ch_type = 'eeg', sphere = 10)\n",
    "# rawab6_2.plot_sensors(ch_type = 'eeg', sphere = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing ICA and SSP Projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-1497dd8d8761>:1: DeprecationWarning: Version 0.23 introduced max_iter=\"auto\", setting max_iter=1000 for `fastica` and max_iter=500 for `infomax` and `picard`. The current default of max_iter=200 will be changed to \"auto\" in version 0.24.\n",
      "  ica = mne.preprocessing.ICA(n_components = 20, random_state = 42)\n"
     ]
    }
   ],
   "source": [
    "ica = mne.preprocessing.ICA(n_components = 20, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica.exclude = [11, 14, 19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_ab6_1 = ica.apply(rawab6_1.copy().filter(1, 50), exclude = ica.exclude)\n",
    "# clean_ab6_2 = ica.apply(rawab6_2.copy().filter(1, 50), exclude = ica.exclude)\n",
    "# clean_ab6_1.plot();\n",
    "# clean_ab6_2.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-56-1497dd8d8761>:1: DeprecationWarning: Version 0.23 introduced max_iter=\"auto\", setting max_iter=1000 for `fastica` and max_iter=500 for `infomax` and `picard`. The current default of max_iter=200 will be changed to \"auto\" in version 0.24.\n",
      "  ica = mne.preprocessing.ICA(n_components = 20, random_state = 42)\n"
     ]
    }
   ],
   "source": [
    "ica = mne.preprocessing.ICA(n_components = 20, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 8 - 35 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 8.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 7.00 Hz)\n",
      "- Upper passband edge: 35.00 Hz\n",
      "- Upper transition bandwidth: 8.75 Hz (-6 dB cutoff frequency: 39.38 Hz)\n",
      "- Filter length: 825 samples (1.650 sec)\n",
      "\n",
      "Fitting ICA to data using 63 channels (please be patient, this may take a while)\n",
      "Selecting by number: 20 components\n",
      "Fitting ICA took 12.4s.\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 8 - 35 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 8.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 7.00 Hz)\n",
      "- Upper passband edge: 35.00 Hz\n",
      "- Upper transition bandwidth: 8.75 Hz (-6 dB cutoff frequency: 39.38 Hz)\n",
      "- Filter length: 825 samples (1.650 sec)\n",
      "\n",
      "Fitting ICA to data using 63 channels (please be patient, this may take a while)\n",
      "Selecting by number: 20 components\n",
      "Fitting ICA took 8.6s.\n"
     ]
    }
   ],
   "source": [
    "cleaned_ab6_1 = ica.fit(rawab6_1.copy().filter(8, 35))\n",
    "cleaned_ab6_2 = ica.fit(rawab6_2.copy().filter(8, 35))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<MNEFigure size 975x963 with 20 Axes>]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ica.plot_components(outlines = 'head', sphere = 10, ch_type = 'eeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ICA' object has no attribute 'plot'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-70f1ef83ca8c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcleaned_ab6_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mcleaned_ab6_2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ICA' object has no attribute 'plot'"
     ]
    }
   ],
   "source": [
    "cleaned_ab6_1.plot();\n",
    "cleaned_ab6_2.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MNEFigure size 750x220 with 5 Axes>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evoked2.plot_topomap(ch_type = 'eeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ecg_projs, ecg_events = mne.preprocessing.compute_proj_ecg(rawab6_1, n_grad = 1, n_mag = 1, n_eeg = 0,\n",
    "#                                                            average = True)\n",
    "# eog_projs, eog_events = mne.preprocessing.compute_proj_eog(raw, n_grad = 1, n_mag = 1, n_eeg = 0,\n",
    "#                                                            average = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Epochs of data for different Subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(ica.plot_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': 1, '10': 2, '11': 3, '2': 4, '3': 5, '4': 6, '5': 7, '9': 8}\n"
     ]
    }
   ],
   "source": [
    "print(eventsab10_1[1])\n",
    "# print(eventsab6_1[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4968,     0,     8],\n",
       "       [ 7636,     0,     1],\n",
       "       [ 8707,     0,     4],\n",
       "       [ 8892,     0,     7],\n",
       "       [11940,     0,     1],\n",
       "       [12807,     0,     4],\n",
       "       [13123,     0,     7],\n",
       "       [15497,     0,     1],\n",
       "       [16752,     0,     4],\n",
       "       [17075,     0,     7]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eventsab10_1[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev_epochsab6_1 = epochsab6_1.events\n",
    "# ev_epochsab6_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "Not setting metadata\n",
      "152 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "152 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "155 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "153 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "154 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "158 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "153 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "156 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "154 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "157 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "155 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "159 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "167 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "154 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Loading data for 152 events and 351 original time points ...\n",
      "0 bad epochs dropped\n",
      "Loading data for 152 events and 351 original time points ...\n",
      "Loading data for 20 events and 351 original time points ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<MNEBrowseFigure size 1920x823 with 4 Axes>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 0 epochs: \n",
      "Channels marked as bad: none\n"
     ]
    }
   ],
   "source": [
    "epochsab6_1 = mne.Epochs(rawab6_1,\n",
    "                   events = eventsab6_1[0],\n",
    "                   event_id = eventsab6_1[1],\n",
    "                   )\n",
    "epochsab6_2 = mne.Epochs(rawab6_2,\n",
    "                   events = eventsab6_1[0],\n",
    "                   event_id = eventsab6_1[1],)\n",
    "\n",
    "epochsab10_1 = mne.Epochs(rawab10_1,\n",
    "                   events = eventsab10_1[0],\n",
    "                   event_id = eventsab10_1[1],)\n",
    "epochsab10_2 = mne.Epochs(rawab10_2,\n",
    "                   events = eventsab10_2[0],\n",
    "                   event_id = eventsab10_2[1],)\n",
    "\n",
    "epochsab12_1 = mne.Epochs(rawab12_1,\n",
    "                   events = eventsab12_1[0],\n",
    "                   event_id = eventsab12_1[1],)\n",
    "epochsab12_2 = mne.Epochs(rawab12_2,\n",
    "                   events = eventsab12_2[0],\n",
    "                   event_id = eventsab12_2[1],)\n",
    "\n",
    "epochsab13_1 = mne.Epochs(rawab13_1,\n",
    "                   events = eventsab13_1[0],\n",
    "                   event_id = eventsab13_1[1],)\n",
    "epochsab13_2 = mne.Epochs(rawab13_2,\n",
    "                   events = eventsab13_2[0],\n",
    "                   event_id = eventsab13_2[1],)\n",
    "\n",
    "epochsab28_1 = mne.Epochs(rawab28_1,\n",
    "                   events = eventsab28_1[0],\n",
    "                   event_id = eventsab28_1[1],)\n",
    "epochsab28_2 = mne.Epochs(rawab28_2,\n",
    "                   events = eventsab28_2[0],\n",
    "                   event_id = eventsab28_2[1],)\n",
    "\n",
    "epochsab31_1 = mne.Epochs(rawab31_1,\n",
    "                   events = eventsab31_1[0],\n",
    "                   event_id = eventsab31_1[1],)\n",
    "epochsab31_2 = mne.Epochs(rawab31_2,\n",
    "                   events = eventsab31_2[0],\n",
    "                   event_id = eventsab31_2[1],)\n",
    "\n",
    "epochsab32_1 = mne.Epochs(rawab32_1,\n",
    "                   events = eventsab32_1[0],\n",
    "                   event_id = eventsab32_1[1],)\n",
    "epochsab32_2 = mne.Epochs(rawab32_2,\n",
    "                   events = eventsab32_2[0],\n",
    "                   event_id = eventsab32_2[1],)\n",
    "\n",
    "epochsab6_1.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_keys_from_value(d, val):\n",
    "#     return [k for k, v in d.items() if v == val]\n",
    "\n",
    "# def replace(dataevents2, dataevents1):\n",
    "#     len = dataevents2.shape[0];\n",
    "#     for i in range(len):\n",
    "#         dataevents2[i][2] = int(get_keys_from_value(dataevents1[1], dataevents2[i][2])[0]);\n",
    "#     return dataevents2;\n",
    "\n",
    "#Changing event indicators(ex. 6 becomes 9)\n",
    "def get_keys_from_value(d, val):\n",
    "    return [k for k, v in d.items() if v == val]\n",
    "def fix_event_ids(epochsab, eventsab):\n",
    "    for i in range(epochsab.events.shape[0]):\n",
    "        epochsab.events[i][2] = int(get_keys_from_value(eventsab[1], epochsab.events[i][2])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(epochsab6_1.shape[0]):\n",
    "#     ev_epochsab6_1[i][2] = int(get_keys_from_value(eventsab6_1[1], ev_epochsab6_1[i][2])[0])\n",
    "fix_event_ids(epochsab6_1, eventsab6_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_event_ids(epochsab10_1, eventsab10_1)\n",
    "fix_event_ids(epochsab12_1, eventsab12_1)\n",
    "fix_event_ids(epochsab13_1, eventsab13_1)\n",
    "fix_event_ids(epochsab28_1, eventsab28_1)\n",
    "fix_event_ids(epochsab31_1, eventsab31_1)\n",
    "fix_event_ids(epochsab32_1, eventsab32_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_event_ids(epochsab10_2, eventsab10_2)\n",
    "fix_event_ids(epochsab12_2, eventsab12_2)\n",
    "fix_event_ids(epochsab13_2, eventsab13_2)\n",
    "fix_event_ids(epochsab28_2, eventsab28_2)\n",
    "fix_event_ids(epochsab31_2, eventsab31_2)\n",
    "fix_event_ids(epochsab32_2, eventsab32_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2398,     0,     9],\n",
       "       [ 5066,     0,     1],\n",
       "       [ 5914,     0,     2],\n",
       "       [ 6065,     0,     5],\n",
       "       [ 8825,     0,     1],\n",
       "       [ 9622,     0,     2],\n",
       "       [ 9751,     0,     5],\n",
       "       [13972,     0,     1],\n",
       "       [17720,     0,     1],\n",
       "       [18495,     0,     2]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochsab28_2.events[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<table class=\"table table-hover\">\n",
       "    <tr>\n",
       "        <th>Number of events</th>\n",
       "        <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Events</th>\n",
       "        <td>1: 60<br>10: 1<br>2: 40<br>4: 10<br>5: 40<br>9: 1<br></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Time range</th>\n",
       "        <td>-0.200 – 0.500 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Baseline</th>\n",
       "        <td>-0.200 – 0.000 sec</td>\n",
       "    </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<Epochs |  152 events (all good), -0.2 - 0.5 sec, baseline -0.2 – 0 sec, ~88 kB, data not loaded,\n",
       " '1': 60\n",
       " '10': 1\n",
       " '2': 40\n",
       " '4': 10\n",
       " '5': 40\n",
       " '9': 1>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochsab6_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<table class=\"table table-hover\">\n",
       "    <tr>\n",
       "        <th>Number of events</th>\n",
       "        <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Events</th>\n",
       "        <td>1: 60<br>10: 1<br>11: 1<br>2: 40<br>3: 2<br>4: 10<br>5: 40<br>9: 1<br></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Time range</th>\n",
       "        <td>-0.200 – 0.500 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Baseline</th>\n",
       "        <td>-0.200 – 0.000 sec</td>\n",
       "    </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<Epochs |  155 events (good & bad), -0.2 - 0.5 sec, baseline -0.2 – 0 sec, ~89 kB, data not loaded,\n",
       " '1': 60\n",
       " '10': 1\n",
       " '11': 1\n",
       " '2': 40\n",
       " '3': 2\n",
       " '4': 10\n",
       " '5': 40\n",
       " '9': 1>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochsab10_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rawab6_1 = ica.apply(rawab6_1.copy().filter(1, 50), exclude = ica.exclude)\n",
    "# raw_m.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evoked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 0 epochs: \n",
      "Channels marked as bad: none\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x296 with 1 Axes>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# target_ab6_1 = epochsab6_1[\"target\"].average()\n",
    "target = epochsab6_1[0].average()\n",
    "target.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<table class=\"table table-hover\">\n",
       "    <tr>\n",
       "        <th>Number of events</th>\n",
       "        <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Events</th>\n",
       "        <td>1: 60<br>10: 1<br>2: 40<br>4: 10<br>5: 40<br>9: 1<br></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Time range</th>\n",
       "        <td>-0.200 – 0.500 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Baseline</th>\n",
       "        <td>-0.200 – 0.000 sec</td>\n",
       "    </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<Epochs |  152 events (all good), -0.2 - 0.5 sec, baseline -0.2 – 0 sec, ~88 kB, data not loaded,\n",
       " '1': 60\n",
       " '10': 1\n",
       " '2': 40\n",
       " '4': 10\n",
       " '5': 40\n",
       " '9': 1>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochsab6_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x296 with 2 Axes>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evoked1 = epochsab6_1['10'].copy().average()\n",
    "evoked2 = epochsab6_2.copy().average()\n",
    "\n",
    "evoked1.plot(spatial_colors = True)\n",
    "# evoked2.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Evoked | '10' (average, N=1), -0.2 – 0.5 sec, baseline -0.2 – 0 sec, 63 ch, ~261 kB>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evoked1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Machine Learning Models for classification purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Softmax\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for 152 events and 351 original time points ...\n",
      "(152, 63, 351)\n",
      "Loading data for 152 events and 351 original time points ...\n",
      "0 bad epochs dropped\n",
      "(152, 63, 351)\n",
      "Loading data for 155 events and 351 original time points ...\n",
      "0 bad epochs dropped\n",
      "(155, 63, 351)\n",
      "Loading data for 153 events and 351 original time points ...\n",
      "0 bad epochs dropped\n",
      "(153, 63, 351)\n",
      "Loading data for 154 events and 351 original time points ...\n",
      "0 bad epochs dropped\n",
      "(154, 63, 351)\n",
      "Loading data for 158 events and 351 original time points ...\n",
      "0 bad epochs dropped\n",
      "(158, 63, 351)\n",
      "Loading data for 153 events and 351 original time points ...\n",
      "0 bad epochs dropped\n",
      "(153, 63, 351)\n",
      "Loading data for 156 events and 351 original time points ...\n",
      "0 bad epochs dropped\n",
      "(156, 63, 351)\n",
      "Loading data for 154 events and 351 original time points ...\n",
      "0 bad epochs dropped\n",
      "(154, 63, 351)\n",
      "Loading data for 157 events and 351 original time points ...\n",
      "0 bad epochs dropped\n",
      "(157, 63, 351)\n",
      "Loading data for 155 events and 351 original time points ...\n",
      "0 bad epochs dropped\n",
      "(155, 63, 351)\n",
      "Loading data for 159 events and 351 original time points ...\n",
      "0 bad epochs dropped\n",
      "(159, 63, 351)\n",
      "Loading data for 167 events and 351 original time points ...\n",
      "0 bad epochs dropped\n",
      "(167, 63, 351)\n",
      "Loading data for 154 events and 351 original time points ...\n",
      "0 bad epochs dropped\n",
      "(154, 63, 351)\n",
      "(2179, 63, 351)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2179, 351, 63)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs_copyab6_1 = epochsab6_1.copy()\n",
    "dataab6_1 = epochs_copyab6_1.get_data()\n",
    "print(dataab6_1.shape)\n",
    "epochs_copyab6_2 = epochsab6_2.copy()\n",
    "dataab6_2 = epochs_copyab6_2.get_data()\n",
    "print(dataab6_2.shape)\n",
    "\n",
    "epochs_copyab10_1 = epochsab10_1.copy()\n",
    "dataab10_1 = epochs_copyab10_1.get_data()\n",
    "print(dataab10_1.shape)\n",
    "epochs_copyab10_2 = epochsab10_2.copy()\n",
    "dataab10_2 = epochs_copyab10_2.get_data()\n",
    "print(dataab10_2.shape)\n",
    "\n",
    "epochs_copyab12_1 = epochsab12_1.copy()\n",
    "dataab12_1 = epochs_copyab12_1.get_data()\n",
    "print(dataab12_1.shape)\n",
    "epochs_copyab12_2 = epochsab12_2.copy()\n",
    "dataab12_2 = epochs_copyab12_2.get_data()\n",
    "print(dataab12_2.shape)\n",
    "\n",
    "epochs_copyab13_1 = epochsab13_1.copy()\n",
    "dataab13_1 = epochs_copyab13_1.get_data()\n",
    "print(dataab13_1.shape)\n",
    "epochs_copyab13_2 = epochsab13_2.copy()\n",
    "dataab13_2 = epochs_copyab13_2.get_data()\n",
    "print(dataab13_2.shape)\n",
    "\n",
    "epochs_copyab28_1 = epochsab28_1.copy()\n",
    "dataab28_1 = epochs_copyab28_1.get_data()\n",
    "print(dataab28_1.shape)\n",
    "epochs_copyab28_2 = epochsab28_2.copy()\n",
    "dataab28_2 = epochs_copyab28_2.get_data()\n",
    "print(dataab28_2.shape)\n",
    "\n",
    "epochs_copyab31_1 = epochsab31_1.copy()\n",
    "dataab31_1 = epochs_copyab31_1.get_data()\n",
    "print(dataab31_1.shape)\n",
    "epochs_copyab31_2 = epochsab31_2.copy()\n",
    "dataab31_2 = epochs_copyab31_2.get_data()\n",
    "print(dataab31_2.shape)\n",
    "\n",
    "epochs_copyab32_1 = epochsab32_1.copy()\n",
    "dataab32_1 = epochs_copyab32_1.get_data()\n",
    "print(dataab32_1.shape)\n",
    "epochs_copyab32_2 = epochsab32_2.copy()\n",
    "dataab32_2 = epochs_copyab32_2.get_data()\n",
    "print(dataab32_2.shape)\n",
    "\n",
    "\n",
    "data = np.concatenate([dataab6_1, dataab6_2,\n",
    "                      dataab10_1, dataab10_2,\n",
    "                      dataab12_1, dataab12_2,\n",
    "                      dataab13_1, dataab13_2,\n",
    "                      dataab28_1, dataab28_2,\n",
    "                      dataab31_1, dataab31_2,\n",
    "                      dataab32_1, dataab32_2], \n",
    "                      axis = 0)\n",
    "print(data.shape)\n",
    "\n",
    "#Changing the shape of data from (events, channel, time points) to (events, time points, channel)\n",
    "datars = np.zeros((data.shape[0], data.shape[2], data.shape[1]))\n",
    "for i in range(datars.shape[0]):\n",
    "    datars[i] = np.transpose(data[i])\n",
    "datars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2179, 22113)\n"
     ]
    }
   ],
   "source": [
    "n_trials = data.shape[0]\n",
    "data = data.reshape(n_trials, -1)\n",
    "print(data.shape)\n",
    "dims_ip = data.shape[1]\n",
    "# dims_ip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(152, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  979,     0,     9],\n",
       "       [ 3641,     0,     1],\n",
       "       [ 4532,     0,     2],\n",
       "       [ 4704,     0,     5],\n",
       "       [ 7453,     0,     1],\n",
       "       [ 8513,     0,     2],\n",
       "       [ 8663,     0,     5],\n",
       "       [11543,     0,     1],\n",
       "       [12343,     0,     2],\n",
       "       [12591,     0,     5]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(epochsab6_1.events.shape)\n",
    "epochsab6_1.events[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(155,)\n",
      "(115,)\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "9\n",
      "10\n",
      "11\n",
      "None\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "yab6_1 = epochsab6_1.events[:, 2]\n",
    "yab6_2 = epochsab6_2.events[:, 2]\n",
    "\n",
    "yab10_1 = epochsab10_1.events[:, 2]\n",
    "yab10_2 = epochsab10_2.events[:, 2]\n",
    "\n",
    "yab12_1 = epochsab12_1.events[:, 2]\n",
    "yab12_2 = epochsab12_2.events[:, 2]\n",
    "\n",
    "yab13_1 = epochsab13_1.events[:, 2]\n",
    "yab13_2 = epochsab13_2.events[:, 2]\n",
    "\n",
    "yab28_1 = epochsab28_1.events[:, 2]\n",
    "yab28_2 = epochsab28_2.events[:, 2]\n",
    "\n",
    "yab31_1 = epochsab31_1.events[:, 2]\n",
    "yab31_2 = epochsab31_2.events[:, 2]\n",
    "\n",
    "yab32_1 = epochsab32_1.events[:, 2]\n",
    "yab32_2 = epochsab32_2.events[:, 2]\n",
    "\n",
    "y = np.concatenate([yab6_1, yab6_2,\n",
    "                   yab10_1, yab10_2,\n",
    "                   yab12_1, yab12_2,\n",
    "                   yab13_1, yab13_2,\n",
    "                   yab28_1, yab28_2,\n",
    "                   yab31_1, yab31_2,\n",
    "                   yab32_1, yab32_2],\n",
    "                   axis = 0)\n",
    "\n",
    "def unique(list1):\n",
    "    # insert the list to the set\n",
    "    list_set = set(list1)\n",
    "    # convert the set to the list\n",
    "    unique_list = (list(list_set))\n",
    "    for x in unique_list:\n",
    "        print(x);\n",
    "        \n",
    "#6: task start\n",
    "#2: task end\n",
    "#{'1': 1(cue), '10': 2(task end), '2': 3(go), '4': 4(no-go), '5': 5(button press), '9': 6(task start)}\n",
    "#\n",
    "#\n",
    "#\n",
    "\n",
    "# print(y.shape)\n",
    "# print(unique(y))\n",
    "\n",
    "y_copy = yab10_1.copy()\n",
    "print(y_copy.shape)\n",
    "y_copy = y_copy[y_copy[:]!=6]\n",
    "y_copy = y_copy[y_copy[:]!=2]\n",
    "\n",
    "# print(unique(y_copy))\n",
    "# y_copy[:15]\n",
    "print(y_copy.shape)\n",
    "# unique(yab6_1)\n",
    "\n",
    "# num_classes = 11\n",
    "# y = tf.keras.utils.to_categorical(y, num_classes)\n",
    "# y[:5]\n",
    "# yab6_1[0]\n",
    "\n",
    "print(unique(yab10_1))\n",
    "\n",
    "\n",
    "j = 0;\n",
    "for i in range(len(yab10_1)):\n",
    "    if (yab10_1[i] == 2):\n",
    "        j = j + 1;\n",
    "print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2179, 351, 63)\n",
      "(2179, 1)\n",
      "(2179, 22114)\n"
     ]
    }
   ],
   "source": [
    "y = y.reshape(-1, 1)\n",
    "# y = y[...,np.newaxis]\n",
    "datarscopy = datars.copy()\n",
    "datarscopy = datarscopy.reshape(datars.shape[0], -1)\n",
    "\n",
    "print(datars.shape)\n",
    "print(y.shape)\n",
    "dataset = np.concatenate((datarscopy, y), axis = 1)\n",
    "print(dataset.shape)\n",
    "\n",
    "# y_copy = y.copy()\n",
    "# X_copy = data.copy()\n",
    "# X_copy = X_copy[y_copy[:]!=9]\n",
    "# X_copy = X_copy[y_copy[:]!=10]\n",
    "# X_copy = X_copy[y_copy[:]!=3]\n",
    "# X_copy = X_copy[y_copy[:]!=6]\n",
    "# X_copy = X_copy[y_copy[:]!=7]\n",
    "# X_copy = X_copy[y_copy[:]!=8]\n",
    "# X_copy = X_copy[y_copy[:]!=11]\n",
    "\n",
    "# y_copy = y.copy()\n",
    "# y_copy = y_copy[y_copy[:]!=9]\n",
    "# y_copy = y_copy[y_copy[:]!=10]\n",
    "# y_copy = y_copy[y_copy[:]!=3]\n",
    "# y_copy = y_copy[y_copy[:]!=6]\n",
    "# y_copy = y_copy[y_copy[:]!=7]\n",
    "# y_copy = y_copy[y_copy[:]!=8]\n",
    "# y_copy = y_copy[y_copy[:]!=11]\n",
    "\n",
    "\n",
    "# print(y_copy.shape)\n",
    "# print(unique(y_copy))\n",
    "# unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2179, 22113)\n",
      "(2179,)\n"
     ]
    }
   ],
   "source": [
    "x = dataset[:, :-1]\n",
    "y = dataset[:, -1]\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2179, 22114)\n",
      "(2058, 22114)\n",
      "(2058, 22113)\n",
      "(2058,)\n",
      "1.0\n",
      "2.0\n",
      "4.0\n",
      "5.0\n"
     ]
    }
   ],
   "source": [
    "datasetcopy = dataset.copy()\n",
    "print(datasetcopy.shape)\n",
    "datasetcopy = datasetcopy[datasetcopy[:, -1]!=9]\n",
    "datasetcopy = datasetcopy[datasetcopy[:, -1]!=10]\n",
    "\n",
    "datasetcopy = datasetcopy[datasetcopy[:, -1]!=3]\n",
    "datasetcopy = datasetcopy[datasetcopy[:, -1]!=6]\n",
    "datasetcopy = datasetcopy[datasetcopy[:, -1]!=7]\n",
    "datasetcopy = datasetcopy[datasetcopy[:, -1]!=8]\n",
    "datasetcopy = datasetcopy[datasetcopy[:, -1]!=11]\n",
    "\n",
    "print(datasetcopy.shape)\n",
    "\n",
    "\n",
    "xcopy = datasetcopy[:, :-1]\n",
    "ycopy = datasetcopy[:, -1]\n",
    "print(xcopy.shape)\n",
    "print(ycopy.shape)\n",
    "unique(ycopy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = 6\n",
    "ycopy = tf.keras.utils.to_categorical(ycopy, num_classes)\n",
    "ycopy[:5]\n",
    "# yab6_1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_shape = (dims_ip, )\n",
    "ip = tf.keras.Input(shape = inp_shape)\n",
    "dense1 = tf.keras.layers.Dense(units = 32, activation = 'relu', kernel_initializer = 'random_normal')(ip)\n",
    "dense2 = tf.keras.layers.Dense(units = 16, activation = 'relu', kernel_initializer = 'random_normal')(dense1)\n",
    "out = tf.keras.layers.Dense(num_classes, activation = 'softmax')(dense2)\n",
    "\n",
    "model = tf.keras.Model(inputs = ip, outputs = out)\n",
    "\n",
    "# inp_shape = (None, )\n",
    "# review_sequence = tf.keras.Input(shape = inp_shape)\n",
    "# embedding_sequence = tf.keras.layers.Embedding(input_dim=100+1, output_dim=32, input_shape=(review_sequence.shape), mask_zero=False)(review_sequence)\n",
    "# average_embedding = tf.keras.layers.GlobalAveragePooling1D()(embedding_sequence)\n",
    "# positive_probability = tf.keras.layers.Dense(units=1, activation='sigmoid')(average_embedding)\n",
    "\n",
    "# model = tf.keras.Model(inputs = review_sequence, outputs = positive_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 22113)]           0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                707648    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 6)                 102       \n",
      "=================================================================\n",
      "Total params: 708,278\n",
      "Trainable params: 708,278\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt = Adam(0.001)\n",
    "\n",
    "earlystop = EarlyStopping(patience = 50, min_delta = 0.0001, monitor = 'acc')\n",
    "\n",
    "path = 'model_checkpoint/checkpoint_{epoch:02d}';\n",
    "model_checkpoint = ModelCheckpoint(filepath = path,\n",
    "                            verbose = 1,\n",
    "                            monitor = 'acc',\n",
    "                            save_freq = 'epoch',\n",
    "                            save_best_only = True,\n",
    "                            save_weights_only = True)\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', metrics = ['accuracy'], optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1952/2058 [===========================>..] - ETA: 0s - loss: 1.6920 - acc: 0.4047\n",
      "Epoch 00001: acc improved from -inf to 0.40816, saving model to model_checkpoint/checkpoint_01\n",
      "2058/2058 [==============================] - 2s 795us/sample - loss: 1.6835 - acc: 0.4082\n",
      "Epoch 2/100\n",
      "1984/2058 [===========================>..] - ETA: 0s - loss: 1.3927 - acc: 0.4078\n",
      "Epoch 00002: acc did not improve from 0.40816\n",
      "2058/2058 [==============================] - 1s 575us/sample - loss: 1.3899 - acc: 0.4082\n",
      "Epoch 3/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 1.3016 - acc: 0.4092- ETA: 0s - loss: 1.31\n",
      "Epoch 00003: acc did not improve from 0.40816\n",
      "2058/2058 [==============================] - 1s 621us/sample - loss: 1.3013 - acc: 0.4082\n",
      "Epoch 4/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 1.2787 - acc: 0.4077\n",
      "Epoch 00004: acc did not improve from 0.40816\n",
      "2058/2058 [==============================] - 1s 674us/sample - loss: 1.2787 - acc: 0.4082\n",
      "Epoch 5/100\n",
      "1984/2058 [===========================>..] - ETA: 0s - loss: 1.2681 - acc: 0.4098\n",
      "Epoch 00005: acc did not improve from 0.40816\n",
      "2058/2058 [==============================] - 1s 608us/sample - loss: 1.2670 - acc: 0.4082\n",
      "Epoch 6/100\n",
      "1984/2058 [===========================>..] - ETA: 0s - loss: 1.2583 - acc: 0.4098\n",
      "Epoch 00006: acc did not improve from 0.40816\n",
      "2058/2058 [==============================] - 1s 532us/sample - loss: 1.2604 - acc: 0.4082\n",
      "Epoch 7/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 1.2590 - acc: 0.4072- ETA: 0s - loss: 1.2588 -\n",
      "Epoch 00007: acc did not improve from 0.40816\n",
      "2058/2058 [==============================] - 1s 541us/sample - loss: 1.2572 - acc: 0.4082\n",
      "Epoch 8/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 1.2538 - acc: 0.4092\n",
      "Epoch 00008: acc did not improve from 0.40816\n",
      "2058/2058 [==============================] - 1s 540us/sample - loss: 1.2545 - acc: 0.4082\n",
      "Epoch 9/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 1.2540 - acc: 0.4077\n",
      "Epoch 00009: acc did not improve from 0.40816\n",
      "2058/2058 [==============================] - 1s 527us/sample - loss: 1.2533 - acc: 0.4082\n",
      "Epoch 10/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 1.2512 - acc: 0.4092\n",
      "Epoch 00010: acc did not improve from 0.40816\n",
      "2058/2058 [==============================] - 1s 621us/sample - loss: 1.2519 - acc: 0.4082\n",
      "Epoch 11/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 1.2478 - acc: 0.4097\n",
      "Epoch 00011: acc did not improve from 0.40816\n",
      "2058/2058 [==============================] - 1s 602us/sample - loss: 1.2501 - acc: 0.4082\n",
      "Epoch 12/100\n",
      "1984/2058 [===========================>..] - ETA: 0s - loss: 1.2447 - acc: 0.4123\n",
      "Epoch 00012: acc did not improve from 0.40816\n",
      "2058/2058 [==============================] - 1s 559us/sample - loss: 1.2492 - acc: 0.4082\n",
      "Epoch 13/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 1.2487 - acc: 0.4067\n",
      "Epoch 00013: acc did not improve from 0.40816\n",
      "2058/2058 [==============================] - 1s 539us/sample - loss: 1.2489 - acc: 0.4082\n",
      "Epoch 14/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 1.2486 - acc: 0.4077\n",
      "Epoch 00014: acc did not improve from 0.40816\n",
      "2058/2058 [==============================] - 1s 531us/sample - loss: 1.2480 - acc: 0.4082\n",
      "Epoch 15/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 1.2475 - acc: 0.4072\n",
      "Epoch 00015: acc did not improve from 0.40816\n",
      "2058/2058 [==============================] - 1s 539us/sample - loss: 1.2473 - acc: 0.4082\n",
      "Epoch 16/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 1.2469 - acc: 0.4077\n",
      "Epoch 00016: acc did not improve from 0.40816\n",
      "2058/2058 [==============================] - 1s 533us/sample - loss: 1.2466 - acc: 0.4082\n",
      "Epoch 17/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 1.2465 - acc: 0.4077\n",
      "Epoch 00017: acc did not improve from 0.40816\n",
      "2058/2058 [==============================] - 1s 605us/sample - loss: 1.2459 - acc: 0.4082\n",
      "Epoch 18/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 1.2437 - acc: 0.4082\n",
      "Epoch 00018: acc did not improve from 0.40816\n",
      "2058/2058 [==============================] - 1s 526us/sample - loss: 1.2446 - acc: 0.4082\n",
      "Epoch 19/100\n",
      "1984/2058 [===========================>..] - ETA: 0s - loss: 1.2433 - acc: 0.4068\n",
      "Epoch 00019: acc did not improve from 0.40816\n",
      "2058/2058 [==============================] - 1s 588us/sample - loss: 1.2445 - acc: 0.4082\n",
      "Epoch 20/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 1.2438 - acc: 0.4082\n",
      "Epoch 00020: acc did not improve from 0.40816\n",
      "2058/2058 [==============================] - 1s 609us/sample - loss: 1.2434 - acc: 0.4082\n",
      "Epoch 21/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 1.2433 - acc: 0.4072\n",
      "Epoch 00021: acc did not improve from 0.40816\n",
      "2058/2058 [==============================] - 1s 585us/sample - loss: 1.2424 - acc: 0.4082\n",
      "Epoch 22/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 1.2413 - acc: 0.4072\n",
      "Epoch 00022: acc did not improve from 0.40816\n",
      "2058/2058 [==============================] - 1s 541us/sample - loss: 1.2412 - acc: 0.4082\n",
      "Epoch 23/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 1.2399 - acc: 0.4077\n",
      "Epoch 00023: acc did not improve from 0.40816\n",
      "2058/2058 [==============================] - 1s 638us/sample - loss: 1.2400 - acc: 0.4082\n",
      "Epoch 24/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 1.2388 - acc: 0.4092\n",
      "Epoch 00024: acc did not improve from 0.40816\n",
      "2058/2058 [==============================] - 1s 577us/sample - loss: 1.2388 - acc: 0.4082\n",
      "Epoch 25/100\n",
      "1952/2058 [===========================>..] - ETA: 0s - loss: 1.2363 - acc: 0.4083- ETA: 0s - loss: 1.2248 - ac\n",
      "Epoch 00025: acc did not improve from 0.40816\n",
      "2058/2058 [==============================] - 1s 583us/sample - loss: 1.2379 - acc: 0.4082\n",
      "Epoch 26/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 1.2351 - acc: 0.4107- ETA: 0s - loss: 1.2517 - a\n",
      "Epoch 00026: acc did not improve from 0.40816\n",
      "2058/2058 [==============================] - 1s 615us/sample - loss: 1.2361 - acc: 0.4082\n",
      "Epoch 27/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 1.2361 - acc: 0.4082\n",
      "Epoch 00027: acc did not improve from 0.40816\n",
      "2058/2058 [==============================] - 1s 570us/sample - loss: 1.2359 - acc: 0.4082\n",
      "Epoch 28/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 1.2325 - acc: 0.4082\n",
      "Epoch 00028: acc did not improve from 0.40816\n",
      "2058/2058 [==============================] - 1s 580us/sample - loss: 1.2323 - acc: 0.4082\n",
      "Epoch 29/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 1.2298 - acc: 0.4087\n",
      "Epoch 00029: acc did not improve from 0.40816\n",
      "2058/2058 [==============================] - 1s 521us/sample - loss: 1.2303 - acc: 0.4082\n",
      "Epoch 30/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 1.2274 - acc: 0.4102\n",
      "Epoch 00030: acc improved from 0.40816 to 0.40914, saving model to model_checkpoint/checkpoint_30\n",
      "2058/2058 [==============================] - 1s 563us/sample - loss: 1.2281 - acc: 0.4091\n",
      "Epoch 31/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 1.2255 - acc: 0.4106\n",
      "Epoch 00031: acc did not improve from 0.40914\n",
      "2058/2058 [==============================] - 1s 523us/sample - loss: 1.2258 - acc: 0.4091\n",
      "Epoch 32/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 1.2207 - acc: 0.4106\n",
      "Epoch 00032: acc improved from 0.40914 to 0.40962, saving model to model_checkpoint/checkpoint_32\n",
      "2058/2058 [==============================] - 1s 645us/sample - loss: 1.2225 - acc: 0.4096\n",
      "Epoch 33/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 1.2214 - acc: 0.4127\n",
      "Epoch 00033: acc improved from 0.40962 to 0.41205, saving model to model_checkpoint/checkpoint_33\n",
      "2058/2058 [==============================] - 2s 844us/sample - loss: 1.2203 - acc: 0.4121\n",
      "Epoch 34/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 1.2183 - acc: 0.4107\n",
      "Epoch 00034: acc improved from 0.41205 to 0.41351, saving model to model_checkpoint/checkpoint_34\n",
      "2058/2058 [==============================] - 1s 704us/sample - loss: 1.2159 - acc: 0.4135\n",
      "Epoch 35/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 1.2120 - acc: 0.4147\n",
      "Epoch 00035: acc improved from 0.41351 to 0.41497, saving model to model_checkpoint/checkpoint_35\n",
      "2058/2058 [==============================] - 2s 846us/sample - loss: 1.2120 - acc: 0.4150\n",
      "Epoch 36/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 1.2075 - acc: 0.4170\n",
      "Epoch 00036: acc improved from 0.41497 to 0.41740, saving model to model_checkpoint/checkpoint_36\n",
      "2058/2058 [==============================] - 2s 983us/sample - loss: 1.2068 - acc: 0.4174\n",
      "Epoch 37/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 1.2040 - acc: 0.4214- ETA: 0s - loss: 1.1941 - a\n",
      "Epoch 00037: acc improved from 0.41740 to 0.42323, saving model to model_checkpoint/checkpoint_37\n",
      "2058/2058 [==============================] - 1s 694us/sample - loss: 1.2025 - acc: 0.4232\n",
      "Epoch 38/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 1.1994 - acc: 0.4276\n",
      "Epoch 00038: acc improved from 0.42323 to 0.42711, saving model to model_checkpoint/checkpoint_38\n",
      "2058/2058 [==============================] - 2s 736us/sample - loss: 1.1979 - acc: 0.4271\n",
      "Epoch 39/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 1.1931 - acc: 0.4405\n",
      "Epoch 00039: acc improved from 0.42711 to 0.43926, saving model to model_checkpoint/checkpoint_39\n",
      "2058/2058 [==============================] - 2s 876us/sample - loss: 1.1928 - acc: 0.4393\n",
      "Epoch 40/100\n",
      "1984/2058 [===========================>..] - ETA: 0s - loss: 1.1859 - acc: 0.4506\n",
      "Epoch 00040: acc improved from 0.43926 to 0.45287, saving model to model_checkpoint/checkpoint_40\n",
      "2058/2058 [==============================] - 1s 545us/sample - loss: 1.1859 - acc: 0.4529\n",
      "Epoch 41/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 1.1799 - acc: 0.4499\n",
      "Epoch 00041: acc did not improve from 0.45287\n",
      "2058/2058 [==============================] - 1s 615us/sample - loss: 1.1793 - acc: 0.4504\n",
      "Epoch 42/100\n",
      "1984/2058 [===========================>..] - ETA: 0s - loss: 1.1766 - acc: 0.4682\n",
      "Epoch 00042: acc improved from 0.45287 to 0.46842, saving model to model_checkpoint/checkpoint_42\n",
      "2058/2058 [==============================] - 2s 770us/sample - loss: 1.1728 - acc: 0.4684\n",
      "Epoch 43/100\n",
      "1984/2058 [===========================>..] - ETA: 0s - loss: 1.1614 - acc: 0.4924\n",
      "Epoch 00043: acc improved from 0.46842 to 0.49125, saving model to model_checkpoint/checkpoint_43\n",
      "2058/2058 [==============================] - 2s 1ms/sample - loss: 1.1648 - acc: 0.4913\n",
      "Epoch 44/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 1.1586 - acc: 0.4980\n",
      "Epoch 00044: acc improved from 0.49125 to 0.49806, saving model to model_checkpoint/checkpoint_44\n",
      "2058/2058 [==============================] - 1s 714us/sample - loss: 1.1586 - acc: 0.4981\n",
      "Epoch 45/100\n",
      "1984/2058 [===========================>..] - ETA: 0s - loss: 1.1507 - acc: 0.5025\n",
      "Epoch 00045: acc improved from 0.49806 to 0.50534, saving model to model_checkpoint/checkpoint_45\n",
      "2058/2058 [==============================] - 1s 722us/sample - loss: 1.1492 - acc: 0.5053\n",
      "Epoch 46/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 1.1389 - acc: 0.5239\n",
      "Epoch 00046: acc improved from 0.50534 to 0.52332, saving model to model_checkpoint/checkpoint_46\n",
      "2058/2058 [==============================] - 1s 665us/sample - loss: 1.1398 - acc: 0.5233\n",
      "Epoch 47/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 1.1312 - acc: 0.5278\n",
      "Epoch 00047: acc improved from 0.52332 to 0.52770, saving model to model_checkpoint/checkpoint_47\n",
      "2058/2058 [==============================] - 2s 1ms/sample - loss: 1.1312 - acc: 0.5277\n",
      "Epoch 48/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 1.1219 - acc: 0.5466\n",
      "Epoch 00048: acc improved from 0.52770 to 0.54713, saving model to model_checkpoint/checkpoint_48\n",
      "2058/2058 [==============================] - 2s 776us/sample - loss: 1.1222 - acc: 0.5471\n",
      "Epoch 49/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 1.1130 - acc: 0.5466\n",
      "Epoch 00049: acc did not improve from 0.54713\n",
      "2058/2058 [==============================] - 1s 718us/sample - loss: 1.1135 - acc: 0.5471\n",
      "Epoch 50/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 1.1045 - acc: 0.5562\n",
      "Epoch 00050: acc improved from 0.54713 to 0.55637, saving model to model_checkpoint/checkpoint_50\n",
      "2058/2058 [==============================] - 1s 687us/sample - loss: 1.1045 - acc: 0.5564\n",
      "Epoch 51/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 1.0978 - acc: 0.5518\n",
      "Epoch 00051: acc did not improve from 0.55637\n",
      "2058/2058 [==============================] - 1s 610us/sample - loss: 1.0971 - acc: 0.5515\n",
      "Epoch 52/100\n",
      "1984/2058 [===========================>..] - ETA: 0s - loss: 1.0856 - acc: 0.5706\n",
      "Epoch 00052: acc improved from 0.55637 to 0.56754, saving model to model_checkpoint/checkpoint_52\n",
      "2058/2058 [==============================] - 2s 739us/sample - loss: 1.0882 - acc: 0.5675\n",
      "Epoch 53/100\n",
      "1984/2058 [===========================>..] - ETA: 0s - loss: 1.0825 - acc: 0.5645\n",
      "Epoch 00053: acc did not improve from 0.56754\n",
      "2058/2058 [==============================] - 1s 538us/sample - loss: 1.0826 - acc: 0.5641\n",
      "Epoch 54/100\n",
      "1984/2058 [===========================>..] - ETA: 0s - loss: 1.0708 - acc: 0.5811\n",
      "Epoch 00054: acc improved from 0.56754 to 0.57920, saving model to model_checkpoint/checkpoint_54\n",
      "2058/2058 [==============================] - 1s 691us/sample - loss: 1.0719 - acc: 0.5792\n",
      "Epoch 55/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 1.0680 - acc: 0.5749- ETA: 0s - loss: 1.0531 - ac\n",
      "Epoch 00055: acc did not improve from 0.57920\n",
      "2058/2058 [==============================] - 1s 588us/sample - loss: 1.0667 - acc: 0.5763\n",
      "Epoch 56/100\n",
      "1984/2058 [===========================>..] - ETA: 0s - loss: 1.0637 - acc: 0.5746\n",
      "Epoch 00056: acc did not improve from 0.57920\n",
      "2058/2058 [==============================] - 1s 666us/sample - loss: 1.0597 - acc: 0.5777\n",
      "Epoch 57/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 1.0564 - acc: 0.5799\n",
      "Epoch 00057: acc improved from 0.57920 to 0.58309, saving model to model_checkpoint/checkpoint_57\n",
      "2058/2058 [==============================] - 1s 700us/sample - loss: 1.0543 - acc: 0.5831\n",
      "Epoch 58/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 1.0480 - acc: 0.585 - ETA: 0s - loss: 1.0485 - acc: 0.5873\n",
      "Epoch 00058: acc improved from 0.58309 to 0.58698, saving model to model_checkpoint/checkpoint_58\n",
      "2058/2058 [==============================] - 1s 709us/sample - loss: 1.0485 - acc: 0.5870\n",
      "Epoch 59/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 1.0445 - acc: 0.5864\n",
      "Epoch 00059: acc did not improve from 0.58698\n",
      "2058/2058 [==============================] - 2s 747us/sample - loss: 1.0455 - acc: 0.5855\n",
      "Epoch 60/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 1.0368 - acc: 0.5923\n",
      "Epoch 00060: acc improved from 0.58698 to 0.59378, saving model to model_checkpoint/checkpoint_60\n",
      "2058/2058 [==============================] - 2s 730us/sample - loss: 1.0355 - acc: 0.5938\n",
      "Epoch 61/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 1.0304 - acc: 0.6021\n",
      "Epoch 00061: acc improved from 0.59378 to 0.60058, saving model to model_checkpoint/checkpoint_61\n",
      "2058/2058 [==============================] - 1s 570us/sample - loss: 1.0317 - acc: 0.6006\n",
      "Epoch 62/100\n",
      "1984/2058 [===========================>..] - ETA: 0s - loss: 1.0259 - acc: 0.5978\n",
      "Epoch 00062: acc did not improve from 0.60058\n",
      "2058/2058 [==============================] - 1s 713us/sample - loss: 1.0275 - acc: 0.5957\n",
      "Epoch 63/100\n",
      "1984/2058 [===========================>..] - ETA: 0s - loss: 1.0164 - acc: 0.6089\n",
      "Epoch 00063: acc improved from 0.60058 to 0.60496, saving model to model_checkpoint/checkpoint_63\n",
      "2058/2058 [==============================] - 2s 841us/sample - loss: 1.0221 - acc: 0.6050\n",
      "Epoch 64/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 1.0177 - acc: 0.6032\n",
      "Epoch 00064: acc did not improve from 0.60496\n",
      "2058/2058 [==============================] - 2s 743us/sample - loss: 1.0172 - acc: 0.6030\n",
      "Epoch 65/100\n",
      "1984/2058 [===========================>..] - ETA: 0s - loss: 1.0132 - acc: 0.6089\n",
      "Epoch 00065: acc improved from 0.60496 to 0.60690, saving model to model_checkpoint/checkpoint_65\n",
      "2058/2058 [==============================] - 2s 869us/sample - loss: 1.0134 - acc: 0.6069\n",
      "Epoch 66/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 1.0065 - acc: 0.6042\n",
      "Epoch 00066: acc did not improve from 0.60690\n",
      "2058/2058 [==============================] - 1s 572us/sample - loss: 1.0075 - acc: 0.6040\n",
      "Epoch 67/100\n",
      "1984/2058 [===========================>..] - ETA: 0s - loss: 1.0026 - acc: 0.6139- ETA: 0s - loss: 0.9659 - acc\n",
      "Epoch 00067: acc improved from 0.60690 to 0.61467, saving model to model_checkpoint/checkpoint_67\n",
      "2058/2058 [==============================] - 1s 587us/sample - loss: 1.0021 - acc: 0.6147\n",
      "Epoch 68/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 0.9969 - acc: 0.6052\n",
      "Epoch 00068: acc did not improve from 0.61467\n",
      "2058/2058 [==============================] - 1s 654us/sample - loss: 0.9984 - acc: 0.6035\n",
      "Epoch 69/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 0.9962 - acc: 0.6172- ETA: 0s - loss: 0.9973 - acc\n",
      "Epoch 00069: acc improved from 0.61467 to 0.61808, saving model to model_checkpoint/checkpoint_69\n",
      "2058/2058 [==============================] - 2s 810us/sample - loss: 0.9951 - acc: 0.6181\n",
      "Epoch 70/100\n",
      "1984/2058 [===========================>..] - ETA: 0s - loss: 0.9887 - acc: 0.6179\n",
      "Epoch 00070: acc did not improve from 0.61808\n",
      "2058/2058 [==============================] - 1s 588us/sample - loss: 0.9910 - acc: 0.6152\n",
      "Epoch 71/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 0.9888 - acc: 0.6196\n",
      "Epoch 00071: acc improved from 0.61808 to 0.62051, saving model to model_checkpoint/checkpoint_71\n",
      "2058/2058 [==============================] - 1s 638us/sample - loss: 0.9876 - acc: 0.6205\n",
      "Epoch 72/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 0.9826 - acc: 0.6230\n",
      "Epoch 00072: acc improved from 0.62051 to 0.62342, saving model to model_checkpoint/checkpoint_72\n",
      "2058/2058 [==============================] - 1s 696us/sample - loss: 0.9819 - acc: 0.6234\n",
      "Epoch 73/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 0.9754 - acc: 0.6250\n",
      "Epoch 00073: acc did not improve from 0.62342\n",
      "2058/2058 [==============================] - 2s 769us/sample - loss: 0.9758 - acc: 0.6234\n",
      "Epoch 74/100\n",
      "1952/2058 [===========================>..] - ETA: 0s - loss: 0.9626 - acc: 0.6368- ETA: 0s - loss: 1.0010 - \n",
      "Epoch 00074: acc improved from 0.62342 to 0.63362, saving model to model_checkpoint/checkpoint_74\n",
      "2058/2058 [==============================] - 1s 699us/sample - loss: 0.9726 - acc: 0.6336\n",
      "Epoch 75/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 0.9681 - acc: 0.6354\n",
      "Epoch 00075: acc improved from 0.63362 to 0.63557, saving model to model_checkpoint/checkpoint_75\n",
      "2058/2058 [==============================] - 1s 632us/sample - loss: 0.9675 - acc: 0.6356\n",
      "Epoch 76/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 0.9672 - acc: 0.6313- ETA: 0s - loss: 0.9672 - ac\n",
      "Epoch 00076: acc did not improve from 0.63557\n",
      "2058/2058 [==============================] - 2s 829us/sample - loss: 0.9667 - acc: 0.6312\n",
      "Epoch 77/100\n",
      "1952/2058 [===========================>..] - ETA: 0s - loss: 0.9543 - acc: 0.6368\n",
      "Epoch 00077: acc improved from 0.63557 to 0.63751, saving model to model_checkpoint/checkpoint_77\n",
      "2058/2058 [==============================] - 1s 668us/sample - loss: 0.9572 - acc: 0.6375\n",
      "Epoch 78/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 0.9518 - acc: 0.6404\n",
      "Epoch 00078: acc improved from 0.63751 to 0.63800, saving model to model_checkpoint/checkpoint_78\n",
      "2058/2058 [==============================] - 1s 686us/sample - loss: 0.9546 - acc: 0.6380\n",
      "Epoch 79/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 0.9526 - acc: 0.6387\n",
      "Epoch 00079: acc improved from 0.63800 to 0.63946, saving model to model_checkpoint/checkpoint_79\n",
      "2058/2058 [==============================] - 2s 782us/sample - loss: 0.9511 - acc: 0.6395\n",
      "Epoch 80/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 0.9428 - acc: 0.6483\n",
      "Epoch 00080: acc improved from 0.63946 to 0.64674, saving model to model_checkpoint/checkpoint_80\n",
      "2058/2058 [==============================] - 2s 806us/sample - loss: 0.9451 - acc: 0.6467\n",
      "Epoch 81/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 0.9411 - acc: 0.6389\n",
      "Epoch 00081: acc did not improve from 0.64674\n",
      "2058/2058 [==============================] - 1s 568us/sample - loss: 0.9401 - acc: 0.6399\n",
      "Epoch 82/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 0.9345 - acc: 0.6488\n",
      "Epoch 00082: acc improved from 0.64674 to 0.64869, saving model to model_checkpoint/checkpoint_82\n",
      "2058/2058 [==============================] - 1s 624us/sample - loss: 0.9348 - acc: 0.6487\n",
      "Epoch 83/100\n",
      "1984/2058 [===========================>..] - ETA: 0s - loss: 0.9340 - acc: 0.6416\n",
      "Epoch 00083: acc did not improve from 0.64869\n",
      "2058/2058 [==============================] - 1s 639us/sample - loss: 0.9316 - acc: 0.6433\n",
      "Epoch 84/100\n",
      "1984/2058 [===========================>..] - ETA: 0s - loss: 0.9293 - acc: 0.6502\n",
      "Epoch 00084: acc improved from 0.64869 to 0.65355, saving model to model_checkpoint/checkpoint_84\n",
      "2058/2058 [==============================] - 2s 751us/sample - loss: 0.9268 - acc: 0.6535\n",
      "Epoch 85/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 0.9240 - acc: 0.6519\n",
      "Epoch 00085: acc did not improve from 0.65355\n",
      "2058/2058 [==============================] - 1s 545us/sample - loss: 0.9221 - acc: 0.6531\n",
      "Epoch 86/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 0.9217 - acc: 0.6450\n",
      "Epoch 00086: acc did not improve from 0.65355\n",
      "2058/2058 [==============================] - 1s 582us/sample - loss: 0.9217 - acc: 0.6453\n",
      "Epoch 87/100\n",
      "1984/2058 [===========================>..] - ETA: 0s - loss: 0.9153 - acc: 0.6653- ETA: 0s - loss: 0.9096\n",
      "Epoch 00087: acc improved from 0.65355 to 0.66424, saving model to model_checkpoint/checkpoint_87\n",
      "2058/2058 [==============================] - 1s 726us/sample - loss: 0.9147 - acc: 0.6642\n",
      "Epoch 88/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 0.9067 - acc: 0.6627\n",
      "Epoch 00088: acc did not improve from 0.66424\n",
      "2058/2058 [==============================] - 1s 627us/sample - loss: 0.9097 - acc: 0.6608\n",
      "Epoch 89/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 0.9066 - acc: 0.6612\n",
      "Epoch 00089: acc did not improve from 0.66424\n",
      "2058/2058 [==============================] - 1s 630us/sample - loss: 0.9042 - acc: 0.6618\n",
      "Epoch 90/100\n",
      "1984/2058 [===========================>..] - ETA: 0s - loss: 0.9013 - acc: 0.6613\n",
      "Epoch 00090: acc did not improve from 0.66424\n",
      "2058/2058 [==============================] - 1s 516us/sample - loss: 0.9021 - acc: 0.6603\n",
      "Epoch 91/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 0.8993 - acc: 0.6572\n",
      "Epoch 00091: acc did not improve from 0.66424\n",
      "2058/2058 [==============================] - 1s 599us/sample - loss: 0.8961 - acc: 0.6584\n",
      "Epoch 92/100\n",
      "1984/2058 [===========================>..] - ETA: 0s - loss: 0.8913 - acc: 0.6658\n",
      "Epoch 00092: acc improved from 0.66424 to 0.66569, saving model to model_checkpoint/checkpoint_92\n",
      "2058/2058 [==============================] - 1s 598us/sample - loss: 0.8918 - acc: 0.6657\n",
      "Epoch 93/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 0.8898 - acc: 0.6617\n",
      "Epoch 00093: acc did not improve from 0.66569\n",
      "2058/2058 [==============================] - 1s 581us/sample - loss: 0.8880 - acc: 0.6623\n",
      "Epoch 94/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 0.8867 - acc: 0.6696\n",
      "Epoch 00094: acc improved from 0.66569 to 0.67007, saving model to model_checkpoint/checkpoint_94\n",
      "2058/2058 [==============================] - 1s 666us/sample - loss: 0.8831 - acc: 0.6701\n",
      "Epoch 95/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 0.8772 - acc: 0.6736\n",
      "Epoch 00095: acc improved from 0.67007 to 0.67347, saving model to model_checkpoint/checkpoint_95\n",
      "2058/2058 [==============================] - 2s 737us/sample - loss: 0.8779 - acc: 0.6735\n",
      "Epoch 96/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 0.8729 - acc: 0.6662- ETA: 0s - loss: 0.8609 - acc: \n",
      "Epoch 00096: acc did not improve from 0.67347\n",
      "2058/2058 [==============================] - 1s 714us/sample - loss: 0.8739 - acc: 0.6647\n",
      "Epoch 97/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 0.8667 - acc: 0.6699\n",
      "Epoch 00097: acc did not improve from 0.67347\n",
      "2058/2058 [==============================] - 2s 750us/sample - loss: 0.8683 - acc: 0.6691\n",
      "Epoch 98/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 0.8695 - acc: 0.6768\n",
      "Epoch 00098: acc improved from 0.67347 to 0.67687, saving model to model_checkpoint/checkpoint_98\n",
      "2058/2058 [==============================] - 1s 600us/sample - loss: 0.8685 - acc: 0.6769\n",
      "Epoch 99/100\n",
      "1984/2058 [===========================>..] - ETA: 0s - loss: 0.8596 - acc: 0.6754\n",
      "Epoch 00099: acc did not improve from 0.67687\n",
      "2058/2058 [==============================] - 1s 536us/sample - loss: 0.8629 - acc: 0.6744\n",
      "Epoch 100/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 0.8570 - acc: 0.6801\n",
      "Epoch 00100: acc improved from 0.67687 to 0.68027, saving model to model_checkpoint/checkpoint_100\n",
      "2058/2058 [==============================] - 1s 700us/sample - loss: 0.8563 - acc: 0.6803\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(xcopy, ycopy, epochs=100, callbacks = [earlystop, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['loss'])\n",
    "plt.legend(['Accuracy', 'Loss'])\n",
    "plt.title('Model History')\n",
    "plt.ylabel('Value')\n",
    "plt.xlabel('epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial accuracy is:  0.40816328\n",
      "Final accuracy is:  0.6802721\n",
      "Initial loss is:  1.6835308554568722\n",
      "Final loss is:  0.8562850130774421\n"
     ]
    }
   ],
   "source": [
    "# plt.plot(history.history['loss'])\n",
    "# plt.title('model loss')\n",
    "# plt.ylabel('loss')\n",
    "# plt.xlabel('epochs')\n",
    "# plt.show()\n",
    "print(\"Initial accuracy is: \", history.history['acc'][0])\n",
    "print(\"Final accuracy is: \", history.history['acc'][-1])\n",
    "\n",
    "print(\"Initial loss is: \", history.history['loss'][0])\n",
    "print(\"Final loss is: \", history.history['loss'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
