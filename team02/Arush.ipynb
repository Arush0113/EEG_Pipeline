{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23.0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import pathlib\n",
    "\n",
    "import mne\n",
    "print(mne.__version__)\n",
    "import mne_bids\n",
    "\n",
    "matplotlib.use('Qt5Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bids_root = pathlib.Path('data')\n",
    "\n",
    "# bids_path = mne_bids.BIDSPath(subject = 'AB6',\n",
    "#                              task = 'gonogo',\n",
    "#                              datatype = 'eeg',\n",
    "#                              root = bids_root,\n",
    "#                              run = '1')\n",
    "\n",
    "# bids_path = mne_bids.BIDSPath(subject = 'AB6',\n",
    "# #                              session = '1',\n",
    "#                              datatype = 'eeg',\n",
    "#                              run = '1',\n",
    "#                              task = 'gonogo',\n",
    "#                              root = bids_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path1 = pathlib.Path('data/sub-AB6/eeg/sub-AB6_task-gonogo_run-1_eeg.set')\n",
    "\n",
    "# raw = mne.io.read_raw_eeglab(path1)\n",
    "# raw.load_data()\n",
    "\n",
    "# events = mne.find_events(raw)\n",
    "# event_id = {\n",
    "#     'Auditory/Left': 1,\n",
    "#     'Auditory/Right': 2,\n",
    "#     'Visual/Left': 3,\n",
    "#     'Visual/Right': 4,\n",
    "#     'Smiley': 5,\n",
    "#     'Button': 32\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw = mne_bids.read_raw_bids(bids_path)\n",
    "# raw.load_data()\n",
    "# raw.data()\n",
    "# raw.filter(l_freq = 0.1, h_freq = 40)\n",
    "# events, event_id = mne.events_from_annotations(raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the data using EEGLAB module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawab6_1 = mne.io.read_raw_eeglab('data/sub-AB6/eeg/sub-AB6_task-gonogo_run-1_eeg.set', eog=(), preload=True, uint16_codec=None, verbose=None)\n",
    "rawab6_2 = mne.io.read_raw_eeglab('data/sub-AB6/eeg/sub-AB6_task-gonogo_run-2_eeg.set', eog=(), preload=True, uint16_codec=None, verbose=None)\n",
    "\n",
    "rawab10_1 = mne.io.read_raw_eeglab('data/other subjects set files/sub-AB10_eeg_sub-AB10_task-gonogo_run-1_eeg.set', eog=(), preload=True, uint16_codec=None, verbose=None)\n",
    "rawab10_2 = mne.io.read_raw_eeglab('data/other subjects set files/sub-AB10_eeg_sub-AB10_task-gonogo_run-2_eeg.set', eog=(), preload=True, uint16_codec=None, verbose=None)\n",
    "\n",
    "# rawab11_1 = mne.io.read_raw_eeglab('data/other subjects set files/sub-AB11_eeg_sub-AB11_task-gonogo_run-1_eeg.set', eog=(), preload=True, uint16_codec=None, verbose=None)\n",
    "# rawab11_2 = mne.io.read_raw_eeglab('data/other subjects set files/sub-AB11_eeg_sub-AB11_task-gonogo_run-2_eeg.set', eog=(), preload=True, uint16_codec=None, verbose=None)\n",
    "\n",
    "rawab12_1 = mne.io.read_raw_eeglab('data/other subjects set files/sub-AB12_eeg_sub-AB12_task-gonogo_run-1_eeg.set', eog=(), preload=True, uint16_codec=None, verbose=None)\n",
    "rawab12_2 = mne.io.read_raw_eeglab('data/other subjects set files/sub-AB12_eeg_sub-AB12_task-gonogo_run-2_eeg.set', eog=(), preload=True, uint16_codec=None, verbose=None)\n",
    "\n",
    "rawab13_1 = mne.io.read_raw_eeglab('data/other subjects set files/sub-AB13_eeg_sub-AB13_task-gonogo_run-1_eeg.set', eog=(), preload=True, uint16_codec=None, verbose=None)\n",
    "rawab13_2 = mne.io.read_raw_eeglab('data/other subjects set files/sub-AB13_eeg_sub-AB13_task-gonogo_run-2_eeg.set', eog=(), preload=True, uint16_codec=None, verbose=None)\n",
    "\n",
    "rawab28_1 = mne.io.read_raw_eeglab('data/other subjects set files/sub-AB28_eeg_sub-AB28_task-gonogo_run-1_eeg.set', eog=(), preload=True, uint16_codec=None, verbose=None)\n",
    "rawab28_2 = mne.io.read_raw_eeglab('data/other subjects set files/sub-AB28_eeg_sub-AB28_task-gonogo_run-2_eeg.set', eog=(), preload=True, uint16_codec=None, verbose=None)\n",
    "\n",
    "rawab31_1 = mne.io.read_raw_eeglab('data/other subjects set files/sub-AB31_eeg_sub-AB31_task-gonogo_run-1_eeg.set', eog=(), preload=True, uint16_codec=None, verbose=None)\n",
    "rawab31_2 = mne.io.read_raw_eeglab('data/other subjects set files/sub-AB31_eeg_sub-AB31_task-gonogo_run-2_eeg.set', eog=(), preload=True, uint16_codec=None, verbose=None)\n",
    "\n",
    "rawab32_1 = mne.io.read_raw_eeglab('data/other subjects set files/sub-AB32_eeg_sub-AB32_task-gonogo_run-1_eeg.set', eog=(), preload=True, uint16_codec=None, verbose=None)\n",
    "rawab32_2 = mne.io.read_raw_eeglab('data/other subjects set files/sub-AB32_eeg_sub-AB32_task-gonogo_run-2_eeg.set', eog=(), preload=True, uint16_codec=None, verbose=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MNEBrowseFigure size 1920x948 with 4 Axes>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels marked as bad: none\n",
      "Channels marked as bad: none\n",
      "Channels marked as bad: none\n",
      "Channels marked as bad: none\n"
     ]
    }
   ],
   "source": [
    "rawab6_1.plot()\n",
    "rawab10_1.plot()\n",
    "rawab12_1.plot()\n",
    "rawab13_1.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.5 - 60 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.50\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
      "- Upper passband edge: 60.00 Hz\n",
      "- Upper transition bandwidth: 15.00 Hz (-6 dB cutoff frequency: 67.50 Hz)\n",
      "- Filter length: 3301 samples (6.602 sec)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<MNEBrowseFigure size 1920x944 with 4 Axes>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels marked as bad: none\n"
     ]
    }
   ],
   "source": [
    "clean_ab12_1 = rawab12_1.copy().filter(0.5, 60)\n",
    "clean_ab12_1.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "The 64 eeg channels indices are:\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "66\n",
      "The 66 eeg channels indices are:\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65]\n"
     ]
    }
   ],
   "source": [
    "rawab13_2.info\n",
    "# rawab6_2.info\n",
    "channel_indices_ab6_1 = mne.pick_types(rawab6_1.info, eeg=True)\n",
    "channel_indices_ab13_1 = mne.pick_types(rawab13_1.info, eeg=True)\n",
    "print(len(channel_indices_ab6_1))\n",
    "print(f\"The {len(channel_indices_ab6_1)} eeg channels indices are:\\n{channel_indices_ab6_1}\")\n",
    "print(len(channel_indices_ab13_1))\n",
    "print(f\"The {len(channel_indices_ab13_1)} eeg channels indices are:\\n{channel_indices_ab13_1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eeg_indices = mne.pick_types(rawab13_1.info, meg=False, eeg=True)\n",
    "# reduced_info = mne.pick_info(rawab13_1.info, eeg_indices)\n",
    "# reduced_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the events for all Subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['1', '10', '2', '4', '5', '9']\n",
      "Used Annotations descriptions: ['1', '10', '2', '4', '5', '6', '7', '9']\n",
      "Used Annotations descriptions: ['1', '10', '11', '2', '3', '4', '5', '9']\n",
      "Used Annotations descriptions: ['1', '10', '2', '3', '4', '5', '9']\n",
      "Used Annotations descriptions: ['1', '10', '2', '4', '5', '6', '7', '9']\n",
      "Used Annotations descriptions: ['1', '10', '11', '2', '3', '4', '5', '6', '7', '9']\n",
      "Used Annotations descriptions: ['1', '10', '2', '3', '4', '5', '9']\n",
      "Used Annotations descriptions: ['1', '10', '11', '2', '4', '5', '6', '7', '9']\n",
      "Used Annotations descriptions: ['1', '10', '2', '4', '5', '6', '7', '9']\n",
      "Used Annotations descriptions: ['1', '10', '2', '3', '4', '5', '6', '7', '9']\n",
      "Used Annotations descriptions: ['1', '10', '2', '3', '4', '5', '9']\n",
      "Used Annotations descriptions: ['1', '10', '2', '3', '4', '5', '6', '7', '9']\n",
      "Used Annotations descriptions: ['1', '10', '11', '2', '3', '4', '5', '6', '7', '9']\n",
      "Used Annotations descriptions: ['1', '10', '2', '4', '5', '6', '7', '9']\n"
     ]
    }
   ],
   "source": [
    "eventsab6_1 = mne.events_from_annotations(rawab6_1)\n",
    "eventsab6_2 = mne.events_from_annotations(rawab6_2)\n",
    "\n",
    "eventsab10_1 = mne.events_from_annotations(rawab10_1)\n",
    "eventsab10_2 = mne.events_from_annotations(rawab10_2)\n",
    "\n",
    "eventsab12_1 = mne.events_from_annotations(rawab12_1)\n",
    "eventsab12_2 = mne.events_from_annotations(rawab12_2)\n",
    "\n",
    "eventsab13_1 = mne.events_from_annotations(rawab13_1)\n",
    "eventsab13_2 = mne.events_from_annotations(rawab13_2)\n",
    "\n",
    "eventsab28_1 = mne.events_from_annotations(rawab28_1)\n",
    "eventsab28_2 = mne.events_from_annotations(rawab28_2)\n",
    "\n",
    "eventsab31_1 = mne.events_from_annotations(rawab31_1)\n",
    "eventsab31_2 = mne.events_from_annotations(rawab31_2)\n",
    "\n",
    "eventsab32_1 = mne.events_from_annotations(rawab32_1)\n",
    "eventsab32_2 = mne.events_from_annotations(rawab32_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the event_id dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'taskstart': '9',\n",
       " 'cue': '1',\n",
       " 'go': '2',\n",
       " 'button press': '5',\n",
       " 'no-go': '4',\n",
       " 'task end': '10',\n",
       " 'error 1': '3',\n",
       " 'error 2': '6',\n",
       " 'error 3': '7',\n",
       " 'error 4': '8',\n",
       " 'error 5': '11'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_id = {\n",
    "    \"taskstart\" : '9',\n",
    "    \"cue\" : \"1\",\n",
    "    \"go\" : \"2\",\n",
    "    \"button press\" : \"5\",\n",
    "    \"no-go\" : \"4\",\n",
    "    \"task end\": \"10\",\n",
    "    \"error 1\" : \"3\",\n",
    "    \"error 2\" : \"6\",\n",
    "    \"error 3\" : \"7\",\n",
    "    \"error 4\" : \"8\",\n",
    "    \"error 5\" : \"11\"\n",
    "}\n",
    "event_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping unwanted channels from the various Subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "<table class=\"table table-hover\">\n",
       "    <tr>\n",
       "        <th>Measurement date</th>\n",
       "<td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Experimenter</th>\n",
       "<td>Unknown</td>\n",
       "    </tr>\n",
       "        <th>Participant</th>\n",
       "<td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Digitized points</th>\n",
       "        <td>66 points</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Good channels</th>\n",
       "        <td>0 magnetometer, 0 gradiometer,\n",
       "            and 61 EEG channels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Bad channels</th>\n",
       "        <td></td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>EOG channels</th>\n",
       "        <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>ECG channels</th>\n",
       "        <td>Not available</td>\n",
       "    <tr>\n",
       "        <th>Sampling frequency</th>\n",
       "        <td>500.00 Hz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Highpass</th>\n",
       "        <td>0.00 Hz</td>\n",
       "    </tr>\n",
       "     <tr>\n",
       "        <th>Lowpass</th>\n",
       "        <td>250.00 Hz</td>\n",
       "    </tr>\n",
       "\n",
       "    <tr>\n",
       "        <th>Filenames</th>\n",
       "        <td>sub-AB32_eeg_sub-AB32_task-gonogo_run-2_eeg.set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Duration</th>\n",
       "        <td>00:08:16 (HH:MM:SS)</td>\n",
       "    </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<RawEEGLAB | sub-AB32_eeg_sub-AB32_task-gonogo_run-2_eeg.set, 61 x 248300 (496.6 s), ~115.6 MB, data loaded>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawab6_1.drop_channels(ch_names = [\"EKG\", \"VEO\", \"HEO\"])\n",
    "rawab6_2.drop_channels(ch_names = [\"EKG\", \"VEO\", \"HEO\"])\n",
    "\n",
    "rawab10_1.drop_channels(ch_names = [\"EKG\", \"R-Dia-X-(mm)\", \"R-Dia-Y-(mm)\", \"VEO\", \"HEO\"])\n",
    "rawab10_2.drop_channels(ch_names = [\"EKG\", \"R-Dia-X-(mm)\", \"R-Dia-Y-(mm)\", \"VEO\", \"HEO\"])\n",
    "\n",
    "rawab12_1.drop_channels(ch_names = [\"EKG\", \"R-Dia-X-(mm)\", \"R-Dia-Y-(mm)\", \"VEO\", \"HEO\"])\n",
    "rawab12_2.drop_channels(ch_names = [\"EKG\", \"R-Dia-X-(mm)\", \"R-Dia-Y-(mm)\", \"VEO\", \"HEO\"])\n",
    "\n",
    "rawab13_1.drop_channels(ch_names = [\"EKG\", \"R-Dia-X-(mm)\", \"R-Dia-Y-(mm)\", \"VEO\", \"HEO\"])\n",
    "rawab13_2.drop_channels(ch_names = [\"EKG\", \"R-Dia-X-(mm)\", \"R-Dia-Y-(mm)\", \"VEO\", \"HEO\"])\n",
    "\n",
    "rawab28_1.drop_channels(ch_names = [\"EKG\", \"R-Dia-X-(mm)\", \"R-Dia-Y-(mm)\", \"VEO\", \"HEO\"])\n",
    "rawab28_2.drop_channels(ch_names = [\"EKG\", \"R-Dia-X-(mm)\", \"R-Dia-Y-(mm)\", \"VEO\", \"HEO\"])\n",
    "\n",
    "rawab31_1.drop_channels(ch_names = [\"EKG\", \"R-Dia-X-(mm)\", \"R-Dia-Y-(mm)\", \"VEO\", \"HEO\"])\n",
    "rawab31_2.drop_channels(ch_names = [\"EKG\", \"R-Dia-X-(mm)\", \"R-Dia-Y-(mm)\", \"VEO\", \"HEO\"])\n",
    "\n",
    "rawab32_1.drop_channels(ch_names = [\"EKG\", \"R-Dia-X-(mm)\", \"R-Dia-Y-(mm)\", \"VEO\", \"HEO\"])\n",
    "rawab32_2.drop_channels(ch_names = [\"EKG\", \"R-Dia-X-(mm)\", \"R-Dia-Y-(mm)\", \"VEO\", \"HEO\"])\n",
    "\n",
    "# rawab14_1.drop_channels(ch_names = [\"EKG\", \"R-Dia-X-(mm)\", \"R-Dia-Y-(mm)\"])\n",
    "# rawab14_2.drop_channels(ch_names = [\"EKG\", \"R-Dia-X-(mm)\", \"R-Dia-Y-(mm)\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting 2D and 3D positions of the 63 Sensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawab6_1.plot_sensors(ch_type = 'eeg', sphere = 10);\n",
    "# rawab6_2.plot_sensors(ch_type = 'eeg', sphere = 10);\n",
    "\n",
    "rawab10_1.plot_sensors(ch_type = 'eeg', sphere = 10);\n",
    "# rawab10_2.plot_sensors(ch_type = 'eeg', sphere = 10);\n",
    "\n",
    "rawab12_1.plot_sensors(ch_type = 'eeg', sphere = 10);\n",
    "# rawab12_2.plot_sensors(ch_type = 'eeg', sphere = 10);\n",
    "\n",
    "rawab13_1.plot_sensors(ch_type = 'eeg', sphere = 10);\n",
    "# rawab13_2.plot_sensors(ch_type = 'eeg', sphere = 10);\n",
    "\n",
    "rawab28_1.plot_sensors(ch_type = 'eeg', sphere = 10);\n",
    "# rawab28_2.plot_sensors(ch_type = 'eeg', sphere = 10);\n",
    "\n",
    "rawab31_1.plot_sensors(ch_type = 'eeg', sphere = 10);\n",
    "# rawab31_2.plot_sensors(ch_type = 'eeg', sphere = 10);\n",
    "\n",
    "rawab32_1.plot_sensors(ch_type = 'eeg', sphere = 10);\n",
    "# rawab32_2.plot_sensors(ch_type = 'eeg', sphere = 10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawab6_1.plot_sensors(ch_type = 'eeg', kind = '3d');\n",
    "# rawab6_2.plot_sensors(ch_type = 'eeg', kind = '3d');\n",
    "\n",
    "rawab10_1.plot_sensors(ch_type = 'eeg', kind = '3d');\n",
    "# rawab10_2.plot_sensors(ch_type = 'eeg', kind = '3d');\n",
    "\n",
    "rawab12_1.plot_sensors(ch_type = 'eeg', kind = '3d');\n",
    "# rawab12_2.plot_sensors(ch_type = 'eeg', kind = '3d');\n",
    "\n",
    "rawab13_1.plot_sensors(ch_type = 'eeg', kind = '3d');\n",
    "# rawab13_2.plot_sensors(ch_type = 'eeg', kind = '3d');\n",
    "\n",
    "rawab28_1.plot_sensors(ch_type = 'eeg', kind = '3d');\n",
    "# rawab28_2.plot_sensors(ch_type = 'eeg', kind = '3d');\n",
    "\n",
    "rawab31_1.plot_sensors(ch_type = 'eeg', kind = '3d');\n",
    "# rawab31_2.plot_sensors(ch_type = 'eeg', kind = '3d');\n",
    "\n",
    "rawab32_1.plot_sensors(ch_type = 'eeg', kind = '3d');\n",
    "# rawab32_2.plot_sensors(ch_type = 'eeg', kind = '3d');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rawab6_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rawab6_1.plot_sensors(ch_type = 'eeg', sphere = 10)\n",
    "# rawab6_2.plot_sensors(ch_type = 'eeg', sphere = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing ICA and SSP Projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-1497dd8d8761>:1: DeprecationWarning: Version 0.23 introduced max_iter=\"auto\", setting max_iter=1000 for `fastica` and max_iter=500 for `infomax` and `picard`. The current default of max_iter=200 will be changed to \"auto\" in version 0.24.\n",
      "  ica = mne.preprocessing.ICA(n_components = 20, random_state = 42)\n"
     ]
    }
   ],
   "source": [
    "ica = mne.preprocessing.ICA(n_components = 20, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica.exclude = [11, 14, 19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_ab6_1 = ica.apply(rawab6_1.copy().filter(1, 50), exclude = ica.exclude)\n",
    "# clean_ab6_2 = ica.apply(rawab6_2.copy().filter(1, 50), exclude = ica.exclude)\n",
    "# clean_ab6_1.plot();\n",
    "# clean_ab6_2.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-56-1497dd8d8761>:1: DeprecationWarning: Version 0.23 introduced max_iter=\"auto\", setting max_iter=1000 for `fastica` and max_iter=500 for `infomax` and `picard`. The current default of max_iter=200 will be changed to \"auto\" in version 0.24.\n",
      "  ica = mne.preprocessing.ICA(n_components = 20, random_state = 42)\n"
     ]
    }
   ],
   "source": [
    "ica = mne.preprocessing.ICA(n_components = 20, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 8 - 35 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 8.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 7.00 Hz)\n",
      "- Upper passband edge: 35.00 Hz\n",
      "- Upper transition bandwidth: 8.75 Hz (-6 dB cutoff frequency: 39.38 Hz)\n",
      "- Filter length: 825 samples (1.650 sec)\n",
      "\n",
      "Fitting ICA to data using 63 channels (please be patient, this may take a while)\n",
      "Selecting by number: 20 components\n",
      "Fitting ICA took 12.4s.\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 8 - 35 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 8.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 7.00 Hz)\n",
      "- Upper passband edge: 35.00 Hz\n",
      "- Upper transition bandwidth: 8.75 Hz (-6 dB cutoff frequency: 39.38 Hz)\n",
      "- Filter length: 825 samples (1.650 sec)\n",
      "\n",
      "Fitting ICA to data using 63 channels (please be patient, this may take a while)\n",
      "Selecting by number: 20 components\n",
      "Fitting ICA took 8.6s.\n"
     ]
    }
   ],
   "source": [
    "cleaned_ab6_1 = ica.fit(rawab6_1.copy().filter(8, 35))\n",
    "cleaned_ab6_2 = ica.fit(rawab6_2.copy().filter(8, 35))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<MNEFigure size 975x963 with 20 Axes>]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ica.plot_components(outlines = 'head', sphere = 10, ch_type = 'eeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ICA' object has no attribute 'plot'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-70f1ef83ca8c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcleaned_ab6_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mcleaned_ab6_2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ICA' object has no attribute 'plot'"
     ]
    }
   ],
   "source": [
    "cleaned_ab6_1.plot();\n",
    "cleaned_ab6_2.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MNEFigure size 750x220 with 5 Axes>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evoked2.plot_topomap(ch_type = 'eeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ecg_projs, ecg_events = mne.preprocessing.compute_proj_ecg(rawab6_1, n_grad = 1, n_mag = 1, n_eeg = 0,\n",
    "#                                                            average = True)\n",
    "# eog_projs, eog_events = mne.preprocessing.compute_proj_eog(raw, n_grad = 1, n_mag = 1, n_eeg = 0,\n",
    "#                                                            average = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Epochs of data for different Subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(ica.plot_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': 1, '10': 2, '11': 3, '2': 4, '3': 5, '4': 6, '5': 7, '9': 8}\n"
     ]
    }
   ],
   "source": [
    "print(eventsab10_1[1])\n",
    "# print(eventsab6_1[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4968,     0,     8],\n",
       "       [ 7636,     0,     1],\n",
       "       [ 8707,     0,     4],\n",
       "       [ 8892,     0,     7],\n",
       "       [11940,     0,     1],\n",
       "       [12807,     0,     4],\n",
       "       [13123,     0,     7],\n",
       "       [15497,     0,     1],\n",
       "       [16752,     0,     4],\n",
       "       [17075,     0,     7]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eventsab10_1[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "Not setting metadata\n",
      "152 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "152 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "155 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "153 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "154 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "158 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "153 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "156 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "154 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "157 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "155 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "159 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "167 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "154 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Loading data for 152 events and 351 original time points ...\n",
      "0 bad epochs dropped\n",
      "Loading data for 152 events and 351 original time points ...\n",
      "Loading data for 20 events and 351 original time points ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<MNEBrowseFigure size 1920x940 with 4 Axes>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 0 epochs: \n",
      "Channels marked as bad: none\n"
     ]
    }
   ],
   "source": [
    "epochsab6_1 = mne.Epochs(rawab6_1,\n",
    "                   events = eventsab6_1[0],\n",
    "                   event_id = eventsab6_1[1],\n",
    "                   )\n",
    "epochsab6_2 = mne.Epochs(rawab6_2,\n",
    "                   events = eventsab6_1[0],\n",
    "                   event_id = eventsab6_1[1],)\n",
    "\n",
    "epochsab10_1 = mne.Epochs(rawab10_1,\n",
    "                   events = eventsab10_1[0],\n",
    "                   event_id = eventsab10_1[1],)\n",
    "epochsab10_2 = mne.Epochs(rawab10_2,\n",
    "                   events = eventsab10_2[0],\n",
    "                   event_id = eventsab10_2[1],)\n",
    "\n",
    "epochsab12_1 = mne.Epochs(rawab12_1,\n",
    "                   events = eventsab12_1[0],\n",
    "                   event_id = eventsab12_1[1],)\n",
    "epochsab12_2 = mne.Epochs(rawab12_2,\n",
    "                   events = eventsab12_2[0],\n",
    "                   event_id = eventsab12_2[1],)\n",
    "\n",
    "epochsab13_1 = mne.Epochs(rawab13_1,\n",
    "                   events = eventsab13_1[0],\n",
    "                   event_id = eventsab13_1[1],)\n",
    "epochsab13_2 = mne.Epochs(rawab13_2,\n",
    "                   events = eventsab13_2[0],\n",
    "                   event_id = eventsab13_2[1],)\n",
    "\n",
    "epochsab28_1 = mne.Epochs(rawab28_1,\n",
    "                   events = eventsab28_1[0],\n",
    "                   event_id = eventsab28_1[1],)\n",
    "epochsab28_2 = mne.Epochs(rawab28_2,\n",
    "                   events = eventsab28_2[0],\n",
    "                   event_id = eventsab28_2[1],)\n",
    "\n",
    "epochsab31_1 = mne.Epochs(rawab31_1,\n",
    "                   events = eventsab31_1[0],\n",
    "                   event_id = eventsab31_1[1],)\n",
    "epochsab31_2 = mne.Epochs(rawab31_2,\n",
    "                   events = eventsab31_2[0],\n",
    "                   event_id = eventsab31_2[1],)\n",
    "\n",
    "epochsab32_1 = mne.Epochs(rawab32_1,\n",
    "                   events = eventsab32_1[0],\n",
    "                   event_id = eventsab32_1[1],)\n",
    "epochsab32_2 = mne.Epochs(rawab32_2,\n",
    "                   events = eventsab32_2[0],\n",
    "                   event_id = eventsab32_2[1],)\n",
    "\n",
    "epochsab6_1.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev_epochsab6_1 = epochsab6_1.events\n",
    "# ev_epochsab6_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_keys_from_value(d, val):\n",
    "#     return [k for k, v in d.items() if v == val]\n",
    "\n",
    "# def replace(dataevents2, dataevents1):\n",
    "#     len = dataevents2.shape[0];\n",
    "#     for i in range(len):\n",
    "#         dataevents2[i][2] = int(get_keys_from_value(dataevents1[1], dataevents2[i][2])[0]);\n",
    "#     return dataevents2;\n",
    "\n",
    "#Changing event indicators(ex. 6 becomes 9)\n",
    "def get_keys_from_value(d, val):\n",
    "    return [k for k, v in d.items() if v == val]\n",
    "def fix_event_ids(epochsab, eventsab):\n",
    "    for i in range(epochsab.events.shape[0]):\n",
    "        epochsab.events[i][2] = int(get_keys_from_value(eventsab[1], epochsab.events[i][2])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(epochsab6_1.shape[0]):\n",
    "#     ev_epochsab6_1[i][2] = int(get_keys_from_value(eventsab6_1[1], ev_epochsab6_1[i][2])[0])\n",
    "fix_event_ids(epochsab6_1, eventsab6_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_event_ids(epochsab10_1, eventsab10_1)\n",
    "fix_event_ids(epochsab12_1, eventsab12_1)\n",
    "fix_event_ids(epochsab13_1, eventsab13_1)\n",
    "fix_event_ids(epochsab28_1, eventsab28_1)\n",
    "fix_event_ids(epochsab31_1, eventsab31_1)\n",
    "fix_event_ids(epochsab32_1, eventsab32_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_event_ids(epochsab10_2, eventsab10_2)\n",
    "fix_event_ids(epochsab12_2, eventsab12_2)\n",
    "fix_event_ids(epochsab13_2, eventsab13_2)\n",
    "fix_event_ids(epochsab28_2, eventsab28_2)\n",
    "fix_event_ids(epochsab31_2, eventsab31_2)\n",
    "fix_event_ids(epochsab32_2, eventsab32_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2398,     0,     9],\n",
       "       [ 5066,     0,     1],\n",
       "       [ 5914,     0,     2],\n",
       "       [ 6065,     0,     5],\n",
       "       [ 8825,     0,     1],\n",
       "       [ 9622,     0,     2],\n",
       "       [ 9751,     0,     5],\n",
       "       [13972,     0,     1],\n",
       "       [17720,     0,     1],\n",
       "       [18495,     0,     2]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochsab28_2.events[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<table class=\"table table-hover\">\n",
       "    <tr>\n",
       "        <th>Number of events</th>\n",
       "        <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Events</th>\n",
       "        <td>1: 60<br>10: 40<br>2: 0<br>4: 10<br>5: 40<br>9: 0<br></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Time range</th>\n",
       "        <td>-0.200 – 0.500 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Baseline</th>\n",
       "        <td>-0.200 – 0.000 sec</td>\n",
       "    </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<Epochs |  152 events (all good), -0.2 - 0.5 sec, baseline -0.2 – 0 sec, ~86 kB, data not loaded,\n",
       " '1': 60\n",
       " '10': 40\n",
       " '2': 0\n",
       " '4': 10\n",
       " '5': 40\n",
       " '9': 0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochsab6_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<table class=\"table table-hover\">\n",
       "    <tr>\n",
       "        <th>Number of events</th>\n",
       "        <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Events</th>\n",
       "        <td>1: 60<br>10: 40<br>11: 2<br>2: 10<br>3: 40<br>4: 0<br>5: 0<br>9: 0<br></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Time range</th>\n",
       "        <td>-0.200 – 0.500 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Baseline</th>\n",
       "        <td>-0.200 – 0.000 sec</td>\n",
       "    </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<Epochs |  155 events (good & bad), -0.2 - 0.5 sec, baseline -0.2 – 0 sec, ~87 kB, data not loaded,\n",
       " '1': 60\n",
       " '10': 40\n",
       " '11': 2\n",
       " '2': 10\n",
       " '3': 40\n",
       " '4': 0\n",
       " '5': 0\n",
       " '9': 0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochsab10_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rawab6_1 = ica.apply(rawab6_1.copy().filter(1, 50), exclude = ica.exclude)\n",
    "# raw_m.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evoked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x296 with 1 Axes>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# target_ab6_1 = epochsab6_1[\"target\"].average()\n",
    "target = epochsab6_1[0].average()\n",
    "target.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<table class=\"table table-hover\">\n",
       "    <tr>\n",
       "        <th>Number of events</th>\n",
       "        <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Events</th>\n",
       "        <td>1: 60<br>10: 1<br>2: 40<br>4: 10<br>5: 40<br>9: 1<br></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Time range</th>\n",
       "        <td>-0.200 – 0.500 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Baseline</th>\n",
       "        <td>-0.200 – 0.000 sec</td>\n",
       "    </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<Epochs |  152 events (all good), -0.2 - 0.5 sec, baseline -0.2 – 0 sec, ~88 kB, data not loaded,\n",
       " '1': 60\n",
       " '10': 1\n",
       " '2': 40\n",
       " '4': 10\n",
       " '5': 40\n",
       " '9': 1>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochsab6_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x296 with 2 Axes>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evoked1 = epochsab6_1['10'].copy().average()\n",
    "evoked2 = epochsab6_2.copy().average()\n",
    "\n",
    "evoked1.plot(spatial_colors = True)\n",
    "# evoked2.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Evoked | '10' (average, N=1), -0.2 – 0.5 sec, baseline -0.2 – 0 sec, 63 ch, ~261 kB>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evoked1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Machine Learning Models for classification purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Softmax\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for 152 events and 351 original time points ...\n",
      "(152, 61, 351)\n",
      "Loading data for 152 events and 351 original time points ...\n",
      "0 bad epochs dropped\n",
      "(152, 61, 351)\n",
      "Loading data for 155 events and 351 original time points ...\n",
      "0 bad epochs dropped\n",
      "(155, 61, 351)\n",
      "Loading data for 153 events and 351 original time points ...\n",
      "0 bad epochs dropped\n",
      "(153, 61, 351)\n",
      "Loading data for 154 events and 351 original time points ...\n",
      "0 bad epochs dropped\n",
      "(154, 61, 351)\n",
      "Loading data for 158 events and 351 original time points ...\n",
      "0 bad epochs dropped\n",
      "(158, 61, 351)\n",
      "Loading data for 153 events and 351 original time points ...\n",
      "0 bad epochs dropped\n",
      "(153, 61, 351)\n",
      "Loading data for 156 events and 351 original time points ...\n",
      "0 bad epochs dropped\n",
      "(156, 61, 351)\n",
      "Loading data for 154 events and 351 original time points ...\n",
      "0 bad epochs dropped\n",
      "(154, 61, 351)\n",
      "Loading data for 157 events and 351 original time points ...\n",
      "0 bad epochs dropped\n",
      "(157, 61, 351)\n",
      "Loading data for 155 events and 351 original time points ...\n",
      "0 bad epochs dropped\n",
      "(155, 61, 351)\n",
      "Loading data for 159 events and 351 original time points ...\n",
      "0 bad epochs dropped\n",
      "(159, 61, 351)\n",
      "Loading data for 167 events and 351 original time points ...\n",
      "0 bad epochs dropped\n",
      "(167, 61, 351)\n",
      "Loading data for 154 events and 351 original time points ...\n",
      "0 bad epochs dropped\n",
      "(154, 61, 351)\n",
      "(2179, 61, 351)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2179, 351, 61)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs_copyab6_1 = epochsab6_1.copy()\n",
    "dataab6_1 = epochs_copyab6_1.get_data()\n",
    "print(dataab6_1.shape)\n",
    "epochs_copyab6_2 = epochsab6_2.copy()\n",
    "dataab6_2 = epochs_copyab6_2.get_data()\n",
    "print(dataab6_2.shape)\n",
    "\n",
    "epochs_copyab10_1 = epochsab10_1.copy()\n",
    "dataab10_1 = epochs_copyab10_1.get_data()\n",
    "print(dataab10_1.shape)\n",
    "epochs_copyab10_2 = epochsab10_2.copy()\n",
    "dataab10_2 = epochs_copyab10_2.get_data()\n",
    "print(dataab10_2.shape)\n",
    "\n",
    "epochs_copyab12_1 = epochsab12_1.copy()\n",
    "dataab12_1 = epochs_copyab12_1.get_data()\n",
    "print(dataab12_1.shape)\n",
    "epochs_copyab12_2 = epochsab12_2.copy()\n",
    "dataab12_2 = epochs_copyab12_2.get_data()\n",
    "print(dataab12_2.shape)\n",
    "\n",
    "epochs_copyab13_1 = epochsab13_1.copy()\n",
    "dataab13_1 = epochs_copyab13_1.get_data()\n",
    "print(dataab13_1.shape)\n",
    "epochs_copyab13_2 = epochsab13_2.copy()\n",
    "dataab13_2 = epochs_copyab13_2.get_data()\n",
    "print(dataab13_2.shape)\n",
    "\n",
    "epochs_copyab28_1 = epochsab28_1.copy()\n",
    "dataab28_1 = epochs_copyab28_1.get_data()\n",
    "print(dataab28_1.shape)\n",
    "epochs_copyab28_2 = epochsab28_2.copy()\n",
    "dataab28_2 = epochs_copyab28_2.get_data()\n",
    "print(dataab28_2.shape)\n",
    "\n",
    "epochs_copyab31_1 = epochsab31_1.copy()\n",
    "dataab31_1 = epochs_copyab31_1.get_data()\n",
    "print(dataab31_1.shape)\n",
    "epochs_copyab31_2 = epochsab31_2.copy()\n",
    "dataab31_2 = epochs_copyab31_2.get_data()\n",
    "print(dataab31_2.shape)\n",
    "\n",
    "epochs_copyab32_1 = epochsab32_1.copy()\n",
    "dataab32_1 = epochs_copyab32_1.get_data()\n",
    "print(dataab32_1.shape)\n",
    "epochs_copyab32_2 = epochsab32_2.copy()\n",
    "dataab32_2 = epochs_copyab32_2.get_data()\n",
    "print(dataab32_2.shape)\n",
    "\n",
    "\n",
    "data = np.concatenate([dataab6_1, dataab6_2,\n",
    "                      dataab10_1, dataab10_2,\n",
    "                      dataab12_1, dataab12_2,\n",
    "                      dataab13_1, dataab13_2,\n",
    "                      dataab28_1, dataab28_2,\n",
    "                      dataab31_1, dataab31_2,\n",
    "                      dataab32_1, dataab32_2], \n",
    "                      axis = 0)\n",
    "print(data.shape)\n",
    "\n",
    "#Changing the shape of data from (events, channel, time points) to (events, time points, channel)\n",
    "datars = np.zeros((data.shape[0], data.shape[2], data.shape[1]))\n",
    "for i in range(datars.shape[0]):\n",
    "    datars[i] = np.transpose(data[i])\n",
    "datars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2179, 21411)\n"
     ]
    }
   ],
   "source": [
    "n_trials = data.shape[0]\n",
    "data = data.reshape(n_trials, -1)\n",
    "print(data.shape)\n",
    "dims_ip = data.shape[1]\n",
    "# dims_ip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(152, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  979,     0,     9],\n",
       "       [ 3641,     0,     1],\n",
       "       [ 4532,     0,     2],\n",
       "       [ 4704,     0,     5],\n",
       "       [ 7453,     0,     1],\n",
       "       [ 8513,     0,     2],\n",
       "       [ 8663,     0,     5],\n",
       "       [11543,     0,     1],\n",
       "       [12343,     0,     2],\n",
       "       [12591,     0,     5]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(epochsab6_1.events.shape)\n",
    "epochsab6_1.events[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(155,)\n",
      "(115,)\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "9\n",
      "10\n",
      "11\n",
      "None\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "yab6_1 = epochsab6_1.events[:, 2]\n",
    "yab6_2 = epochsab6_2.events[:, 2]\n",
    "\n",
    "yab10_1 = epochsab10_1.events[:, 2]\n",
    "yab10_2 = epochsab10_2.events[:, 2]\n",
    "\n",
    "yab12_1 = epochsab12_1.events[:, 2]\n",
    "yab12_2 = epochsab12_2.events[:, 2]\n",
    "\n",
    "yab13_1 = epochsab13_1.events[:, 2]\n",
    "yab13_2 = epochsab13_2.events[:, 2]\n",
    "\n",
    "yab28_1 = epochsab28_1.events[:, 2]\n",
    "yab28_2 = epochsab28_2.events[:, 2]\n",
    "\n",
    "yab31_1 = epochsab31_1.events[:, 2]\n",
    "yab31_2 = epochsab31_2.events[:, 2]\n",
    "\n",
    "yab32_1 = epochsab32_1.events[:, 2]\n",
    "yab32_2 = epochsab32_2.events[:, 2]\n",
    "\n",
    "y = np.concatenate([yab6_1, yab6_2,\n",
    "                   yab10_1, yab10_2,\n",
    "                   yab12_1, yab12_2,\n",
    "                   yab13_1, yab13_2,\n",
    "                   yab28_1, yab28_2,\n",
    "                   yab31_1, yab31_2,\n",
    "                   yab32_1, yab32_2],\n",
    "                   axis = 0)\n",
    "\n",
    "def unique(list1):\n",
    "    # insert the list to the set\n",
    "    list_set = set(list1)\n",
    "    # convert the set to the list\n",
    "    unique_list = (list(list_set))\n",
    "    for x in unique_list:\n",
    "        print(x);\n",
    "        \n",
    "#6: task start\n",
    "#2: task end\n",
    "#{'1': 1(cue), '10': 2(task end), '2': 3(go), '4': 4(no-go), '5': 5(button press), '9': 6(task start)}\n",
    "#\n",
    "#\n",
    "#\n",
    "\n",
    "# print(y.shape)\n",
    "# print(unique(y))\n",
    "\n",
    "y_copy = yab10_1.copy()\n",
    "print(y_copy.shape)\n",
    "y_copy = y_copy[y_copy[:]!=6]\n",
    "y_copy = y_copy[y_copy[:]!=2]\n",
    "\n",
    "# print(unique(y_copy))\n",
    "# y_copy[:15]\n",
    "print(y_copy.shape)\n",
    "# unique(yab6_1)\n",
    "\n",
    "# num_classes = 11\n",
    "# y = tf.keras.utils.to_categorical(y, num_classes)\n",
    "# y[:5]\n",
    "# yab6_1[0]\n",
    "\n",
    "print(unique(yab10_1))\n",
    "\n",
    "\n",
    "j = 0;\n",
    "for i in range(len(yab10_1)):\n",
    "    if (yab10_1[i] == 2):\n",
    "        j = j + 1;\n",
    "print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2179, 351, 61)\n",
      "(2179, 1)\n",
      "(2179, 21412)\n"
     ]
    }
   ],
   "source": [
    "y = y.reshape(-1, 1)\n",
    "# y = y[...,np.newaxis]\n",
    "datarscopy = datars.copy()\n",
    "datarscopy = datarscopy.reshape(datars.shape[0], -1)\n",
    "\n",
    "print(datars.shape)\n",
    "print(y.shape)\n",
    "dataset = np.concatenate((datarscopy, y), axis = 1)\n",
    "print(dataset.shape)\n",
    "\n",
    "# y_copy = y.copy()\n",
    "# X_copy = data.copy()\n",
    "# X_copy = X_copy[y_copy[:]!=9]\n",
    "# X_copy = X_copy[y_copy[:]!=10]\n",
    "# X_copy = X_copy[y_copy[:]!=3]\n",
    "# X_copy = X_copy[y_copy[:]!=6]\n",
    "# X_copy = X_copy[y_copy[:]!=7]\n",
    "# X_copy = X_copy[y_copy[:]!=8]\n",
    "# X_copy = X_copy[y_copy[:]!=11]\n",
    "\n",
    "# y_copy = y.copy()\n",
    "# y_copy = y_copy[y_copy[:]!=9]\n",
    "# y_copy = y_copy[y_copy[:]!=10]\n",
    "# y_copy = y_copy[y_copy[:]!=3]\n",
    "# y_copy = y_copy[y_copy[:]!=6]\n",
    "# y_copy = y_copy[y_copy[:]!=7]\n",
    "# y_copy = y_copy[y_copy[:]!=8]\n",
    "# y_copy = y_copy[y_copy[:]!=11]\n",
    "\n",
    "\n",
    "# print(y_copy.shape)\n",
    "# print(unique(y_copy))\n",
    "# unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2179, 21411)\n",
      "(2179,)\n"
     ]
    }
   ],
   "source": [
    "x = dataset[:, :-1]\n",
    "y = dataset[:, -1]\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2179, 21412)\n",
      "(2058, 21412)\n",
      "(2058, 21411)\n",
      "(2058,)\n",
      "1.0\n",
      "2.0\n",
      "4.0\n",
      "5.0\n"
     ]
    }
   ],
   "source": [
    "datasetcopy = dataset.copy()\n",
    "print(datasetcopy.shape)\n",
    "datasetcopy = datasetcopy[datasetcopy[:, -1]!=9]\n",
    "datasetcopy = datasetcopy[datasetcopy[:, -1]!=10]\n",
    "\n",
    "datasetcopy = datasetcopy[datasetcopy[:, -1]!=3]\n",
    "datasetcopy = datasetcopy[datasetcopy[:, -1]!=6]\n",
    "datasetcopy = datasetcopy[datasetcopy[:, -1]!=7]\n",
    "datasetcopy = datasetcopy[datasetcopy[:, -1]!=8]\n",
    "datasetcopy = datasetcopy[datasetcopy[:, -1]!=11]\n",
    "\n",
    "print(datasetcopy.shape)\n",
    "\n",
    "xcopy = datasetcopy[:, :-1]\n",
    "ycopy = datasetcopy[:, -1]\n",
    "print(xcopy.shape)\n",
    "print(ycopy.shape)\n",
    "unique(ycopy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n"
     ]
    }
   ],
   "source": [
    "dict = {1.0: 0,2.0: 1, 4.0: 2, 5.0: 3}\n",
    "\n",
    "# ycopy = ycopy[dict[ycopy]]\n",
    "# dict[ycopy[:]]\n",
    "\n",
    "for i in range(len(ycopy)):\n",
    "    ycopy[i] = dict[ycopy[i]]\n",
    "#     print(dict[ycopy[i]])\n",
    "\n",
    "unique(ycopy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = 4\n",
    "ycopy = tf.keras.utils.to_categorical(ycopy, num_classes)\n",
    "ycopy[:5]\n",
    "# yab6_1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_shape = (dims_ip, )\n",
    "ip = tf.keras.Input(shape = inp_shape)\n",
    "dense1 = tf.keras.layers.Dense(units = 32, activation = 'relu', kernel_initializer = 'random_normal')(ip)\n",
    "dense2 = tf.keras.layers.Dense(units = 16, activation = 'relu', kernel_initializer = 'random_normal')(dense1)\n",
    "out = tf.keras.layers.Dense(num_classes, activation = 'softmax')(dense2)\n",
    "\n",
    "model = tf.keras.Model(inputs = ip, outputs = out)\n",
    "\n",
    "# inp_shape = (None, )\n",
    "# review_sequence = tf.keras.Input(shape = inp_shape)\n",
    "# embedding_sequence = tf.keras.layers.Embedding(input_dim=100+1, output_dim=32, input_shape=(review_sequence.shape), mask_zero=False)(review_sequence)\n",
    "# average_embedding = tf.keras.layers.GlobalAveragePooling1D()(embedding_sequence)\n",
    "# positive_probability = tf.keras.layers.Dense(units=1, activation='sigmoid')(average_embedding)\n",
    "\n",
    "# model = tf.keras.Model(inputs = review_sequence, outputs = positive_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 21411)]           0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                685184    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4)                 68        \n",
      "=================================================================\n",
      "Total params: 685,780\n",
      "Trainable params: 685,780\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt = Adam(0.001)\n",
    "\n",
    "earlystop = EarlyStopping(patience = 50, min_delta = 0.0001, monitor = 'acc')\n",
    "\n",
    "path = 'model_checkpoint/checkpoint_{epoch:02d}';\n",
    "model_checkpoint = ModelCheckpoint(filepath = path,\n",
    "                            verbose = 1,\n",
    "                            monitor = 'acc',\n",
    "                            save_freq = 'epoch',\n",
    "                            save_best_only = True,\n",
    "                            save_weights_only = True)\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', metrics = ['accuracy'], optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1920/2058 [==========================>...] - ETA: 0s - loss: 1.3631 - acc: 0.4052\n",
      "Epoch 00001: acc improved from -inf to 0.40622, saving model to model_checkpoint/checkpoint_01\n",
      "2058/2058 [==============================] - 2s 963us/sample - loss: 1.3605 - acc: 0.4062\n",
      "Epoch 2/100\n",
      "1952/2058 [===========================>..] - ETA: 0s - loss: 1.2920 - acc: 0.4093\n",
      "Epoch 00002: acc improved from 0.40622 to 0.40816, saving model to model_checkpoint/checkpoint_02\n",
      "2058/2058 [==============================] - 1s 675us/sample - loss: 1.2915 - acc: 0.4082\n",
      "Epoch 3/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 1.2591 - acc: 0.4062\n",
      "Epoch 00003: acc did not improve from 0.40816\n",
      "2058/2058 [==============================] - 1s 377us/sample - loss: 1.2575 - acc: 0.4082\n",
      "Epoch 4/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 1.2485 - acc: 0.4097\n",
      "Epoch 00004: acc did not improve from 0.40816\n",
      "2058/2058 [==============================] - 1s 369us/sample - loss: 1.2508 - acc: 0.4082\n",
      "Epoch 5/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 1.2488 - acc: 0.4082\n",
      "Epoch 00005: acc did not improve from 0.40816\n",
      "2058/2058 [==============================] - 1s 398us/sample - loss: 1.2496 - acc: 0.4082\n",
      "Epoch 6/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 1.2480 - acc: 0.4062\n",
      "Epoch 00006: acc did not improve from 0.40816\n",
      "2058/2058 [==============================] - 1s 424us/sample - loss: 1.2485 - acc: 0.4082\n",
      "Epoch 7/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 1.2479 - acc: 0.4092\n",
      "Epoch 00007: acc did not improve from 0.40816\n",
      "2058/2058 [==============================] - 1s 374us/sample - loss: 1.2479 - acc: 0.4082\n",
      "Epoch 8/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 1.2445 - acc: 0.4097\n",
      "Epoch 00008: acc did not improve from 0.40816\n",
      "2058/2058 [==============================] - 1s 378us/sample - loss: 1.2472 - acc: 0.4082\n",
      "Epoch 9/100\n",
      "1984/2058 [===========================>..] - ETA: 0s - loss: 1.2491 - acc: 0.4078\n",
      "Epoch 00009: acc did not improve from 0.40816\n",
      "2058/2058 [==============================] - 1s 429us/sample - loss: 1.2468 - acc: 0.4082\n",
      "Epoch 10/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 1.2482 - acc: 0.4077\n",
      "Epoch 00010: acc did not improve from 0.40816\n",
      "2058/2058 [==============================] - 1s 422us/sample - loss: 1.2461 - acc: 0.4082\n",
      "Epoch 11/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 1.2462 - acc: 0.4082\n",
      "Epoch 00011: acc did not improve from 0.40816\n",
      "2058/2058 [==============================] - 1s 381us/sample - loss: 1.2456 - acc: 0.4082\n",
      "Epoch 12/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 1.2452 - acc: 0.4077\n",
      "Epoch 00012: acc did not improve from 0.40816\n",
      "2058/2058 [==============================] - 1s 380us/sample - loss: 1.2444 - acc: 0.4082\n",
      "Epoch 13/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 1.2444 - acc: 0.4082\n",
      "Epoch 00013: acc did not improve from 0.40816\n",
      "2058/2058 [==============================] - 1s 383us/sample - loss: 1.2439 - acc: 0.4082\n",
      "Epoch 14/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 1.2421 - acc: 0.4072\n",
      "Epoch 00014: acc did not improve from 0.40816\n",
      "2058/2058 [==============================] - 1s 382us/sample - loss: 1.2431 - acc: 0.4082\n",
      "Epoch 15/100\n",
      "1952/2058 [===========================>..] - ETA: 0s - loss: 1.2383 - acc: 0.4098\n",
      "Epoch 00015: acc did not improve from 0.40816\n",
      "2058/2058 [==============================] - 1s 388us/sample - loss: 1.2419 - acc: 0.4082\n",
      "Epoch 16/100\n",
      "1952/2058 [===========================>..] - ETA: 0s - loss: 1.2413 - acc: 0.4068\n",
      "Epoch 00016: acc did not improve from 0.40816\n",
      "2058/2058 [==============================] - 1s 487us/sample - loss: 1.2403 - acc: 0.4082\n",
      "Epoch 17/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 1.2401 - acc: 0.4072\n",
      "Epoch 00017: acc did not improve from 0.40816\n",
      "2058/2058 [==============================] - 1s 451us/sample - loss: 1.2392 - acc: 0.4082\n",
      "Epoch 18/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 1.2382 - acc: 0.4082\n",
      "Epoch 00018: acc did not improve from 0.40816\n",
      "2058/2058 [==============================] - 1s 446us/sample - loss: 1.2376 - acc: 0.4082\n",
      "Epoch 19/100\n",
      "1952/2058 [===========================>..] - ETA: 0s - loss: 1.2373 - acc: 0.4109\n",
      "Epoch 00019: acc did not improve from 0.40816\n",
      "2058/2058 [==============================] - 1s 387us/sample - loss: 1.2362 - acc: 0.4082\n",
      "Epoch 20/100\n",
      "1984/2058 [===========================>..] - ETA: 0s - loss: 1.2345 - acc: 0.4062\n",
      "Epoch 00020: acc did not improve from 0.40816\n",
      "2058/2058 [==============================] - 1s 410us/sample - loss: 1.2341 - acc: 0.4082\n",
      "Epoch 21/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 1.2325 - acc: 0.4082\n",
      "Epoch 00021: acc did not improve from 0.40816\n",
      "2058/2058 [==============================] - 1s 391us/sample - loss: 1.2319 - acc: 0.4082\n",
      "Epoch 22/100\n",
      "1984/2058 [===========================>..] - ETA: 0s - loss: 1.2308 - acc: 0.4073\n",
      "Epoch 00022: acc did not improve from 0.40816\n",
      "2058/2058 [==============================] - 1s 378us/sample - loss: 1.2300 - acc: 0.4082\n",
      "Epoch 23/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 1.2256 - acc: 0.4102\n",
      "Epoch 00023: acc improved from 0.40816 to 0.40865, saving model to model_checkpoint/checkpoint_23\n",
      "2058/2058 [==============================] - 1s 650us/sample - loss: 1.2272 - acc: 0.4086\n",
      "Epoch 24/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 1.2241 - acc: 0.4092- ETA: 0s - loss: 1.2149 - ac\n",
      "Epoch 00024: acc improved from 0.40865 to 0.40914, saving model to model_checkpoint/checkpoint_24\n",
      "2058/2058 [==============================] - 1s 624us/sample - loss: 1.2243 - acc: 0.4091\n",
      "Epoch 25/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 1.2224 - acc: 0.4097\n",
      "Epoch 00025: acc did not improve from 0.40914\n",
      "2058/2058 [==============================] - 1s 488us/sample - loss: 1.2225 - acc: 0.4086\n",
      "Epoch 26/100\n",
      "1920/2058 [==========================>...] - ETA: 0s - loss: 1.2204 - acc: 0.4109\n",
      "Epoch 00026: acc improved from 0.40914 to 0.41254, saving model to model_checkpoint/checkpoint_26\n",
      "2058/2058 [==============================] - 1s 544us/sample - loss: 1.2189 - acc: 0.4125\n",
      "Epoch 27/100\n",
      "1984/2058 [===========================>..] - ETA: 0s - loss: 1.2150 - acc: 0.4194\n",
      "Epoch 00027: acc improved from 0.41254 to 0.41740, saving model to model_checkpoint/checkpoint_27\n",
      "2058/2058 [==============================] - 1s 618us/sample - loss: 1.2151 - acc: 0.4174\n",
      "Epoch 28/100\n",
      "1984/2058 [===========================>..] - ETA: 0s - loss: 1.2121 - acc: 0.4229\n",
      "Epoch 00028: acc improved from 0.41740 to 0.42177, saving model to model_checkpoint/checkpoint_28\n",
      "2058/2058 [==============================] - 1s 593us/sample - loss: 1.2125 - acc: 0.4218\n",
      "Epoch 29/100\n",
      "1952/2058 [===========================>..] - ETA: 0s - loss: 1.2111 - acc: 0.4308\n",
      "Epoch 00029: acc improved from 0.42177 to 0.43246, saving model to model_checkpoint/checkpoint_29\n",
      "2058/2058 [==============================] - 1s 574us/sample - loss: 1.2094 - acc: 0.4325\n",
      "Epoch 30/100\n",
      "1952/2058 [===========================>..] - ETA: 0s - loss: 1.2058 - acc: 0.4390\n",
      "Epoch 00030: acc improved from 0.43246 to 0.43635, saving model to model_checkpoint/checkpoint_30\n",
      "2058/2058 [==============================] - 2s 945us/sample - loss: 1.2062 - acc: 0.4363\n",
      "Epoch 31/100\n",
      "1952/2058 [===========================>..] - ETA: 0s - loss: 1.2066 - acc: 0.4406\n",
      "Epoch 00031: acc improved from 0.43635 to 0.44655, saving model to model_checkpoint/checkpoint_31\n",
      "2058/2058 [==============================] - 1s 624us/sample - loss: 1.2028 - acc: 0.4466\n",
      "Epoch 32/100\n",
      "1952/2058 [===========================>..] - ETA: 0s - loss: 1.1992 - acc: 0.4529\n",
      "Epoch 00032: acc improved from 0.44655 to 0.44995, saving model to model_checkpoint/checkpoint_32\n",
      "2058/2058 [==============================] - 1s 592us/sample - loss: 1.1999 - acc: 0.4500\n",
      "Epoch 33/100\n",
      "1952/2058 [===========================>..] - ETA: 0s - loss: 1.1946 - acc: 0.4585\n",
      "Epoch 00033: acc improved from 0.44995 to 0.45821, saving model to model_checkpoint/checkpoint_33\n",
      "2058/2058 [==============================] - 2s 907us/sample - loss: 1.1964 - acc: 0.4582\n",
      "Epoch 34/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 1.1931 - acc: 0.4554\n",
      "Epoch 00034: acc did not improve from 0.45821\n",
      "2058/2058 [==============================] - 1s 405us/sample - loss: 1.1937 - acc: 0.4558\n",
      "Epoch 35/100\n",
      "1984/2058 [===========================>..] - ETA: 0s - loss: 1.1884 - acc: 0.4667\n",
      "Epoch 00035: acc improved from 0.45821 to 0.46599, saving model to model_checkpoint/checkpoint_35\n",
      "2058/2058 [==============================] - 1s 612us/sample - loss: 1.1901 - acc: 0.4660\n",
      "Epoch 36/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 1.1887 - acc: 0.4658\n",
      "Epoch 00036: acc did not improve from 0.46599\n",
      "2058/2058 [==============================] - 1s 434us/sample - loss: 1.1877 - acc: 0.4660\n",
      "Epoch 37/100\n",
      "1984/2058 [===========================>..] - ETA: 0s - loss: 1.1832 - acc: 0.4708\n",
      "Epoch 00037: acc improved from 0.46599 to 0.46842, saving model to model_checkpoint/checkpoint_37\n",
      "2058/2058 [==============================] - 2s 1ms/sample - loss: 1.1841 - acc: 0.4684\n",
      "Epoch 38/100\n",
      "1984/2058 [===========================>..] - ETA: 0s - loss: 1.1809 - acc: 0.4698\n",
      "Epoch 00038: acc improved from 0.46842 to 0.47182, saving model to model_checkpoint/checkpoint_38\n",
      "2058/2058 [==============================] - 1s 641us/sample - loss: 1.1817 - acc: 0.4718\n",
      "Epoch 39/100\n",
      "1984/2058 [===========================>..] - ETA: 0s - loss: 1.1788 - acc: 0.4768\n",
      "Epoch 00039: acc improved from 0.47182 to 0.47716, saving model to model_checkpoint/checkpoint_39\n",
      "2058/2058 [==============================] - 1s 612us/sample - loss: 1.1785 - acc: 0.4772\n",
      "Epoch 40/100\n",
      "1920/2058 [==========================>...] - ETA: 0s - loss: 1.1805 - acc: 0.4786\n",
      "Epoch 00040: acc improved from 0.47716 to 0.47959, saving model to model_checkpoint/checkpoint_40\n",
      "2058/2058 [==============================] - 1s 629us/sample - loss: 1.1759 - acc: 0.4796\n",
      "Epoch 41/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 1.1738 - acc: 0.4868\n",
      "Epoch 00041: acc improved from 0.47959 to 0.48639, saving model to model_checkpoint/checkpoint_41\n",
      "2058/2058 [==============================] - 2s 906us/sample - loss: 1.1733 - acc: 0.4864\n",
      "Epoch 42/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 1.1683 - acc: 0.4810\n",
      "Epoch 00042: acc did not improve from 0.48639\n",
      "2058/2058 [==============================] - 1s 397us/sample - loss: 1.1693 - acc: 0.4806\n",
      "Epoch 43/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 1.1661 - acc: 0.4858\n",
      "Epoch 00043: acc did not improve from 0.48639\n",
      "2058/2058 [==============================] - 1s 365us/sample - loss: 1.1666 - acc: 0.4859\n",
      "Epoch 44/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 1.1664 - acc: 0.4940\n",
      "Epoch 00044: acc improved from 0.48639 to 0.49611, saving model to model_checkpoint/checkpoint_44\n",
      "2058/2058 [==============================] - 1s 621us/sample - loss: 1.1633 - acc: 0.4961\n",
      "Epoch 45/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 1.1592 - acc: 0.4965\n",
      "Epoch 00045: acc did not improve from 0.49611\n",
      "2058/2058 [==============================] - 1s 404us/sample - loss: 1.1594 - acc: 0.4961\n",
      "Epoch 46/100\n",
      "1984/2058 [===========================>..] - ETA: 0s - loss: 1.1535 - acc: 0.4940\n",
      "Epoch 00046: acc did not improve from 0.49611\n",
      "2058/2058 [==============================] - 1s 386us/sample - loss: 1.1562 - acc: 0.4927\n",
      "Epoch 47/100\n",
      "1984/2058 [===========================>..] - ETA: 0s - loss: 1.1516 - acc: 0.5045\n",
      "Epoch 00047: acc improved from 0.49611 to 0.50729, saving model to model_checkpoint/checkpoint_47\n",
      "2058/2058 [==============================] - 2s 915us/sample - loss: 1.1518 - acc: 0.5073\n",
      "Epoch 48/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 1.1481 - acc: 0.4995\n",
      "Epoch 00048: acc did not improve from 0.50729\n",
      "2058/2058 [==============================] - 1s 427us/sample - loss: 1.1473 - acc: 0.5000\n",
      "Epoch 49/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 1.1432 - acc: 0.5098\n",
      "Epoch 00049: acc improved from 0.50729 to 0.50875, saving model to model_checkpoint/checkpoint_49\n",
      "2058/2058 [==============================] - 1s 647us/sample - loss: 1.1433 - acc: 0.5087\n",
      "Epoch 50/100\n",
      "1920/2058 [==========================>...] - ETA: 0s - loss: 1.1414 - acc: 0.5130\n",
      "Epoch 00050: acc improved from 0.50875 to 0.51652, saving model to model_checkpoint/checkpoint_50\n",
      "2058/2058 [==============================] - 2s 941us/sample - loss: 1.1387 - acc: 0.5165\n",
      "Epoch 51/100\n",
      "1952/2058 [===========================>..] - ETA: 0s - loss: 1.1296 - acc: 0.5241\n",
      "Epoch 00051: acc improved from 0.51652 to 0.52089, saving model to model_checkpoint/checkpoint_51\n",
      "2058/2058 [==============================] - 1s 710us/sample - loss: 1.1339 - acc: 0.5209\n",
      "Epoch 52/100\n",
      "1920/2058 [==========================>...] - ETA: 0s - loss: 1.1282 - acc: 0.5255\n",
      "Epoch 00052: acc improved from 0.52089 to 0.52332, saving model to model_checkpoint/checkpoint_52\n",
      "2058/2058 [==============================] - 1s 655us/sample - loss: 1.1281 - acc: 0.5233\n",
      "Epoch 53/100\n",
      "1952/2058 [===========================>..] - ETA: 0s - loss: 1.1226 - acc: 0.5359\n",
      "Epoch 00053: acc improved from 0.52332 to 0.53984, saving model to model_checkpoint/checkpoint_53\n",
      "2058/2058 [==============================] - 2s 949us/sample - loss: 1.1219 - acc: 0.5398\n",
      "Epoch 54/100\n",
      "1952/2058 [===========================>..] - ETA: 0s - loss: 1.1134 - acc: 0.5389\n",
      "Epoch 00054: acc did not improve from 0.53984\n",
      "2058/2058 [==============================] - 1s 451us/sample - loss: 1.1163 - acc: 0.5389\n",
      "Epoch 55/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 1.1078 - acc: 0.5488\n",
      "Epoch 00055: acc improved from 0.53984 to 0.54762, saving model to model_checkpoint/checkpoint_55\n",
      "2058/2058 [==============================] - 1s 570us/sample - loss: 1.1096 - acc: 0.5476\n",
      "Epoch 56/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 1.1019 - acc: 0.5521\n",
      "Epoch 00056: acc improved from 0.54762 to 0.55151, saving model to model_checkpoint/checkpoint_56\n",
      "2058/2058 [==============================] - 1s 573us/sample - loss: 1.1030 - acc: 0.5515\n",
      "Epoch 57/100\n",
      "1952/2058 [===========================>..] - ETA: 0s - loss: 1.0933 - acc: 0.5517\n",
      "Epoch 00057: acc did not improve from 0.55151\n",
      "2058/2058 [==============================] - 1s 486us/sample - loss: 1.0957 - acc: 0.5505\n",
      "Epoch 58/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 1.0903 - acc: 0.5556\n",
      "Epoch 00058: acc improved from 0.55151 to 0.55782, saving model to model_checkpoint/checkpoint_58\n",
      "2058/2058 [==============================] - 2s 945us/sample - loss: 1.0879 - acc: 0.5578\n",
      "Epoch 59/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 1.0836 - acc: 0.5581\n",
      "Epoch 00059: acc improved from 0.55782 to 0.55831, saving model to model_checkpoint/checkpoint_59\n",
      "2058/2058 [==============================] - 5s 2ms/sample - loss: 1.0821 - acc: 0.5583\n",
      "Epoch 60/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 1.0792 - acc: 0.5660\n",
      "Epoch 00060: acc improved from 0.55831 to 0.56851, saving model to model_checkpoint/checkpoint_60\n",
      "2058/2058 [==============================] - 1s 622us/sample - loss: 1.0759 - acc: 0.5685\n",
      "Epoch 61/100\n",
      "1952/2058 [===========================>..] - ETA: 0s - loss: 1.0626 - acc: 0.5738\n",
      "Epoch 00061: acc improved from 0.56851 to 0.57240, saving model to model_checkpoint/checkpoint_61\n",
      "2058/2058 [==============================] - 2s 918us/sample - loss: 1.0662 - acc: 0.5724\n",
      "Epoch 62/100\n",
      "1984/2058 [===========================>..] - ETA: 0s - loss: 1.0600 - acc: 0.5786\n",
      "Epoch 00062: acc improved from 0.57240 to 0.58017, saving model to model_checkpoint/checkpoint_62\n",
      "2058/2058 [==============================] - 1s 670us/sample - loss: 1.0598 - acc: 0.5802\n",
      "Epoch 63/100\n",
      "1952/2058 [===========================>..] - ETA: 0s - loss: 1.0494 - acc: 0.5856\n",
      "Epoch 00063: acc improved from 0.58017 to 0.58503, saving model to model_checkpoint/checkpoint_63\n",
      "2058/2058 [==============================] - 1s 661us/sample - loss: 1.0513 - acc: 0.5850\n",
      "Epoch 64/100\n",
      "1984/2058 [===========================>..] - ETA: 0s - loss: 1.0464 - acc: 0.5857- ETA: 0s - loss: 1.0604 - acc:\n",
      "Epoch 00064: acc improved from 0.58503 to 0.58746, saving model to model_checkpoint/checkpoint_64\n",
      "2058/2058 [==============================] - 1s 639us/sample - loss: 1.0436 - acc: 0.5875\n",
      "Epoch 65/100\n",
      "1984/2058 [===========================>..] - ETA: 0s - loss: 1.0383 - acc: 0.5862\n",
      "Epoch 00065: acc improved from 0.58746 to 0.58795, saving model to model_checkpoint/checkpoint_65\n",
      "2058/2058 [==============================] - 2s 939us/sample - loss: 1.0368 - acc: 0.5879\n",
      "Epoch 66/100\n",
      "1952/2058 [===========================>..] - ETA: 0s - loss: 1.0330 - acc: 0.5922\n",
      "Epoch 00066: acc improved from 0.58795 to 0.59427, saving model to model_checkpoint/checkpoint_66\n",
      "2058/2058 [==============================] - 1s 677us/sample - loss: 1.0300 - acc: 0.5943\n",
      "Epoch 67/100\n",
      "1920/2058 [==========================>...] - ETA: 0s - loss: 1.0305 - acc: 0.6031\n",
      "Epoch 00067: acc improved from 0.59427 to 0.60301, saving model to model_checkpoint/checkpoint_67\n",
      "2058/2058 [==============================] - 1s 599us/sample - loss: 1.0232 - acc: 0.6030\n",
      "Epoch 68/100\n",
      "1952/2058 [===========================>..] - ETA: 0s - loss: 1.0141 - acc: 0.6081\n",
      "Epoch 00068: acc improved from 0.60301 to 0.60690, saving model to model_checkpoint/checkpoint_68\n",
      "2058/2058 [==============================] - 2s 983us/sample - loss: 1.0157 - acc: 0.6069\n",
      "Epoch 69/100\n",
      "1920/2058 [==========================>...] - ETA: 0s - loss: 1.0094 - acc: 0.6052\n",
      "Epoch 00069: acc did not improve from 0.60690\n",
      "2058/2058 [==============================] - 1s 459us/sample - loss: 1.0093 - acc: 0.6064\n",
      "Epoch 70/100\n",
      "1952/2058 [===========================>..] - ETA: 0s - loss: 1.0011 - acc: 0.6173\n",
      "Epoch 00070: acc improved from 0.60690 to 0.61613, saving model to model_checkpoint/checkpoint_70\n",
      "2058/2058 [==============================] - 1s 600us/sample - loss: 1.0037 - acc: 0.6161\n",
      "Epoch 71/100\n",
      "1984/2058 [===========================>..] - ETA: 0s - loss: 1.0015 - acc: 0.6124- ETA: 0s - loss: 1.0084 - acc: 0.6\n",
      "Epoch 00071: acc did not improve from 0.61613\n",
      "2058/2058 [==============================] - 1s 451us/sample - loss: 0.9978 - acc: 0.6122\n",
      "Epoch 72/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 0.9924 - acc: 0.6143\n",
      "Epoch 00072: acc did not improve from 0.61613\n",
      "2058/2058 [==============================] - 1s 387us/sample - loss: 0.9930 - acc: 0.6142\n",
      "Epoch 73/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 0.9844 - acc: 0.6274\n",
      "Epoch 00073: acc improved from 0.61613 to 0.62682, saving model to model_checkpoint/checkpoint_73\n",
      "2058/2058 [==============================] - 2s 992us/sample - loss: 0.9861 - acc: 0.6268\n",
      "Epoch 74/100\n",
      "1920/2058 [==========================>...] - ETA: 0s - loss: 0.9768 - acc: 0.6240\n",
      "Epoch 00074: acc did not improve from 0.62682\n",
      "2058/2058 [==============================] - 1s 463us/sample - loss: 0.9819 - acc: 0.6186\n",
      "Epoch 75/100\n",
      "1952/2058 [===========================>..] - ETA: 0s - loss: 0.9788 - acc: 0.6199\n",
      "Epoch 00075: acc did not improve from 0.62682\n",
      "2058/2058 [==============================] - 1s 381us/sample - loss: 0.9755 - acc: 0.6229\n",
      "Epoch 76/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 0.9681 - acc: 0.6284\n",
      "Epoch 00076: acc improved from 0.62682 to 0.62731, saving model to model_checkpoint/checkpoint_76\n",
      "2058/2058 [==============================] - 1s 615us/sample - loss: 0.9701 - acc: 0.6273\n",
      "Epoch 77/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 0.9622 - acc: 0.6324\n",
      "Epoch 00077: acc improved from 0.62731 to 0.63217, saving model to model_checkpoint/checkpoint_77\n",
      "2058/2058 [==============================] - 1s 703us/sample - loss: 0.9652 - acc: 0.6322\n",
      "Epoch 78/100\n",
      "1952/2058 [===========================>..] - ETA: 0s - loss: 0.9593 - acc: 0.6363\n",
      "Epoch 00078: acc improved from 0.63217 to 0.63751, saving model to model_checkpoint/checkpoint_78\n",
      "2058/2058 [==============================] - 2s 1ms/sample - loss: 0.9576 - acc: 0.6375\n",
      "Epoch 79/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 0.9529 - acc: 0.6424\n",
      "Epoch 00079: acc improved from 0.63751 to 0.64140, saving model to model_checkpoint/checkpoint_79\n",
      "2058/2058 [==============================] - 1s 590us/sample - loss: 0.9549 - acc: 0.6414\n",
      "Epoch 80/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 0.9509 - acc: 0.6458\n",
      "Epoch 00080: acc improved from 0.64140 to 0.64723, saving model to model_checkpoint/checkpoint_80\n",
      "2058/2058 [==============================] - 1s 631us/sample - loss: 0.9494 - acc: 0.6472\n",
      "Epoch 81/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 0.9435 - acc: 0.6436\n",
      "Epoch 00081: acc did not improve from 0.64723\n",
      "2058/2058 [==============================] - 1s 372us/sample - loss: 0.9426 - acc: 0.6443\n",
      "Epoch 82/100\n",
      "1952/2058 [===========================>..] - ETA: 0s - loss: 0.9410 - acc: 0.6481\n",
      "Epoch 00082: acc improved from 0.64723 to 0.64917, saving model to model_checkpoint/checkpoint_82\n",
      "2058/2058 [==============================] - 2s 863us/sample - loss: 0.9387 - acc: 0.6492\n",
      "Epoch 83/100\n",
      "1952/2058 [===========================>..] - ETA: 0s - loss: 0.9307 - acc: 0.6440\n",
      "Epoch 00083: acc did not improve from 0.64917\n",
      "2058/2058 [==============================] - 1s 362us/sample - loss: 0.9352 - acc: 0.6448\n",
      "Epoch 84/100\n",
      "1952/2058 [===========================>..] - ETA: 0s - loss: 0.9357 - acc: 0.6491\n",
      "Epoch 00084: acc improved from 0.64917 to 0.65306, saving model to model_checkpoint/checkpoint_84\n",
      "2058/2058 [==============================] - 1s 599us/sample - loss: 0.9277 - acc: 0.6531\n",
      "Epoch 85/100\n",
      "1920/2058 [==========================>...] - ETA: 0s - loss: 0.9182 - acc: 0.6568\n",
      "Epoch 00085: acc improved from 0.65306 to 0.65549, saving model to model_checkpoint/checkpoint_85\n",
      "2058/2058 [==============================] - 1s 574us/sample - loss: 0.9243 - acc: 0.6555\n",
      "Epoch 86/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 0.9210 - acc: 0.6577\n",
      "Epoch 00086: acc improved from 0.65549 to 0.65743, saving model to model_checkpoint/checkpoint_86\n",
      "2058/2058 [==============================] - 2s 953us/sample - loss: 0.9205 - acc: 0.6574\n",
      "Epoch 87/100\n",
      "1984/2058 [===========================>..] - ETA: 0s - loss: 0.9154 - acc: 0.6618\n",
      "Epoch 00087: acc improved from 0.65743 to 0.66132, saving model to model_checkpoint/checkpoint_87\n",
      "2058/2058 [==============================] - 2s 770us/sample - loss: 0.9152 - acc: 0.6613\n",
      "Epoch 88/100\n",
      "1984/2058 [===========================>..] - ETA: 0s - loss: 0.9097 - acc: 0.6598\n",
      "Epoch 00088: acc did not improve from 0.66132\n",
      "2058/2058 [==============================] - 1s 412us/sample - loss: 0.9108 - acc: 0.6589\n",
      "Epoch 89/100\n",
      "2048/2058 [============================>.] - ETA: 0s - loss: 0.9063 - acc: 0.6626\n",
      "Epoch 00089: acc did not improve from 0.66132\n",
      "2058/2058 [==============================] - 1s 384us/sample - loss: 0.9081 - acc: 0.6613\n",
      "Epoch 90/100\n",
      "1920/2058 [==========================>...] - ETA: 0s - loss: 0.9118 - acc: 0.6594\n",
      "Epoch 00090: acc improved from 0.66132 to 0.66375, saving model to model_checkpoint/checkpoint_90\n",
      "2058/2058 [==============================] - 2s 853us/sample - loss: 0.9030 - acc: 0.6638\n",
      "Epoch 91/100\n",
      "1952/2058 [===========================>..] - ETA: 0s - loss: 0.9005 - acc: 0.6609\n",
      "Epoch 00091: acc did not improve from 0.66375\n",
      "2058/2058 [==============================] - 1s 336us/sample - loss: 0.8989 - acc: 0.6613\n",
      "Epoch 92/100\n",
      "1952/2058 [===========================>..] - ETA: 0s - loss: 0.8946 - acc: 0.6701\n",
      "Epoch 00092: acc improved from 0.66375 to 0.66861, saving model to model_checkpoint/checkpoint_92\n",
      "2058/2058 [==============================] - 1s 596us/sample - loss: 0.8940 - acc: 0.6686\n",
      "Epoch 93/100\n",
      "1984/2058 [===========================>..] - ETA: 0s - loss: 0.8934 - acc: 0.6653\n",
      "Epoch 00093: acc did not improve from 0.66861\n",
      "2058/2058 [==============================] - 1s 377us/sample - loss: 0.8892 - acc: 0.6662\n",
      "Epoch 94/100\n",
      "1984/2058 [===========================>..] - ETA: 0s - loss: 0.8885 - acc: 0.6744\n",
      "Epoch 00094: acc improved from 0.66861 to 0.67541, saving model to model_checkpoint/checkpoint_94\n",
      "2058/2058 [==============================] - 2s 917us/sample - loss: 0.8852 - acc: 0.6754\n",
      "Epoch 95/100\n",
      "1952/2058 [===========================>..] - ETA: 0s - loss: 0.8799 - acc: 0.6726\n",
      "Epoch 00095: acc did not improve from 0.67541\n",
      "2058/2058 [==============================] - 1s 350us/sample - loss: 0.8800 - acc: 0.6735\n",
      "Epoch 96/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 0.8751 - acc: 0.6766\n",
      "Epoch 00096: acc did not improve from 0.67541\n",
      "2058/2058 [==============================] - 1s 372us/sample - loss: 0.8774 - acc: 0.6754\n",
      "Epoch 97/100\n",
      "1952/2058 [===========================>..] - ETA: 0s - loss: 0.8775 - acc: 0.6757\n",
      "Epoch 00097: acc improved from 0.67541 to 0.67784, saving model to model_checkpoint/checkpoint_97\n",
      "2058/2058 [==============================] - 1s 621us/sample - loss: 0.8741 - acc: 0.6778\n",
      "Epoch 98/100\n",
      "2016/2058 [============================>.] - ETA: 0s - loss: 0.8713 - acc: 0.6751\n",
      "Epoch 00098: acc did not improve from 0.67784\n",
      "2058/2058 [==============================] - 1s 339us/sample - loss: 0.8697 - acc: 0.6740\n",
      "Epoch 99/100\n",
      "1984/2058 [===========================>..] - ETA: 0s - loss: 0.8641 - acc: 0.6789\n",
      "Epoch 00099: acc did not improve from 0.67784\n",
      "2058/2058 [==============================] - 1s 340us/sample - loss: 0.8648 - acc: 0.6774\n",
      "Epoch 100/100\n",
      "1984/2058 [===========================>..] - ETA: 0s - loss: 0.8684 - acc: 0.6744\n",
      "Epoch 00100: acc did not improve from 0.67784\n",
      "2058/2058 [==============================] - 1s 385us/sample - loss: 0.8639 - acc: 0.6759\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(xcopy, ycopy, epochs=100, callbacks = [earlystop, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3dd3yV5dnA8d+VnRASyAQSIEDYI4CRIQgqWtG6qK17r7fDona82re2tdS3b3crraMOxFVcVWodWMWNIEtACCNhJkAGCYQMMs/1/nGfYIQkBMjJSXKu7+fzfJLzPM8557o5eq7cW1QVY4wxgSvI3wEYY4zxL0sExhgT4CwRGGNMgLNEYIwxAc4SgTHGBDhLBMYYE+AsEZiAJiJpIqIiEtKKe28QkU9O4r36iUi5iASf6GsY4wuWCEynISI7RKRGRBKOOL/G+2We5p/Imk8oIjJfRO4HUNVdqhqtqvXHeK2TSjjGHC9LBKaz2Q5c2fBAREYDkf4Lp+NpTe3GmMYsEZjO5hngukaPrweebnyDiMSKyNMiUiQiO0XkXhEJ8l4LFpE/iMg+EdkGfL2J5z4hIntFZLeI3N9WTTlH1hq8f/lvE5EyEdkuIleLyHDgEWCytxnpQCvKdIOILBGRP4tICfArESnxJsmG904SkUMiktgWZTFdiyUC09ksA2JEZLj3C/py4Nkj7vkrEAsMBKbjEseN3mu3AhcA44BM4JtHPPcpoA5I997zNeCWti6EiHQD5gLnqWp34DRgjapuBL4NLPU2I/VoRZkAJgLbgCRgDvA8cE2j61cC76pqUVuXxXR+lghMZ9RQKzgH2ATsbrjQKDn8RFXLVHUH8EfgWu8tlwF/UdVcVS0B/q/Rc5OB84A7VbVCVQuBPwNXHEds+0TkQMMBXNXCvR5glIhEqupeVd3Q1E2tKBPAHlX9q6rWqeohXEK7qqHW4L33meMohwkg1pZoOqNngI+AARzRLAQkAGHAzkbndgIp3t/7ALlHXGvQHwgF9opIw7mgI+4/lgRVrWt4ICLzm7pJVStE5HLgR8ATIrIE+KGqbmrqNWm5TBwZo6p+JiIVwHQR2Yur4bx2HOUwAcRqBKbTUdWduE7j84FXjri8D6jFfak36MeXtYa9QN8jrjXIBapxX+Y9vEeMqo5sy/gbqOrbqnoO0BtXs3ms4dIRtx6rTE09B1yt4BpcbeBlVa1qi7hN12OJwHRWNwNnqWpF45PeoZkvAv8rIt1FpD/wA77sR3gRmC0iqSLSE7in0XP3Av8B/igiMSISJCKDRGR6WwcvIskicpG3r6AaKAcahpUWAKkiEtbKMjXnGWAWLhkcWXMy5jBLBKZTUtWtqrqymcvfBypwnaefAP8A5nmvPQa8DawFVnN0jeI6XDNMFrAfeBn3F3tbCwJ+COwBSnAdwN/1XnsP2ADki8g+77mWytQkVc3DlVGBj9s4ftOFiG1MY0zXJSLzcB3J9/o7FtNxWWexMV2Ud6b1N3DDYI1pljUNGdMFicivgPXA71V1u7/jMR2bNQ0ZY0yA81mNQETmiUihiKw/xn2niki9iBw5w9MYY0w78FmNQESm4YbEPa2qo5q5Jxh4B6gC5qnqy8d63YSEBE1LS2vLUI0xpstbtWrVPlVtcq0pn3UWq+pHrVgW+PvAP4FTW/u6aWlprFzZ3KhBY4wxTRGRnc1d81tnsYik4Ca7PNKKe28TkZUisrKoyNbMMsaYtuTPUUN/Ae4+1iYdAKr6qKpmqmpmYqKtomuMMW3Jn/MIMoHnvYt7JQDni0idqi70Y0zGGBNw/JYIVHVAw+/eFRpftyRgTGCrra0lLy+PqipbH+9ERUREkJqaSmhoaKuf47NEICILgDOABBHJA36BW+IXVT1mv4AxJvDk5eXRvXt30tLSaLQUuGklVaW4uJi8vDwGDBhw7Cd4+XLU0JXHvuvwvTf4Kg5jTOdRVVVlSeAkiAjx8fEc76AaW2LCGNOhWBI4OSfy7xc4iaAgC97+KdRUHPteY4wJIIGTCA7sgqV/g71r/R2JMaaDe/XVVxERNm1qaufQridwEkFqpvuZZ7OSjTEtW7BgAVOnTuX555/32XvU1x9zClW7CZxE0C0BevSH3ZYIjDHNKy8vZ8mSJTzxxBNfSQS/+93vGD16NBkZGdxzj9vhNCcnh7PPPpuMjAzGjx/P1q1b+eCDD7jgggsOP+/2229n/vz5gFsiZ86cOUydOpWXXnqJxx57jFNPPZWMjAwuvfRSKisrASgoKGDWrFlkZGSQkZHBp59+ys9+9jMeeOCBw6/705/+lLlz57ZJmQNrY5rUTNi1zN9RGGNa4Zf/3kDWnoNt+poj+sTwiwtHtnjPwoULmTlzJkOGDCEuLo7Vq1dTUFDAwoUL+eyzz4iKiqKkpASAq6++mnvuuYdZs2ZRVVWFx+MhNze3xdePiIjgk08+AaC4uJhbb70VgHvvvZcnnniC73//+8yePZvp06fz6quvUl9fT3l5OX369OEb3/gGd9xxBx6Ph+eff57ly5e3wb9KoCWClExY/084uBdifLENrTGms1uwYAF33nknAFdccQULFizA4/Fw4403EhUVBUBcXBxlZWXs3r2bWbNmAe4LvjUuv/zyw7+vX7+ee++9lwMHDlBeXs65554LwHvvvcfTTz8NQHBwMLGxscTGxhIfH8/nn39OQUEB48aNIz4+vk3KHFiJoKGfYPdKiLnQv7EYY1p0rL/cfaG4uJj33nuP9evXIyLU19cjIlx66aVHDctsbgn/kJAQPB7P4cdHzpLu1q3b4d9vuOEGFi5cSEZGBvPnz+eDDz5oMb5bbrmF+fPnk5+fz0033XScpWte4PQRAPQaA0Gh1mFsjGnSyy+/zHXXXcfOnTvZsWMHubm5DBgwgLi4OObNm3e4Db+kpISYmBhSU1NZuNCtjFNdXU1lZSX9+/cnKyuL6upqSktLWbx4cbPvV1ZWRu/evamtreW55547fH7GjBk8/PDDgOtUPnjQNZHNmjWLRYsWsWLFisO1h7YQWIkgNAJ6jYLdq/wdiTGmA1qwYMHhpp4Gl156KXv27OGiiy4iMzOTsWPH8oc//AGAZ555hrlz5zJmzBhOO+008vPz6du3L5dddhljxozh6quvZty4cc2+369+9SsmTpzIOeecw7Bhww6ff+CBB3j//fcZPXo0p5xyChs2bAAgLCyMM888k8suu4zg4OA2K3en27M4MzNTT2pjmjd+BGsXwD27IKjt/iGNMSdv48aNDB8+3N9hdFgej4fx48fz0ksvMXjw4Gbva+rfUURWqWpmU/cHVo0AXD9BTTkUBcZEEWNM15CVlUV6ejozZsxoMQmciMDqLAY3cghcP0Fy+3dGGWPMiRgxYgTbtm3zyWsHXo0gfhBE9LCJZcYY4xV4iUAEUk6BPOswNsYYCMREAK6foDALqsv8HYkxxvhdgCaCCYDC9o/8HYkxxvhdYCaCgdOhex9Y/qi/IzHGdDDR0dH+DqHdBWYiCA6FCbfAtg/chjXGGBPAAjMRAJxyI4REwGcP+zsSY0wHt3PnTmbMmMGYMWOYMWMGu3btAuCll15i1KhRZGRkMG3aNAA2bNjAhAkTGDt2LGPGjCE7O9ufobdK4M0jaBAVBxlXwNrnYcZ90K1tVvEzxrSRt+6B/C/a9jV7jYbzfnPcT7v99tu57rrruP7665k3bx6zZ89m4cKFzJkzh7fffpuUlBQOHDgAwCOPPMIdd9zB1VdfTU1NTYfagKY5gVsjAJj4bairglVP+jsSY0wHtnTpUq666ioArr322sP7CUyZMoUbbriBxx577PAX/uTJk/n1r3/Nb3/7W3bu3ElkZKTf4m6twK0RACQNh4FnworHYcodru/AGNMxnMBf7u2lYUnqRx55hM8++4w33niDsWPHsmbNGq666iomTpzIG2+8wbnnnsvjjz/OWWed5eeIWxbYNQKAyd+Dsr3w9+mw5h9QV+PviIwxHcxpp512eNvK5557jqlTpwKwdetWJk6cyJw5c0hISCA3N5dt27YxcOBAZs+ezUUXXcS6dev8GXqrBHaNACD9bJj1KHzyZ1j4HXj3PkgeBVHxjY6e7mdYdwiNdEdYN+8R7R4HhUKQ5VVjOrvKykpSU1MPP/7BD37A3Llzuemmm/j9739PYmIiTz7pmpN//OMfk52djaoyY8YMMjIy+M1vfsOzzz5LaGgovXr14uc//7m/itJqgbcMdXNUYetiWP00lOZBZTFUlkD1ceyZGhTqTRLREB4NoVHucUiEe9yQWCJ7unMhEe56eIy7Hh4D3RLcPdZMZQKQLUPdNo53GWqrETQQcbWD9LO/er6uBg7td4mhpgJqK91RU+E9yqH2ENTXQn21+726HGrKoKbSdUbXVEBZPlR+5l5HWzGKIKIHdO8N3Xu5n90a1VCie7nzMX0gMs5qIsaYk2KJ4FhCwqB7sjvagsfjkkddNdQd+jJxVB+EqlKo3AcVxVBR6JJH2V7YtwUq9rlEc6SgEIhOdomhRz+IGwhxg9zP+EHQLdElOWOMaYYlgvYWFAQRMcf/PFVXE6nYB+UFLkGU5Tc69sLetZD12ldrHGHdIS4NenqPhCFuLHXicLd1pzEdjKoetVG8ab0Tae63RNBZiHzZQd2zf/P31dfCgV1Qsg2Kt0LJVti/A4o2w5b/fFmrkGBIHAa9x0DvDEga4WoUsanWP2H8JiIiguLiYuLj4y0ZnABVpbi4mIiI4/sjzzqLA4nHAwd2uNmae9dB/jpXiygv+PIeCYIe/aHfZOh/mjviBlrzkmkXtbW15OXlUVVV5e9QOq2IiAhSU1MJDf3qH3QtdRZbIjCuaaloM5TmutpEwQbYtdR1bAPEpMKAaZA2xQ2tTRzqRjsZYzoNv4waEpF5wAVAoaqOauL61cDd3oflwHdUda2v4jEt6O4dhdSYquuk3vExbP8YtiyCtf/wXhRXS0gZ73Z7SzkFeo2xPgdjOimf1QhEZBruC/7pZhLBacBGVd0vIucB96nqxGO9rtUI/MTjgeIct7Nb0SbXvLR7NZTtcdeDQlxtITUT+k6EvhNcE5M1KRnTIfilRqCqH4lIWgvXP230cBmQ2ty9pgMICoLEIe5o7OAe2L3KHXkr3WquKx5316J7QZ9x0Ges65BOPdVNmDPGdCgdZdTQzcBbzV0UkduA2wD69evXXjGZ1ojp447hF7rHnnpXa9i1DHKXu87oLYsAb80zPh36TYI+490w1qQRbla1McZvfNpZ7K0RvN5U01Cje84EHgKmqmrxsV7TmoY6oepy15SU+5k3QSxzs7UBELcKbMMIpZRTILafzZY2po112CUmRGQM8DhwXmuSgOmkwqOh/2R3gOuILs2F/PVfJojGTUohkZAw2HVA95/shrLaEFZjfMZviUBE+gGvANeq6hZ/xWH8QMRNXuvRD4ad787V10H+WpcYira4DunNb8KaZ931yDg3AS5xCCSNdJ3SvUbb5Ddj2oAvh48uAM4AEkQkD/gFEAqgqo8APwfigYe8Mwjrmqu2mAAQHPLlUNQGHo8bwrpzietr2LcFsv4Fq+a76yERrtaQPNIdSSNcM1NUnF+KYExnZRPKTOei6pYJz1vhRint+RwKN7gF+xp0S3KJYcA0GHSWSxbW52ACnM0sNl2bqhvGWrgRijZC4aYvEwS4ZqXeY9w8h+RRrtYRn27JwQSUDttZbEybEIHYFHcMbrSfRFkBbPsAdnzkOqZXPO72hwC330PqqZA2FQZO99Yagv0SvjH+ZjUCEzg89bAv29ustMKNVira5K5F9oTUCa4TOuUUNzva5jeYLsRqBMaA+4s/aZg7xl/rzpXlw/aPYNuHLjlkv+3OB4dB2ukwZCYMnelGOBnTRVmNwJjGqkpdJ3TOYpcUinPc+eTRbqjr4HPdkhnWjGQ6GessNuZE7ctx8xk2v+VmRKvH9S8MnO72tx4yE6KT/B2lMcdkicCYtlBRDNveh63vu58HdwPiOp2Hfd2ttxQ/yN9RGtMkSwTGtDVVNwt685uw6Q232xu44akjL4GMq9woJmM6CEsExvja/p2w6XXIes01IUkQpJ8Dp1zv+hWCbVyG8S9LBMa0p5Jt8Pmz8PlzUJ7vtvrMvAHGX2/9CcZvLBEY4w/1dbDlLVj+GGz/0O3iNmQmjLvG1RaslmDakc0jMMYfgkNcB/LwC92KqqufgnUvuCak6GSYcCtk3myL5Bm/sxqBMe2pvhay33HLXWxdDKFRroYw6TtuzwVjfMRqBMZ0FMGhbmLasPOhYAMsfRBWPumaj4aeD5O/53Zqs014TDuy5ReN8ZfkkXDJQ3DXepj2I9i1FOafD/POhex33RBVY9qBJQJj/K17LzjrXrhrA5z/ByjdDc9dCo+dBTmWEIzvWSIwpqMIi3IdyLM/hwvnQuU+ePZSeOpCyF3h7+hMF2aJwJiOJiTMTUS7fRWc93u3VPYTZ8O8mW5+QnW5vyM0XYwlAmM6qpAwmHgbzF4D58yBiiL41/fgj0Ph9bugIMvfEZouwoaPGtNZqLrNdFY/DV+8DPXVbs+E6XfDgNP9HZ3p4FoaPmo1AmM6CxHoN8mNNPrhJjj7l1CyHZ66wNUQqg76O0LTSVkiMKYzioqDqXfC7Stg8u1uLsJDk701hVp/R2c6GUsExnRmYVFw7v/Cze+4PZb/eTP8ZQx89Hu3f4IxrWCJwJiuoO+p8J1P4coX3J7M790Pc8fCp3+Fuhp/R2c6OEsExnQVQcEwdCZc+yp8d5nrT/jPvfDQJLd5TicbGGLajyUCY7qipOFw9Utw9csuQTx/FTw+A7a+ZwnBHMUSgTFd2eBz4DtL4aK/QlkBPDMLnjwftrwNHo+/ozMdhCUCY7q64BAYfx3MXg3n/Q4O7IJ/XAYPn+Z2UbM+hIBnicCYQBESDhP/C+5YA7Medfsq/+u78MAY+PhPcGi/vyM0fmKJwJhAExwKGZfDd5bANa9A4jBY/Ev400hY9BNXYzABxRKBMYFKBNJnwHUL4dufuC01lz8KD4yFf97ittc0AcESgTEGeo2Gb/wd7ljrts3c9CY8NBFe+S8o3urv6IyPWSIwxnwpNtXNVL5znds2M+tf8LdMeOEa2P6xDT3tonyWCERknogUisj6Zq6LiMwVkRwRWSci430VizHmOHVLgK/d72oIU+6AHUvc4nYPT4Flj9jyFV2ML2sE84GZLVw/DxjsPW4DHvZhLMaYE9E9Gc6+D36QBRf9zXU0L7rb7YnwwjVub2VPvb+jNCcpxFcvrKofiUhaC7dcDDytbkOEZSLSQ0R6q+peX8VkjDlBoZEw/lp35K+HtQtg7fOw8d8Q29fNUxj9TYgb6O9IzQnwZx9BCpDb6HGe99xRROQ2EVkpIiuLioraJThjTDN6jXL9CD/YCN+aD/Hp8P7/wtxx8MhUt/LpwT3+jtIcB38mAmniXJM9Uar6qKpmqmpmYmKij8MyxrRKSBiMnOWGn975BZz7awiNciuf/mUMLPwuFG7yd5SmFXzWNNQKeUDfRo9TAfszwpjOqEc/N8po8vdg/w5Y+pDbUnPNc5CS6dY8Sj8H+oyDIBus2NH48xN5DbjOO3poElBq/QPGdAE90+D838FdG+CsnwEKH/wGHj8L/jreJYmqUn9HaRrx2eb1IrIAOANIAAqAXwChAKr6iIgI8DfcyKJK4EZVPeau9LZ5vTGdUMU+yH4HVj0JuZ9BaDfXuZxxBfSdZLWEdtDS5vU+SwS+YonAmE5u92pY/hhkLYTaStesNPpbrr8heZRb+sK0OUsExpiOp7ocNr3uhqFu/xDU40YgZVwJE26DiBh/R9ilWCIwxnRs5UWw6d+w/hXY8TFE9oTTZruEEB7t7+i6BEsExpjOY/dqeP/XkPMOBIW6ZbJ7jYKUU1zzUbcEf0fYKVkiMMZ0PrkrXC0hfz0UbIDyfAgKgcFfg7FXwdDz3X7MplVaSgT+nEdgjDHN63uqOxoUbHD9CetehM1vumGqk293SSGsm9/C7AqsRmCM6Vw89bDpDfh0LuStgPBYGDgNBp4JA89w6x3ZyKOjWI3AGNN1BAXDiIvcsWsZfP4sbPvALYAHEJ0M/SZB/ykw5jLX8WxadMxEICLJwK+BPqp6noiMACar6hM+j84YY1rSb5I7VKFkmxuGumsZ7FrqNtV5736349qk70JkD39H22Eds2lIRN4CngR+qqoZIhICfK6qo9sjwCNZ05AxplXyv4APf+tqCuExMGCaSxp9J0GfsW5vhQBysk1DCar6ooj8BEBV60TEdqIwxnRsvUbD5c/C3nXw2SOwc4mbwAZuiYv+p7nkMOzrED/Iv7H6WWsSQYWIxONdIrphgTifRmWMMW2l9xi45CH3e1m+azra8TFs/wje+Zk7UjJdf8KIi6F7L//G6wetaRoaD/wVGAWsBxKBb6rqOt+HdzRrGjLGtJnSPDebed2LUPCFO9d7LAw9z3U2J4+EqDj/xthGTnpCmbdfYChuM5nNqlrbtiG2niUCY4xPFG508xO2vA25yzm8T1ZMCvSbDKO+AelnQ0i4X8M8USeVCETkuqbOq+rTbRDbcbNEYIzxuYpi2LsGCta7TuecxXCoxM1ZGHIupM+AQWdBdJK/I221k+0sbjS1jwhgBrAa8EsiMMYYn+sW777s02e4x/W1bmjq+ldcjeGLF9353hmuX2HEJZ26w/m4ZxaLSCzwjKpe5JuQWmY1AmOMX3k8kL8Oti6GzW+52c0AyaO9E90uhsSh/o2xCW266JyIhALrVHV4WwR3vCwRGGM6lAO5sPE1yHoNcpe5c/GDXdPRwDMgbQpExPozQuDk+wj+zeFeE4KAEcCLqnpPm0bZSpYIjDEd1sG9bq7C5rfc7ObaSreUdvrZbmvOoef5bYG8k00E0xs9rAN2qmpeG8Z3XCwRGGM6hbpq12y0ZZHrWzi4G4LDIWmYa0Zq2GOhd0a7jESy/QiMMcafPB5XQ9iyyI1CKtgAFYXuWnCYm7sw6CwY8jXoPQ6Cgto8hBNKBCJSxpdNQl+5BKiq+mVDUUsExpguoSzf1Rhyl7skkbcSUOiWBMPOd53OadMguG0WibYagTHGdHQVxZDzLmx5C7b8B2or3BLacYNcZ3NEDAy7wPU1nIA22Y9ARJJw8wgAUNVdJxSNMcaYo3WLh4zL3VF7yCWFzW9B2V6oOgAHdkGfcT5569bsR3AR8EegD1AI9Ac2AiN9EpExxgS60EgYfqE72kFreiR+BUwCtqjqANzM4iU+jcoYY0y7aU0iqFXVYiBIRIJU9X1grI/jMsYY005a00dwQESigY+B50SkEDefwBhjTBfQbI1ARP4mIlOAi4FK4E5gEbAVaJ+GK2OMMT7XUo0gG/gD0Bt4AVigqk+1S1TGGGPaTbM1AlV9QFUnA9OBEuBJEdkoIj8TkSHtFqExxhifOmZnsaruVNXfquo44CrgG7jho8YYY7qAYyYCEQkVkQtF5DngLWALcKnPIzPGGNMuWuosPkdE5gF5wG3Am8AgVb1cVRe25sVFZKaIbBaRHBE5atlqEeknIu+LyOcisk5Ezj/RghhjjDkxLXUW/w/wD+BHqlpyvC8sIsHAg8A5uGSyQkReU9WsRrfdi9vb4GERGYFLNmnH+17GGGNOXLOJQFXPPMnXngDkqOo2ABF5HjcUtXEiUKBhFdNYYM9Jvqcxxpjj1PaLXn8pBcht9DjPe66x+4BrRCQPVxv4flMvJCK3ichKEVlZVFTki1iNMSZg+TIRSBPnjlzz+kpgvqqmAucDz4jIUTGp6qOqmqmqmYmJiT4I1RhjApcvE0Ee0LfR41SObvq5GXgRQFWX4pa5TvBhTMYYY47gy0SwAhgsIgNEJAy4AnjtiHt24VYzRUSG4xKBtf0YY0w78lkiUNU64HbgbdwEtBdVdYOIzPHucQDwQ+BWEVkLLABu0M62ZZoxxnRybbMZZjNU9U1cJ3Djcz9v9HsWMMWXMRhjjGmZL5uGjDHGdAKWCIwxJsBZIjDGmABnicAYYwKcJQJjjAlwlgiMMSbAWSIwxpgAZ4nAGGMCnCUCY4wJcJYIjDEmwFkiMMaYAGeJwBhjApwlAmOMCXCWCIwxJsBZIjDGmABnicAYYwKcJQJjjAlwlgiMMSbAWSIwxhg/UlVKD9Xiz+3afbpnsTHGBLLVu/bz5rq9JMWE0y8uivjocPaWVpFbUsnO4gpyCsvJLiynrKqOlB6RTB4Uz6lpPcktOcTKnSWsyyslNDiI5JhwkrpHcMm4FL55Smqbx2mJwBhjTlJVbT2FB6vp0yOCkOAgSg/V8rtFm/jH8l0Ei1DnOfqv/YTocNKTunHJ2BR6xUbwRV4p72QV8PKqPIKDhBG9Y7h0fCqKUniwmsKyasqran0SvyUCY4xpBVWlsKyaeo/SOzYCEaGypo7nlu3i7x9tY195NWHBQQxM7Ma+8mpKKmq4acoA7jpnCPX1Su7+SvaVV9M7NpK+cZFEhR399VvvUbbvq6B3bATdwtvv69kSgTEmoBUcrGJJzj6Wby8hLCSIwUnRDEqKprrOQ05BOdmFZWQXlpNTUE5ZdR0A3cKCSU+KJnf/IUoqapiSHs+dowaTW1JJdmE5vWMj+OHXhjIqJfbw+8RGxTYXwmHBQUJ6UrTPytocSwTGmC7P41F2HzhETmE5OYXl7CypYFfJIXYWV7CzuBKA2MhQ6j1KuffLvsHhJpxxKQxOjkZE2FroEkRm/5781/SBnNI/zh/FajOWCIwxXYLHoxSVV5PUPRwRAVzb/bwl23nkg60crPryC75HVCh9e0Yxsk8MV03ox5T0BEb0jkEE8g9WkVNYTnhIMIOTounZLcxfRWo3lgiMMZ1G3v5KXlyRyxe7SxnSqzuj+sTSMyqMxZsKWLQ+n72lVfSJjeDMYUkMSozmiU+2s/vAIWYMS+LsEckMToomPSmaHlHNf7n3jo2kd2xkO5bK/ywRGGM6tNySSpbk7OPN9fl8nF0EwKDEaJbkFFNT7wEgLCSIM4YkcuOUNFbu2M+rn++msqaeUSkx/P5bYzhtUII/i9DhWSIwxnQoqsoXu0t59fPdLN5YyK4S14bfJzaC2WcN5rJT+5LSI5KaOg/ZhXpxptwAABFfSURBVGUUHqzm1AFxRHtH2dw2Darr6tmxr5LBSdEEBYk/i9MpWCIwxnQI2QVlvPlFPq+t3c3WogrCgoOYNiSBm6akMSU9gfSk6MNt/+BqASP7xDKyz9GvFR4SzNBe3dsx+s7NEoExxic8HuX5FbkMSY4mM+3oUTX1HmVN7n7e21TIovX5bC2qQAROTYvj1tMHct6o3sRGhfoh8sBjicAY0+YO1dRz1wtrWLQhH4CZI3tx93nDiIsK48PsIt7fVMgHmwvZX1lLcJAwIS2OG05L49yRvUiKifBz9IHHEoEx5rh5PMqqXfvpHxd11Bd34cEqbnl6JV/sLuV/zh9GTZ2Hhz/YyrsbC1BcTaBnVCjThyQyY3gy0wYn2l/+fmaJwBhzXHIKy7n7n+tYtXM/AOlJ0UwYEMehmnpySyrZXFBGvUd57NpMzh6RDMBlp/bliY+3ExwkzBiexNi+PQm2TtwOQ3y59KmIzAQeAIKBx1X1N03ccxlwH6DAWlW9qqXXzMzM1JUrV/ogWmNMYx6PkrX3IBv2lBIcFEREaBBbCyt48IMcIkOD+dHXhlBRU8+nW4tZvXM/MREh9I2Lon98FDdOGcDw3jH+LoJpRERWqWpmU9d8ViMQkWDgQeAcIA9YISKvqWpWo3sGAz8BpqjqfhFJ8lU8xpjWWb69hCeXbGfptmIOVB692uV5o3rxy4tHktTdNQl9e/qg9g7RtDFfNg1NAHJUdRuAiDwPXAxkNbrnVuBBVd0PoKqFPozHGNOC/NIqfv3mRl5bu4eE6HDOHp7MlPR4xvfriSBU19UTHCQMTGz/RdGMb/kyEaQAuY0e5wETj7hnCICILME1H92nqouOfCERuQ24DaBfv34+CdaYQJW3v5Jnlu3kmaU7qfMos89K5ztnpBMZFuzv0Ew78WUiaKon6MgOiRBgMHAGkAp8LCKjVPXAV56k+ijwKLg+grYP1ZiurfHqmwUHq6iqrae6zsOqnft5d2MBIsLMUb24+9xh9IuP8ne4pp35MhHkAX0bPU4F9jRxzzJVrQW2i8hmXGJY4cO4jAkIhQereHtDPm+tz+fzXQc4VFt/1D1x3cL49vRBXDOpP316BNZCa+ZLvkwEK4DBIjIA2A1cARw5ImghcCUwX0QScE1F23wYkzFd3trcA/zxnS18nF2EqhveecWEvgxJ7s7gpGj69IgkIjSYiNAgIkKCbS0e47tEoKp1InI78Dau/X+eqm4QkTnASlV9zXvtayKSBdQDP1bVYl/FZExX5fG4hdoe+iCHtzcUENctjNlnDeaCMb0ZnGxr7piW+XQegS/YPAJjHFXl3+v28vaGfJZuLaakoobu4SHcOm0gN00dcHg1TmPAT/MIjDG+k19axd3/XMeHW4pIjgnnjKGJTBmUwIzhSS1uumJMUywRGNMJbNx7kH3l1VTXeth94BB/emcL1XX1zLl4JNdM7G/t/OakWCIwpoNSVZbkFDN3cTbLd5R85drYvj3402UZNrnLtAlLBMb4WXZBGZ/k7GNJzj7W5ZUSHhpEbGQotXXK5oIyesVE8PMLRjA6NZbwkCCiwoIZkBBti7aZNmOJwBg/2VlcwZx/Z7F4k1tZpX98FFMHJ6AKpYdqqaqt5/7Jo/hWZirhITbL1/iOJQJj2kHe/kr+tWYPEaHBxEaGsrWonCc+3k5osPDfM4dyUUYfUnvajF7jH5YIjPGxwoNVXPHoMvL2H/rK+VnjUrjnvGEk245cxs8sERjjQwerarn+yRWUVNTw6ndPY2BCNKWHagkKwmoApsOwRGCMj1TV1vPtZ1aRXVDG49dnMq5fTwDbltF0OJYIjGkjO/ZVsHhTIat37SenoJzt+yqoqffwp8syOGOo7blkOi5LBMachPLqOuYv2c4rq3ezbV8FAH3jIhma3J0zhyUxeVA804ck+jlKY1pmicCYE1BVW89zn+3iofdzKK6oYUp6PNdN7s9Zw5JtPX/T6VgiMKYZVbX1/PLfG+gRFcbNUweQEB2OqvL2hgLufyOLvP2HmJqewI/OHcrYvj38Ha4xJ8wSgTFNOFRTz61Pr2TJ1n0AzF+ygysn9CO7sIyPs/cxNLk7z90ykSnpCX6O1JiTZ4nABKSq2noWfr6bg1W1AAhCelI04/r1ICwkiJvnr2TZ9mJ+/80MxvbtwUPv5zD/0+1Eh4dw34UjuGZSf0KCg/xcCmPahu1HYALOhj2l/OCFtWwuKGvyeo+oUA4equVPl43lknEph88XllURERpMTIQN/zSdj+1HYAJKbkklK3aUcPrgRBK7hx8+X1ZVy1Of7uCBxdn0iArjieszmTQwHoC6eiVr70FW7Swha+9BLh6bwrkje33ldZO62wxg0zVZIjBdxvrdpfz9o228sW4PHoWQIOGcEcmcOTSJj7KLeCergOo6D18f3Zv7LxlFz25f3cBl8qB4Jg+K91P0xviPJQLTKdXUefhgcyEfZ+8ju7CM7IJyiitqiA4P4ZbTB/K1EcksWp/PP1fn8db6fHpGhXL5qX25ZFwK4/r2QMSWcDamgSUC02kcqKxh9a79vLuxkDfW7aX0UC3dw0MYnBzN2cOTGZUSw8XjUg634WemxfHjmUPZkl/O0F7dCQuxzl1jmmKJwHQYxeXV7CqpBECB4vIasgvLyCko54vdpWQXlgMQERrEuSN7ccm4FE5PT2hx9E54SDCjU2PbI3xjOi1LBMbvVJWXVuYx5/UsyqvrjrreKyaCYb27c/HYPpzSP46xfXsQGWYbtRjTViwRmHZVWlnL00t3UOdR0pOiSe0ZyYPv5/DuxkImDYzj1tMHHt6IPTYylPSkaBuuaYyPWSIw7aKmzsMzy3Yyd3H24UlcDVNYwkKC+NkFI7jxtLTDScAY034sERif2VpUztKtxazauZ+lW4vJP1jF6YMT+J/zhzMgoRvbiirYWlTOqJRYBiR083e4xgQsSwSmzVXV1vO7RZuZt2Q7AAnRYZzSvyf/N2E0ZwxJPDx0c0SfGEb0ifFnqMYYLBGYNrYu7wB3vbCGrUUVXD+5PzdNHUC/uCgbt29MB2aJwJwUj0f5cEsRH2fv49Ot+9iUX0bv2AievXkiUwfbypzGdAaWCMwJKyyr4ocvruXj7H2EhwSRmdaT/545lKsn9ic20kb6GNNZWCIwJ+T9TYX86KW1VNTU8auLR/KtzL5EhNrYfmM6I0sEplXqPcqa3P28t6mQxRsL2ZRfxrBe3Xn+ykkMTu7u7/CMMSfBEoFpVm29hxXbS3hz/V7e3lBAUVk1wUHCqWk9uffrw7lmUn+rBRjTBfg0EYjITOABIBh4XFV/08x93wReAk5VVZ/uOlPvUfIPVpFfWoWnk23Kc7JUoc7jobrWQ3VdPVXen9V1HjweJTw0mPCQIEoqaliSs4/l20uoqKknMjSYM4clMnNUb6YPSbT2f2O6GJ8lAhEJBh4EzgHygBUi8pqqZh1xX3dgNvCZr2IB16b9y39vYPeBQ9TWB1YCOBEDE7oxa3wKU9MTmTYkgagwqzwa01X58v/uCUCOqm4DEJHngYuBrCPu+xXwO+BHPoyFuG5hjOwTy8xRvekbF0mfHpGEBgXessQhwUJ4SBDhIcGEhwYRERpMREgQIkJNnYeq2nqiwoJJirHduIwJFL5MBClAbqPHecDExjeIyDigr6q+LiLNJgIRuQ24DaBfv34nFExG3x48ePX4E3quMcZ0Zb78k7ipqaSH22REJAj4M/DDY72Qqj6qqpmqmpmYmNiGIRpjjPFlIsgD+jZ6nArsafS4OzAK+EBEdgCTgNdEJNOHMRljjDmCLxPBCmCwiAwQkTDgCuC1houqWqqqCaqapqppwDLgIl+PGjLGGPNVPksEqloH3A68DWwEXlTVDSIyR0Qu8tX7GmOMOT4+HROoqm8Cbx5x7ufN3HuGL2MxxhjTtMAbP2mMMeYrLBEYY0yAs0RgjDEBTrSTrbcjIkXAzhN8egKwrw3D6SwCsdyBWGYIzHIHYpnh+MvdX1WbnIjV6RLByRCRlaoacPMUArHcgVhmCMxyB2KZoW3LbU1DxhgT4CwRGGNMgAu0RPCovwPwk0AsdyCWGQKz3IFYZmjDcgdUH4ExxpijBVqNwBhjzBEsERhjTIALmEQgIjNFZLOI5IjIPf6OxxdEpK+IvC8iG0Vkg4jc4T0fJyLviEi292dPf8fqCyISLCKfi8jr3scDROQzb7lf8K6C22WISA8ReVlENnk/88mB8FmLyF3e/77Xi8gCEYnoip+1iMwTkUIRWd/oXJOfrzhzvd9v60TkuHbhCohE0Gj/5POAEcCVIjLCv1H5RB3wQ1Udjtvf4Xvect4DLFbVwcBi7+Ou6A7cSrcNfgv82Vvu/cDNfonKdx4AFqnqMCADV/Yu/VmLSApuj/NMVR0FBOOWuO+Kn/V8YOYR55r7fM8DBnuP24CHj+eNAiIR0Gj/ZFWtARr2T+5SVHWvqq72/l6G+2JIwZX1Ke9tTwGX+CdC3xGRVODrwOPexwKcBbzsvaVLlVtEYoBpwBMAqlqjqgcIgM8at2pypIiEAFHAXrrgZ62qHwElR5xu7vO9GHhanWVADxHp3dr3CpRE0NT+ySl+iqVdiEgaMA74DEhW1b3gkgWQ5L/IfOYvwH8DHu/jeOCAd18M6Hqf+UCgCHjS2xz2uIh0o4t/1qq6G/gDsAuXAEqBVXTtz7qx5j7fk/qOC5RE0OL+yV2NiEQD/wTuVNWD/o7H10TkAqBQVVc1Pt3ErV3pMw8BxgMPq+o4oIIu1gzUFG+b+MXAAKAP0A3XLHKkrvRZt8ZJ/fceKIngWPsndxkiEopLAs+p6ive0wUN1UTvz0J/xecjU4CLvHtfP49rJvgLrnrcsPlSV/vM84A8Vf3M+/hlXGLo6p/12cB2VS1S1VrgFeA0uvZn3Vhzn+9JfccFSiJocf/krsLbLv4EsFFV/9To0mvA9d7frwf+1d6x+ZKq/kRVU717X18BvKeqVwPvA9/03talyq2q+UCuiAz1npoBZNHFP2tck9AkEYny/vfeUO4u+1kfobnP9zXgOu/ooUlAaUMTUquoakAcwPnAFmAr8FN/x+OjMk7FVQfXAWu8x/m49vLFQLb3Z5y/Y/Xhv8EZwOve3wcCy4Ec4CUg3N/xtXFZxwIrvZ/3QqBnIHzWwC+BTcB64BkgvCt+1sACXD9ILe4v/pub+3xxTUMPer/fvsCNqmr1e9kSE8YYE+ACpWnIGGNMMywRGGNMgLNEYIwxAc4SgTHGBDhLBMYYE+AsERjjYyJyRsOKqMZ0RJYIjDEmwFkiMMZLRK4RkeUiskZE/u7d36BcRP4oIqtFZLGIJHrvHSsiy7xrv7/aaF34dBF5V0TWep8zyPvy0Y32DnjOOysWEfmNiGR5X+cPfiq6CXCWCIwBRGQ4cDkwRVXHAvXA1bhFzVar6njgQ+AX3qc8DdytqmNwMzkbzj8HPKiqGbg1cBqm+Y8D7sTthzEQmCIiccAsYKT3de73bSmNaZolAmOcGcApwAoRWeN9PBC3rPUL3nueBaaKSCzQQ1U/9J5/CpgmIt2BFFV9FUBVq1S10nvPclXNU1UPbumPNOAgUAU8LiLfABruNaZdWSIwxhHgKVUd6z2Gqup9TdzX0posTS0F3KC60e/1QIi69fMn4FaLvQRYdJwxG9MmLBEY4ywGvikiSXB4b9j+uP9HGla1vAr4RFVLgf0icrr3/LXAh+r2fsgTkUu8rxEuIlHNvaF334hYVX0T12w01hcFM+ZYQo59izFdn6pmici9wH9EJAi34uP3cBu+jBSRVbjdsC73PuV64BHvF/024Ebv+WuBv4vIHO9rfKuFt+0O/EtEInC1ibvauFjGtIqtPmpMC0SkXFWj/R2HMb5kTUPGGBPgrEZgjDEBzmoExhgT4CwRGGNMgLNEYIwxAc4SgTHGBDhLBMYYE+D+H/Kgaq5pqSXFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['loss'])\n",
    "plt.legend(['Accuracy', 'Loss'])\n",
    "plt.title('Model History')\n",
    "plt.ylabel('Value')\n",
    "plt.xlabel('epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial accuracy is:  0.40621963\n",
      "Final accuracy is:  0.6758989\n",
      "Initial loss is:  1.3604972426235618\n",
      "Final loss is:  0.8638907034960155\n"
     ]
    }
   ],
   "source": [
    "# plt.plot(history.history['loss'])\n",
    "# plt.title('model loss')\n",
    "# plt.ylabel('loss')\n",
    "# plt.xlabel('epochs')\n",
    "# plt.show()\n",
    "print(\"Initial accuracy is: \", history.history['acc'][0])\n",
    "print(\"Final accuracy is: \", history.history['acc'][-1])\n",
    "\n",
    "print(\"Initial loss is: \", history.history['loss'][0])\n",
    "print(\"Final loss is: \", history.history['loss'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training for go/no-go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2179, 21412)\n",
      "(661, 21412)\n",
      "(661, 21411)\n",
      "(661,)\n",
      "2.0\n",
      "4.0\n"
     ]
    }
   ],
   "source": [
    "datasetcopy = dataset.copy()\n",
    "print(datasetcopy.shape)\n",
    "datasetcopy = datasetcopy[datasetcopy[:, -1]!=9]\n",
    "datasetcopy = datasetcopy[datasetcopy[:, -1]!=10]\n",
    "\n",
    "datasetcopy = datasetcopy[datasetcopy[:, -1]!=3]\n",
    "datasetcopy = datasetcopy[datasetcopy[:, -1]!=6]\n",
    "datasetcopy = datasetcopy[datasetcopy[:, -1]!=7]\n",
    "datasetcopy = datasetcopy[datasetcopy[:, -1]!=8]\n",
    "datasetcopy = datasetcopy[datasetcopy[:, -1]!=11]\n",
    "\n",
    "# dataset\n",
    "datasetcopy = datasetcopy[datasetcopy[:, -1]!=1]\n",
    "datasetcopy = datasetcopy[datasetcopy[:, -1]!=5]\n",
    "\n",
    "print(datasetcopy.shape)\n",
    "\n",
    "xgonogo = datasetcopy[:, :-1]\n",
    "ygonogo = datasetcopy[:, -1]\n",
    "print(xgonogo.shape)\n",
    "print(ygonogo.shape)\n",
    "unique(ygonogo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "dict = {2.0: 0, 4.0: 1}\n",
    "\n",
    "for i in range(len(ygonogo)):\n",
    "    ygonogo[i] = dict[ygonogo[i]]\n",
    "\n",
    "unique(ygonogo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = 2\n",
    "ygonogo = tf.keras.utils.to_categorical(ygonogo, num_classes)\n",
    "ygonogo[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_shape = (dims_ip, )\n",
    "ip = tf.keras.Input(shape = inp_shape)\n",
    "dense1 = tf.keras.layers.Dense(units = 32, activation = 'relu', kernel_initializer = 'random_normal')(ip)\n",
    "dense2 = tf.keras.layers.Dense(units = 16, activation = 'relu', kernel_initializer = 'random_normal')(dense1)\n",
    "out = tf.keras.layers.Dense(num_classes, activation = 'softmax')(dense2)\n",
    "\n",
    "newmodel = tf.keras.Model(inputs = ip, outputs = out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 21411)]           0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 32)                685184    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 2)                 34        \n",
      "=================================================================\n",
      "Total params: 685,746\n",
      "Trainable params: 685,746\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "newmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop = EarlyStopping(patience = 50, min_delta = 0.0001, monitor = 'acc')\n",
    "\n",
    "path = 'new_model_checkpoint/checkpoint_{epoch:02d}';\n",
    "model_checkpoint = ModelCheckpoint(filepath = path,\n",
    "                            verbose = 0,\n",
    "                            monitor = 'acc',\n",
    "                            save_freq = 'epoch',\n",
    "                            save_best_only = True,\n",
    "                            save_weights_only = True)\n",
    "\n",
    "newmodel.compile(loss = 'categorical_crossentropy', metrics = ['accuracy'], optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "661/661 [==============================] - 1s 2ms/sample - loss: 0.6741 - acc: 0.7761\n",
      "Epoch 2/100\n",
      "661/661 [==============================] - 1s 956us/sample - loss: 0.6266 - acc: 0.7882\n",
      "Epoch 3/100\n",
      "661/661 [==============================] - 0s 391us/sample - loss: 0.5723 - acc: 0.7882\n",
      "Epoch 4/100\n",
      "661/661 [==============================] - 0s 377us/sample - loss: 0.5312 - acc: 0.7882\n",
      "Epoch 5/100\n",
      "661/661 [==============================] - 0s 395us/sample - loss: 0.5174 - acc: 0.7882\n",
      "Epoch 6/100\n",
      "661/661 [==============================] - 0s 444us/sample - loss: 0.5163 - acc: 0.7882s - loss: 0.5070 - acc: 0.7\n",
      "Epoch 7/100\n",
      "661/661 [==============================] - 0s 412us/sample - loss: 0.5163 - acc: 0.7882\n",
      "Epoch 8/100\n",
      "661/661 [==============================] - 0s 367us/sample - loss: 0.5161 - acc: 0.7882\n",
      "Epoch 9/100\n",
      "661/661 [==============================] - 0s 383us/sample - loss: 0.5159 - acc: 0.7882\n",
      "Epoch 10/100\n",
      "661/661 [==============================] - 0s 362us/sample - loss: 0.5160 - acc: 0.7882\n",
      "Epoch 11/100\n",
      "661/661 [==============================] - 0s 362us/sample - loss: 0.5160 - acc: 0.7882\n",
      "Epoch 12/100\n",
      "661/661 [==============================] - 0s 361us/sample - loss: 0.5157 - acc: 0.7882\n",
      "Epoch 13/100\n",
      "661/661 [==============================] - 0s 448us/sample - loss: 0.5157 - acc: 0.7882\n",
      "Epoch 14/100\n",
      "661/661 [==============================] - 0s 370us/sample - loss: 0.5153 - acc: 0.7882\n",
      "Epoch 15/100\n",
      "661/661 [==============================] - 0s 336us/sample - loss: 0.5154 - acc: 0.7882\n",
      "Epoch 16/100\n",
      "661/661 [==============================] - 0s 314us/sample - loss: 0.5155 - acc: 0.7882\n",
      "Epoch 17/100\n",
      "661/661 [==============================] - 0s 321us/sample - loss: 0.5153 - acc: 0.7882\n",
      "Epoch 18/100\n",
      "661/661 [==============================] - 0s 408us/sample - loss: 0.5151 - acc: 0.7882\n",
      "Epoch 19/100\n",
      "661/661 [==============================] - 0s 480us/sample - loss: 0.5149 - acc: 0.7882\n",
      "Epoch 20/100\n",
      "661/661 [==============================] - 0s 389us/sample - loss: 0.5149 - acc: 0.7882\n",
      "Epoch 21/100\n",
      "661/661 [==============================] - 0s 411us/sample - loss: 0.5155 - acc: 0.7882\n",
      "Epoch 22/100\n",
      "661/661 [==============================] - 0s 388us/sample - loss: 0.5157 - acc: 0.7882\n",
      "Epoch 23/100\n",
      "661/661 [==============================] - 0s 495us/sample - loss: 0.5155 - acc: 0.7882\n",
      "Epoch 24/100\n",
      "661/661 [==============================] - 0s 355us/sample - loss: 0.5144 - acc: 0.7882\n",
      "Epoch 25/100\n",
      "661/661 [==============================] - 0s 370us/sample - loss: 0.5144 - acc: 0.7882\n",
      "Epoch 26/100\n",
      "661/661 [==============================] - 0s 367us/sample - loss: 0.5147 - acc: 0.7882\n",
      "Epoch 27/100\n",
      "661/661 [==============================] - 0s 362us/sample - loss: 0.5143 - acc: 0.7882\n",
      "Epoch 28/100\n",
      "661/661 [==============================] - 0s 365us/sample - loss: 0.5135 - acc: 0.7882\n",
      "Epoch 29/100\n",
      "661/661 [==============================] - 0s 370us/sample - loss: 0.5136 - acc: 0.7882\n",
      "Epoch 30/100\n",
      "661/661 [==============================] - 0s 394us/sample - loss: 0.5132 - acc: 0.7882\n",
      "Epoch 31/100\n",
      "661/661 [==============================] - 0s 407us/sample - loss: 0.5131 - acc: 0.7882\n",
      "Epoch 32/100\n",
      "661/661 [==============================] - 0s 388us/sample - loss: 0.5131 - acc: 0.7882\n",
      "Epoch 33/100\n",
      "661/661 [==============================] - 0s 379us/sample - loss: 0.5129 - acc: 0.7882\n",
      "Epoch 34/100\n",
      "661/661 [==============================] - 0s 365us/sample - loss: 0.5137 - acc: 0.7882\n",
      "Epoch 35/100\n",
      "661/661 [==============================] - 0s 386us/sample - loss: 0.5143 - acc: 0.7882\n",
      "Epoch 36/100\n",
      "661/661 [==============================] - 0s 367us/sample - loss: 0.5132 - acc: 0.7882\n",
      "Epoch 37/100\n",
      "661/661 [==============================] - 0s 392us/sample - loss: 0.5124 - acc: 0.7882\n",
      "Epoch 38/100\n",
      "661/661 [==============================] - 0s 380us/sample - loss: 0.5121 - acc: 0.7882\n",
      "Epoch 39/100\n",
      "661/661 [==============================] - 0s 412us/sample - loss: 0.5121 - acc: 0.7882\n",
      "Epoch 40/100\n",
      "661/661 [==============================] - 0s 472us/sample - loss: 0.5116 - acc: 0.7882\n",
      "Epoch 41/100\n",
      "661/661 [==============================] - 0s 463us/sample - loss: 0.5120 - acc: 0.7882\n",
      "Epoch 42/100\n",
      "661/661 [==============================] - 0s 465us/sample - loss: 0.5123 - acc: 0.7882\n",
      "Epoch 43/100\n",
      "661/661 [==============================] - 0s 409us/sample - loss: 0.5118 - acc: 0.7882\n",
      "Epoch 44/100\n",
      "661/661 [==============================] - 0s 484us/sample - loss: 0.5110 - acc: 0.7882\n",
      "Epoch 45/100\n",
      "661/661 [==============================] - 0s 492us/sample - loss: 0.5109 - acc: 0.7882\n",
      "Epoch 46/100\n",
      "661/661 [==============================] - 0s 403us/sample - loss: 0.5108 - acc: 0.7882\n",
      "Epoch 47/100\n",
      "661/661 [==============================] - 0s 408us/sample - loss: 0.5105 - acc: 0.7882\n",
      "Epoch 48/100\n",
      "661/661 [==============================] - 0s 383us/sample - loss: 0.5102 - acc: 0.7882\n",
      "Epoch 49/100\n",
      "661/661 [==============================] - 0s 365us/sample - loss: 0.5101 - acc: 0.7882\n",
      "Epoch 50/100\n",
      "661/661 [==============================] - 0s 354us/sample - loss: 0.5095 - acc: 0.7882\n",
      "Epoch 51/100\n",
      "661/661 [==============================] - 0s 378us/sample - loss: 0.5106 - acc: 0.7882\n",
      "Epoch 52/100\n",
      "661/661 [==============================] - 0s 382us/sample - loss: 0.5087 - acc: 0.7882\n"
     ]
    }
   ],
   "source": [
    "newhistory = newmodel.fit(xgonogo, ygonogo, epochs=100, callbacks = [earlystop, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(newhistory.history['acc'])\n",
    "plt.plot(newhistory.history['loss'])\n",
    "plt.legend(['Accuracy', 'Loss'])\n",
    "plt.title('Model History')\n",
    "plt.ylabel('Value')\n",
    "plt.xlabel('epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
