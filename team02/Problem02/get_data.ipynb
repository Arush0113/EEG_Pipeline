{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "357b232a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77f94b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a579080c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'import_ipynb'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2000/3233574590.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mimport_ipynb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'import_ipynb'"
     ]
    }
   ],
   "source": [
    "import import_ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "382168b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tf'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2000/2476188476.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tf'"
     ]
    }
   ],
   "source": [
    "from tf.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37d6690b-4211-48d7-a9d0-633ff0e3b4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mne\n",
      "  Using cached mne-0.24.1-py3-none-any.whl (7.4 MB)\n",
      "Requirement already satisfied: numpy>=1.15.4 in c:\\users\\arush\\anaconda3\\envs\\tf-gpu_arush\\lib\\site-packages (from mne) (1.21.2)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\arush\\anaconda3\\envs\\tf-gpu_arush\\lib\\site-packages (from mne) (1.7.1)\n",
      "Installing collected packages: mne\n",
      "Successfully installed mne-0.24.1\n",
      "0.24.1\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import pathlib\n",
    "import glob\n",
    "\n",
    "!pip install mne\n",
    "import mne\n",
    "print(mne.__version__)\n",
    "\n",
    "from scipy.io import loadmat, savemat\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8eab6038-4d53-467f-b8db-fae61474e92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_trials(file_path):\n",
    "    \"\"\"\n",
    "    Utility function to get trial data from a .mat file\n",
    "    \n",
    "    Args:\n",
    "    file_path: String; Location of the matlab file\n",
    "    ----------\n",
    "    Returns:\n",
    "    trials: nparray; trials from the .mat file\n",
    "    \"\"\"\n",
    "    mat = loadmat(file_path)\n",
    "    trials = mat[\"trial\"][0]\n",
    "    return np.array([a for a in trials])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e07b9e3-2a0c-4556-938a-c7d615405f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(subject_files_path):\n",
    "    \"\"\"\n",
    "    A function to read data from all subjects and concatenate it\n",
    "    \n",
    "    Args:\n",
    "    ----------\n",
    "    subject_files_path: String; Location of where subject files are located\n",
    "    \n",
    "    Returns:\n",
    "    ----------\n",
    "    final_data: nparray; contains concatenated data from all trials\n",
    "    final_y: nparray; contains corresponding labels\n",
    "    \n",
    "    \"\"\"\n",
    "    labels = [\"breath\", \"feet\", \"future\", \"worry\"]\n",
    "    l_trial_data = {}\n",
    "    for l in labels:\n",
    "        l_trial_data[l] = []\n",
    "    for files in glob.glob(subject_files_path+str(\"/subject*\")):\n",
    "        for file in glob.glob(files + str(\"/*\")):\n",
    "            for label in labels:\n",
    "                if(file.split(\"\\\\\")[-1] == f\"{label}_cleaned_ica_data.mat\"):\n",
    "                    l_trial_data[label].append(get_file_trials(file))\n",
    "    trial_data = {}\n",
    "    for l in labels:\n",
    "        trial_data[l] = np.concatenate(l_trial_data[l], axis = 0)\n",
    "    y = {}\n",
    "    for i in range(len(labels)):\n",
    "        y[labels[i]] = np.full(trial_data[labels[i]].shape[0],i)\n",
    "    final_data = np.concatenate([i for i in trial_data.values()], axis = 0)\n",
    "    final_y = np.concatenate([i for i in y.values()], axis = 0)\n",
    "    return final_data, final_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abc49436-d2e4-4e98-a888-5acdfd22515f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = get_data(\"meditation_eeg/data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8855e44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savez('meditation_data', X = X, y = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e351e133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loadfile = np.load(\"meditation_data.npz\")\n",
    "# X = loadfile[\"X\"]\n",
    "# y = loadfile[\"y\"]\n",
    "# del loadfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b16321d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24756, 32, 513)\n",
      "(24756,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12f55721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = np.zeros((X.shape[0], X.shape[2], X.shape[1]))\n",
    "# for i in range(X.shape[0]):\n",
    "#     data[i] = np.transpose(X[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8214b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ebfed24a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ff450e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 3, 3, 3])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ab3eae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "num_classes = 4\n",
    "y = keras.utils.to_categorical(y, num_classes)\n",
    "ymlp = y.copy()\n",
    "ylstm = y.copy()\n",
    "ycnn = y.copy()\n",
    "# yab10_1[0]\n",
    "print(y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f4b14b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19804\n"
     ]
    }
   ],
   "source": [
    "train_test_split = int(0.8 * len(X))\n",
    "print(train_test_split)\n",
    "\n",
    "x_train = X[:train_test_split]\n",
    "y_train = y[:train_test_split]\n",
    "\n",
    "x_test = X[train_test_split:]\n",
    "y_test = y[train_test_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87250c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e402349d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_shape = (32, 513)\n",
    "ip = keras.Input(shape = inp_shape)\n",
    "conv1 = keras.layers.Conv1D(32, 3,)(ip)\n",
    "rel = keras.layers.LeakyReLU()(conv1)\n",
    "conv2 = keras.layers.Conv1D(16, 3,)(rel)\n",
    "rel2 = keras.layers.LeakyReLU()(conv2)\n",
    "# lstm = tf.keras.layers.LSTM(16, return_sequences=True)(ip)\n",
    "flatten = keras.layers.Flatten()(rel2)\n",
    "dense1 = keras.layers.Dense(units = 32, kernel_initializer = 'random_normal')(flatten)\n",
    "leakyRelu = keras.layers.LeakyReLU()(dense1)\n",
    "drop1 = keras.layers.Dropout(.4)(leakyRelu)\n",
    "dense2 = keras.layers.Dense(units = 16, kernel_initializer = 'random_normal')(drop1)\n",
    "leakyRelu2 = keras.layers.LeakyReLU()(dense2)\n",
    "drop2 = keras.layers.Dropout(.4)(dense2)\n",
    "out = keras.layers.Dense(4, activation = 'softmax')(drop2)\n",
    "\n",
    "cnn2 = keras.Model(inputs = ip, outputs = out)\n",
    "cnn2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3a9412e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Compiling the model\n",
    "# cnn2_earlystop = EarlyStopping(patience = 10, min_delta = 0.001, monitor = 'val_acc')\n",
    "\n",
    "# path = 'cnn2_checkpoint/checkpoint_{epoch:02d}';\n",
    "# cnn2_checkpoint = ModelCheckpoint(filepath = path,\n",
    "#                             verbose = 1,\n",
    "#                             monitor = 'val_acc',\n",
    "#                             save_freq = 'epoch',\n",
    "#                             save_best_only = True,\n",
    "#                             save_weights_only = True)\n",
    "\n",
    "cnn2.compile(loss = 'categorical_crossentropy', metrics = ['acc'], optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b837a136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "619/619 [==============================] - 22s 32ms/step - loss: 1.4962 - acc: 0.3049 - val_loss: 2.8387 - val_acc: 0.0000e+00\n",
      "Epoch 2/30\n",
      "619/619 [==============================] - 7s 11ms/step - loss: 1.2872 - acc: 0.3168 - val_loss: 2.6647 - val_acc: 2.0194e-04\n",
      "Epoch 3/30\n",
      "619/619 [==============================] - 7s 11ms/step - loss: 1.2735 - acc: 0.3124 - val_loss: 2.6925 - val_acc: 0.0000e+00\n",
      "Epoch 4/30\n",
      "619/619 [==============================] - 6s 10ms/step - loss: 1.2643 - acc: 0.3169 - val_loss: 2.8537 - val_acc: 0.0000e+00\n",
      "Epoch 5/30\n",
      "619/619 [==============================] - 6s 10ms/step - loss: 1.2586 - acc: 0.3276 - val_loss: 2.9648 - val_acc: 0.0000e+00\n",
      "Epoch 6/30\n",
      "619/619 [==============================] - 7s 11ms/step - loss: 1.2475 - acc: 0.3408 - val_loss: 2.9772 - val_acc: 0.0026\n",
      "Epoch 7/30\n",
      "619/619 [==============================] - 7s 12ms/step - loss: 1.2352 - acc: 0.3536 - val_loss: 3.2260 - val_acc: 6.0582e-04\n",
      "Epoch 8/30\n",
      "619/619 [==============================] - 7s 11ms/step - loss: 1.2202 - acc: 0.3708 - val_loss: 3.1724 - val_acc: 0.0067\n",
      "Epoch 9/30\n",
      "619/619 [==============================] - 7s 11ms/step - loss: 1.2067 - acc: 0.3783 - val_loss: 3.7436 - val_acc: 0.0018\n",
      "Epoch 10/30\n",
      "619/619 [==============================] - 7s 11ms/step - loss: 1.1913 - acc: 0.3880 - val_loss: 3.7371 - val_acc: 0.0036\n",
      "Epoch 11/30\n",
      "365/619 [================>.............] - ETA: 2s - loss: 1.1777 - acc: 0.3957"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15148/2650732933.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m cnn2_history = cnn2.fit(x_train, y_train,\n\u001b[0m\u001b[0;32m      2\u001b[0m                         \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#                         steps_per_epoch= 449,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                         \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                         \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1214\u001b[0m                 _r=1):\n\u001b[0;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1217\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    909\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 910\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    911\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    940\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    941\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 942\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    943\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3128\u001b[0m       (graph_function,\n\u001b[0;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3130\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1958\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1959\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     60\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cnn2_history = cnn2.fit(x_train, y_train,\n",
    "                        validation_data = (x_test, y_test),\n",
    "#                         steps_per_epoch= 449,\n",
    "                        batch_size = 32,\n",
    "                        epochs = 30,\n",
    "#                         callbacks = [cnn2_checkpoint],\n",
    "                        )\n",
    "                         #Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6921fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting model history\n",
    "plt.plot(cnn2_history.history['acc'])\n",
    "plt.plot(cnn2_history.history['loss'])\n",
    "plt.legend(['Training Accuracy', 'Training Loss'])\n",
    "plt.title('Training History')\n",
    "plt.ylabel('Value')\n",
    "plt.xlabel('epochs')\n",
    "plt.show()\n",
    "print(\"Initial training accuracy with preprocessing is: \", cnn2_history.history['acc'][0])\n",
    "print(\"Final training accuracy with preprocessing is: \", cnn2_history.history['acc'][-1])\n",
    "\n",
    "print(\"Initial training loss with preprocessing is: \", cnn2_history.history['loss'][0])\n",
    "print(\"Final training loss with preprocessing is: \", cnn2_history.history['loss'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64a0b97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
